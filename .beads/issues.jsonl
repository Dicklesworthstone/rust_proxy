{"id":"rust_proxy-008","title":"Feature: Dry-run mode for destructive operations","description":"Add --dry-run flag to destructive commands (stop, service uninstall, completions uninstall) that shows what would happen without actually doing it. Reduces fear of experimentation and builds trust. Implementation: check dry_run flag at start of each command, print intended actions, return early.","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:14:27.529650071-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:14:27.529650071-05:00","dependencies":[{"issue_id":"rust_proxy-008","depends_on_id":"rust_proxy-hvv","type":"blocks","created_at":"2026-01-18T14:57:05.992695494-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-008","depends_on_id":"rust_proxy-btn","type":"blocks","created_at":"2026-01-18T15:03:47.378474421-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-008","depends_on_id":"rust_proxy-ar9","type":"blocks","created_at":"2026-01-18T15:03:49.660562007-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-0em","title":"Unit tests for Dry-Run Mode","description":"## Unit Tests for Dry-Run Mode\n\n### Test Coverage Areas\n\n1. **Dry-Run Flag Parsing**\n   ```rust\n   #[test]\n   fn test_dry_run_flag_parsed() {\n       let args = Args::try_parse_from([\"rp\", \"stop\", \"--dry-run\"]).unwrap();\n       assert!(args.dry_run);\n   }\n\n   #[test]\n   fn test_dry_run_short_flag() {\n       let args = Args::try_parse_from([\"rp\", \"stop\", \"-n\"]).unwrap();\n       assert!(args.dry_run);\n   }\n\n   #[test]\n   fn test_dry_run_default_false() {\n       let args = Args::try_parse_from([\"rp\", \"stop\"]).unwrap();\n       assert!(!args.dry_run);\n   }\n   ```\n\n2. **Dry-Run Context**\n   ```rust\n   #[test]\n   fn test_dry_run_context_records_actions() {\n       let ctx = DryRunContext::new();\n\n       ctx.would_do(\"Stop daemon process (PID: 12345)\");\n       ctx.would_do(\"Remove PID file at /var/run/rp.pid\");\n\n       let actions = ctx.actions();\n       assert_eq!(actions.len(), 2);\n       assert!(actions[0].contains(\"Stop daemon\"));\n       assert!(actions[1].contains(\"Remove PID\"));\n   }\n\n   #[test]\n   fn test_dry_run_context_formats_output() {\n       let ctx = DryRunContext::new();\n       ctx.would_do(\"Stop daemon process\");\n\n       let output = ctx.format();\n       assert!(output.contains(\"Would\"));\n       assert!(output.contains(\"Stop daemon\"));\n   }\n   ```\n\n3. **Stop Command Dry-Run**\n   ```rust\n   #[tokio::test]\n   async fn test_stop_dry_run_does_not_stop() {\n       let harness = TestHarness::new().await;\n       harness.start_daemon().await.unwrap();\n       assert!(harness.daemon_is_running());\n\n       let ctx = DryRunContext::new();\n       stop_command_with_context(\u0026ctx, true).await;\n\n       // Daemon should still be running\n       assert!(harness.daemon_is_running());\n       assert!(!ctx.actions().is_empty());\n   }\n   ```\n\n4. **Service Uninstall Dry-Run**\n   ```rust\n   #[test]\n   fn test_service_uninstall_dry_run_does_not_delete() {\n       let temp = tempdir().unwrap();\n       let service_path = temp.path().join(\"rp.service\");\n       fs::write(\u0026service_path, \"[Service]\").unwrap();\n\n       let ctx = DryRunContext::new();\n       service_uninstall_with_context(\u0026ctx, \u0026service_path, true);\n\n       // File should still exist\n       assert!(service_path.exists());\n       assert!(ctx.actions().iter().any(|a| a.contains(\"Remove\")));\n   }\n   ```\n\n5. **Completions Uninstall Dry-Run**\n   ```rust\n   #[test]\n   fn test_completions_uninstall_dry_run_does_not_delete() {\n       let temp = tempdir().unwrap();\n       let completion_path = temp.path().join(\"rp\");\n       fs::write(\u0026completion_path, \"complete -F _rp rp\").unwrap();\n\n       let ctx = DryRunContext::new();\n       completions_uninstall_with_context(\u0026ctx, \u0026completion_path, true);\n\n       // File should still exist\n       assert!(completion_path.exists());\n       assert!(!ctx.actions().is_empty());\n   }\n   ```\n\n6. **Action Description Quality**\n   ```rust\n   #[test]\n   fn test_dry_run_actions_are_descriptive() {\n       let ctx = DryRunContext::new();\n\n       // Actions should include relevant details\n       ctx.would_do(\"Stop daemon process (PID: 12345)\");\n       ctx.would_do(\"Remove /var/run/rp.pid\");\n\n       for action in ctx.actions() {\n           // Should not be vague\n           assert!(!action.contains(\"do something\"));\n           // Should have specifics (paths, PIDs, etc)\n           assert!(action.len() \u003e 10);\n       }\n   }\n   ```\n\n7. **Dry-Run With JSON Output**\n   ```rust\n   #[test]\n   fn test_dry_run_json_format() {\n       let ctx = DryRunContext::new();\n       ctx.would_do(\"Stop daemon\");\n       ctx.would_do(\"Remove PID file\");\n\n       let json = ctx.to_json().unwrap();\n       let parsed: Value = serde_json::from_str(\u0026json).unwrap();\n\n       assert!(parsed[\"dry_run\"].as_bool().unwrap());\n       assert!(parsed[\"actions\"].is_array());\n       assert_eq!(parsed[\"actions\"].as_array().unwrap().len(), 2);\n   }\n   ```\n\n### Test Files\n- `src/commands/common.rs` - DryRunContext tests\n- `tests/unit/dry_run_test.rs` - extended tests","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:30.414081605-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:30.414081605-05:00","dependencies":[{"issue_id":"rust_proxy-0em","depends_on_id":"rust_proxy-008","type":"blocks","created_at":"2026-01-18T14:56:55.090064999-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-0fx","title":"Implement 'rust_proxy test \u003curl\u003e' routing diagnosis command","description":"## Overview\n\nAdd a `rust_proxy test \u003curl\u003e` command that shows exactly how a given URL would be routed - whether it would go through the proxy or direct, and WHY. This is the single most valuable diagnostic feature for users troubleshooting routing issues.\n\n## Background \u0026 Motivation\n\n**The Problem:**\nUsers frequently ask \"Why isn't my traffic going through the proxy?\" Currently, answering this requires:\n1. Running the daemon with debug logging\n2. Making actual requests and observing behavior\n3. Manually checking ipset rules with root access\n4. Deep understanding of the routing logic\n\n**The Solution:**\nA simple command that answers: \"Would this URL be proxied? Why or why not?\"\n\n```bash\nrust_proxy test https://api.openai.com/v1/chat\n```\n\nThis is the #1 most valuable user-facing feature because it:\n- Provides instant answers without running daemon\n- Explains the routing decision chain\n- Gives actionable suggestions when routing doesn't match expectations\n- Works for both debugging and learning how the system works\n\n## CLI Interface\n\n```\nrust_proxy test \u003curl\u003e [OPTIONS]\n\nARGS:\n    \u003curl\u003e           URL or domain to test (e.g., https://api.openai.com/v1/chat, api.openai.com)\n\nOPTIONS:\n    --json          Output results as JSON\n    -v, --verbose   Show detailed routing decision process (each check step)\n    --no-dns        Skip DNS resolution (only check config, useful offline)\n```\n\n## Decision Logic Flow\n\nThe test command evaluates routing in this order:\n\n1. **Parse input** → Extract domain from URL\n2. **Check if domain in targets** → Direct config match\n3. **Resolve DNS** → Get IP addresses for domain\n4. **Check ipset membership** → Is IP in the target set? (if daemon running)\n5. **Check provider IP ranges** → Does IP match AWS/Cloudflare/Google ranges?\n6. **Aggregate decision** → Proxied if ANY check passes\n\n## Output Formats\n\n### Standard Output - WOULD BE PROXIED\n```\nrust_proxy test https://api.openai.com/v1/chat\n\nURL: https://api.openai.com/v1/chat\nDomain: api.openai.com\nResolved IPs: 104.18.6.192, 104.18.7.192\n\n✓ WOULD BE PROXIED via 'mesh-us'\n\nRouting Decision:\n  ✓ Domain 'api.openai.com' is in targets list\n    └─ Provider hint: openai\n  ✓ IP 104.18.6.192 would be in ipset (based on config)\n\nActive proxy: mesh-us (http://us-wa.proxymesh.com:31280)\n```\n\n### Standard Output - WOULD NOT BE PROXIED\n```\nrust_proxy test https://example.com/api\n\nURL: https://example.com/api\nDomain: example.com\nResolved IPs: 93.184.216.34\n\n✗ WOULD NOT BE PROXIED (direct connection)\n\nRouting Decision:\n  ✗ Domain 'example.com' is not in targets list\n  ✗ IP 93.184.216.34 does not match any provider range\n\nSuggestions:\n  • Add domain to targets:\n    rust_proxy targets add example.com\n  • Or with provider hint (if applicable):\n    rust_proxy targets add example.com --provider \u003cprovider\u003e\n```\n\n### Standard Output - PROXIED VIA PROVIDER RANGE\n```\nrust_proxy test https://storage.googleapis.com/my-bucket/file\n\nURL: https://storage.googleapis.com/my-bucket/file\nDomain: storage.googleapis.com\nResolved IPs: 142.250.185.208\n\n✓ WOULD BE PROXIED via 'mesh-us'\n\nRouting Decision:\n  ✗ Domain 'storage.googleapis.com' is not explicitly in targets\n  ✓ IP 142.250.185.208 matches Google Cloud IP range\n    └─ Matched range: 142.250.0.0/15 (via include_google_ip_ranges=true)\n\nNote: This domain is proxied via provider IP range matching, not explicit target.\n```\n\n### Standard Output - DAEMON NOT RUNNING\n```\nrust_proxy test https://api.openai.com/v1/chat\n\nURL: https://api.openai.com/v1/chat\nDomain: api.openai.com\nResolved IPs: 104.18.6.192, 104.18.7.192\n\n✓ WOULD BE PROXIED via 'mesh-us' (when daemon is running)\n\nRouting Decision:\n  ✓ Domain 'api.openai.com' is in targets list\n    └─ Provider hint: openai\n\nNote: Daemon is not running. ipset rules not active.\n      Run 'sudo rust_proxy daemon' to activate routing.\n```\n\n### Standard Output - NO ACTIVE PROXY\n```\nrust_proxy test https://api.openai.com/v1/chat\n\nURL: https://api.openai.com/v1/chat\nDomain: api.openai.com\nResolved IPs: 104.18.6.192, 104.18.7.192\n\n⚠ NO ACTIVE PROXY CONFIGURED\n\nThe domain matches routing rules, but no proxy is activated.\nRun 'rust_proxy activate --select' to choose a proxy.\n```\n\n### Verbose Output (-v)\n```\nrust_proxy test https://api.openai.com/v1/chat -v\n\n[1/5] Parsing URL...\n      Input: https://api.openai.com/v1/chat\n      Extracted domain: api.openai.com\n\n[2/5] Checking targets list...\n      Searching 87 configured targets\n      ✓ Found: api.openai.com (provider: openai)\n\n[3/5] Resolving DNS...\n      Query: api.openai.com A\n      Response: 104.18.6.192, 104.18.7.192 (23ms)\n\n[4/5] Checking ipset membership...\n      Daemon status: not running\n      Skipping ipset check (would be populated when daemon runs)\n\n[5/5] Checking provider IP ranges...\n      IP 104.18.6.192:\n        AWS ranges: ✗ no match\n        Cloudflare ranges: ✓ matches 104.16.0.0/13\n        Google ranges: ✗ no match\n\nFinal Decision: WOULD BE PROXIED\n```\n\n### JSON Output\n```json\n{\n  \"input\": \"https://api.openai.com/v1/chat\",\n  \"domain\": \"api.openai.com\",\n  \"resolved_ips\": [\"104.18.6.192\", \"104.18.7.192\"],\n  \"would_proxy\": true,\n  \"active_proxy\": {\n    \"id\": \"mesh-us\",\n    \"url\": \"http://us-wa.proxymesh.com:31280\"\n  },\n  \"routing_decision\": {\n    \"domain_in_targets\": true,\n    \"target_provider\": \"openai\",\n    \"ip_in_ipset\": null,\n    \"provider_range_match\": {\n      \"ip\": \"104.18.6.192\",\n      \"provider\": \"cloudflare\",\n      \"range\": \"104.16.0.0/13\"\n    }\n  },\n  \"daemon_running\": false,\n  \"suggestions\": []\n}\n```\n\n## Edge Cases\n\n### 1. Domain-only input\n```bash\nrust_proxy test api.openai.com  # Works, assumes https://\n```\n\n### 2. URL with port\n```bash\nrust_proxy test https://api.example.com:8443/endpoint\n# Extracts domain: api.example.com (port ignored for routing)\n```\n\n### 3. IP address input\n```bash\nrust_proxy test 104.18.6.192\n# Checks IP directly against ipset and provider ranges\n```\n\n### 4. DNS resolution failure\n```\nrust_proxy test https://nonexistent.example.invalid\n\nURL: https://nonexistent.example.invalid\nDomain: nonexistent.example.invalid\n\n✗ DNS RESOLUTION FAILED\n\nError: NXDOMAIN - domain does not exist\n\nCannot determine routing without resolved IP addresses.\nCheck domain spelling or network connectivity.\n```\n\n### 5. Offline mode (--no-dns)\n```bash\nrust_proxy test https://api.openai.com --no-dns\n# Shows config-based decision only, skips DNS and IP checks\n```\n\n## Implementation Notes\n\n### Code Structure\n```rust\n// In src/main.rs or src/test_command.rs\n\nstruct TestTarget {\n    input: String,\n    domain: String,\n    port: Option\u003cu16\u003e,\n}\n\nstruct RoutingDecision {\n    would_proxy: bool,\n    domain_in_targets: bool,\n    target_provider: Option\u003cString\u003e,\n    ip_in_ipset: Option\u003cbool\u003e,  // None if daemon not running\n    provider_range_matches: Vec\u003cProviderMatch\u003e,\n}\n\nstruct ProviderMatch {\n    ip: IpAddr,\n    provider: String,\n    cidr: String,\n}\n\nasync fn test_routing(target: \u0026TestTarget, config: \u0026Config) -\u003e RoutingResult {\n    // 1. Check domain in targets\n    // 2. Resolve DNS (unless --no-dns)\n    // 3. Check ipset (if daemon running)\n    // 4. Check provider ranges\n    // 5. Aggregate and return\n}\n```\n\n### Daemon Detection\n```rust\nfn is_daemon_running() -\u003e bool {\n    // Check if process is listening on configured port\n    TcpStream::connect((\"127.0.0.1\", config.settings.listen_port)).is_ok()\n}\n```\n\n### ipset Query (when daemon running)\n```rust\nfn is_ip_in_ipset(ip: IpAddr, ipset_name: \u0026str) -\u003e Result\u003cbool\u003e {\n    let output = Command::new(\"ipset\")\n        .args([\"test\", ipset_name, \u0026ip.to_string()])\n        .output()?;\n    Ok(output.status.success())\n}\n```\n\n## File Changes Summary\n\n| File | Change |\n|------|--------|\n| `src/main.rs` | Add `test` subcommand |\n| `src/main.rs` | Add test_routing() function |\n| `src/ip_ranges.rs` | Add `find_matching_range(ip)` helper (reuse existing CIDR data) |\n\n## Testing Requirements\n\nSee dedicated subtask for comprehensive test suite.\n\n## Risk Assessment\n\n- **Complexity**: Medium (DNS lookup, ipset query, decision logic)\n- **Impact**: Very high (most valuable user-facing diagnostic feature)\n- **Risk**: Very low (read-only, diagnostic only, no side effects)\n- **Confidence**: Very high (clear requirements, well-scoped implementation)\n\n## Dependencies\n\n- Shares validation patterns with 'rust_proxy check' command\n- Should be implemented after 'check' to reuse URL/domain parsing helpers","status":"closed","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:49:14.641393324-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:35:42.023309231-05:00","closed_at":"2026-01-18T04:35:42.023309231-05:00","close_reason":"Test command fully implemented and verified: URL parsing, DNS lookup, routing decision logic, output formatting (standard/JSON/verbose), all 55 tests passing","dependencies":[{"issue_id":"rust_proxy-0fx","depends_on_id":"rust_proxy-4ce","type":"blocks","created_at":"2026-01-18T02:53:17.220346495-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-0fx.1","title":"Subtask: Implement URL parsing and DNS lookup for test command","description":"## Scope\nImplement URL parsing and DNS resolution for the 'rust_proxy test' command.\n\n## Tasks\n1. Parse user-provided URL:\n   - Extract domain/host from URL\n   - Handle various URL formats:\n     - Full URL: https://api.openai.com/v1/chat\n     - Domain only: api.openai.com\n     - With port: api.example.com:8443\n   - Validate URL format, provide helpful errors\n2. Perform DNS resolution:\n   - Resolve domain to IPv4 addresses\n   - Handle DNS failures gracefully\n   - Timeout handling (use dns_timeout or default)\n3. Display resolution results:\n   - Show resolved IPs\n   - Show if resolution failed and why\n\n## Output Format\n```\nURL: https://api.openai.com/v1/chat\nDomain: api.openai.com\nResolved IPs: 104.18.6.192, 104.18.7.192\n```\nor\n```\nURL: https://invalid.example.com/api\nDomain: invalid.example.com\n✗ DNS resolution failed: NXDOMAIN\n```\n\n## Code Location\nNew function in `src/main.rs` or dedicated module: `parse_test_url(url: \u0026str) -\u003e Result\u003cTestTarget\u003e`\n\n## Testing\n- Test various URL formats\n- Test domain-only input\n- Test with ports\n- Test DNS failure handling","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:50:33.582336109-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:35:41.630515791-05:00","closed_at":"2026-01-18T04:35:41.630515791-05:00","close_reason":"Test command fully implemented and verified: URL parsing, DNS lookup, routing decision logic, output formatting (standard/JSON/verbose), all 55 tests passing","dependencies":[{"issue_id":"rust_proxy-0fx.1","depends_on_id":"rust_proxy-0fx","type":"parent-child","created_at":"2026-01-18T02:50:33.594779838-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-0fx.2","title":"Subtask: Implement routing decision logic for test command","description":"## Scope\nImplement the core routing decision logic that determines if traffic would be proxied.\n\n## Decision Flow\n1. Check if domain is in targets list:\n   - Direct match against configured targets\n   - Record provider hint if present\n2. Check if IP is in ipset (if daemon running):\n   - Query ipset for each resolved IP\n   - May require sudo or reading ipset state\n3. Check provider IP ranges:\n   - If include_aws_ip_ranges: check AWS CIDRs\n   - If include_cloudflare_ip_ranges: check CF CIDRs  \n   - If include_google_ip_ranges: check Google CIDRs\n4. Aggregate decision:\n   - Proxied if: domain in targets OR IP in ipset OR IP in provider range\n   - Direct if: none of the above\n\n## Data Structures\n```rust\npub struct RoutingDecision {\n    pub would_proxy: bool,\n    pub active_proxy: Option\u003cString\u003e,\n    pub reasons: RoutingReasons,\n}\n\npub struct RoutingReasons {\n    pub domain_in_targets: bool,\n    pub target_provider: Option\u003cString\u003e,\n    pub ip_in_ipset: bool,\n    pub provider_range_match: Option\u003cString\u003e,\n}\n```\n\n## Code Location\nNew function: `determine_routing(domain: \u0026str, ips: \u0026[IpAddr], config: \u0026Config) -\u003e RoutingDecision`\n\n## Testing\n- Test domain in targets\n- Test domain not in targets but IP in provider range\n- Test completely unmatched domain/IP\n- Test with various provider configurations","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:50:40.935444506-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:35:41.767322556-05:00","closed_at":"2026-01-18T04:35:41.767322556-05:00","close_reason":"Test command fully implemented and verified: URL parsing, DNS lookup, routing decision logic, output formatting (standard/JSON/verbose), all 55 tests passing","dependencies":[{"issue_id":"rust_proxy-0fx.2","depends_on_id":"rust_proxy-0fx","type":"parent-child","created_at":"2026-01-18T02:50:40.959797968-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-0fx.3","title":"Subtask: Implement output formatting and CLI for test command","description":"## Scope\nImplement the CLI subcommand and output formatting for 'rust_proxy test'.\n\n## CLI Definition\n```rust\n#[derive(Subcommand)]\nenum Commands {\n    /// Test routing for a URL\n    Test {\n        /// URL to test (e.g., https://api.openai.com/v1/chat)\n        url: String,\n        /// Output as JSON\n        #[arg(long)]\n        json: bool,\n        /// Show detailed routing decision process\n        #[arg(long, short)]\n        verbose: bool,\n    },\n}\n```\n\n## Output Formats\n\n### Standard Output (proxied)\n```\nURL: https://api.openai.com/v1/chat\nDomain: api.openai.com\nResolved IPs: 104.18.6.192, 104.18.7.192\n\n✓ WOULD BE PROXIED via 'mesh-us'\n\nReason:\n  ✓ Domain 'api.openai.com' is in targets list (provider: openai)\n  ✓ IP 104.18.6.192 is in ipset 'rust_proxy_targets'\n```\n\n### Standard Output (not proxied)\n```\nURL: https://example.com/api\nDomain: example.com\nResolved IPs: 93.184.216.34\n\n✗ WOULD NOT BE PROXIED (direct connection)\n\nReason:\n  ✗ Domain 'example.com' is not in targets list\n  ✗ IP 93.184.216.34 is not in ipset 'rust_proxy_targets'\n\nSuggestions:\n  • Add target: rust_proxy targets add example.com\n```\n\n### JSON Output\n```json\n{\n  \"url\": \"https://api.openai.com/v1/chat\",\n  \"domain\": \"api.openai.com\",\n  \"resolved_ips\": [\"104.18.6.192\"],\n  \"would_proxy\": true,\n  \"active_proxy\": \"mesh-us\",\n  \"reasons\": {\n    \"domain_in_targets\": true,\n    \"ip_in_ipset\": true,\n    \"provider_match\": \"openai\"\n  }\n}\n```\n\n## Color Scheme\n- ✓ Green for positive matches\n- ✗ Red for negative/missing\n- Yellow for suggestions\n- Cyan for informational (IPs, domain)\n\n## Code Location\n- CLI: `src/main.rs`\n- Formatting: helper functions or inline\n\n## Testing\n- Test standard output format\n- Test JSON output format\n- Test verbose mode\n- Test color output (manual)","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:50:48.245843194-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:35:41.79792637-05:00","closed_at":"2026-01-18T04:35:41.79792637-05:00","close_reason":"Test command fully implemented and verified: URL parsing, DNS lookup, routing decision logic, output formatting (standard/JSON/verbose), all 55 tests passing","dependencies":[{"issue_id":"rust_proxy-0fx.3","depends_on_id":"rust_proxy-0fx","type":"parent-child","created_at":"2026-01-18T02:50:48.26418842-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-0fx.4","title":"Subtask: Comprehensive test suite for test command","description":"## Scope\nCreate comprehensive unit tests, integration tests, and E2E tests for the 'rust_proxy test' command.\n\n## Unit Tests\n\n### URL/Domain Parsing Tests\n```rust\n#[test]\nfn test_parse_full_url() {\n    let target = parse_test_input(\"https://api.openai.com/v1/chat\").unwrap();\n    assert_eq\\!(target.domain, \"api.openai.com\");\n}\n\n#[test]\nfn test_parse_url_with_port() {\n    let target = parse_test_input(\"https://api.example.com:8443/path\").unwrap();\n    assert_eq\\!(target.domain, \"api.example.com\");\n    assert_eq\\!(target.port, Some(8443));\n}\n\n#[test]\nfn test_parse_domain_only() {\n    let target = parse_test_input(\"api.openai.com\").unwrap();\n    assert_eq\\!(target.domain, \"api.openai.com\");\n}\n\n#[test]\nfn test_parse_ip_address() {\n    let target = parse_test_input(\"104.18.6.192\").unwrap();\n    assert\\!(target.is_ip_address);\n}\n\n#[test]\nfn test_parse_invalid_input() {\n    assert\\!(parse_test_input(\"\").is_err());\n    assert\\!(parse_test_input(\"not a valid thing :::\").is_err());\n}\n```\n\n### Routing Decision Tests\n```rust\n#[test]\nfn test_domain_in_targets_matches() {\n    let config = test_config_with_target(\"api.openai.com\");\n    let decision = check_domain_in_targets(\"api.openai.com\", \u0026config);\n    assert\\!(decision.matches);\n    assert_eq\\!(decision.provider, Some(\"openai\".to_string()));\n}\n\n#[test]\nfn test_domain_not_in_targets() {\n    let config = test_config_with_target(\"api.openai.com\");\n    let decision = check_domain_in_targets(\"example.com\", \u0026config);\n    assert\\!(\\!decision.matches);\n}\n\n#[test]\nfn test_ip_in_provider_range_cloudflare() {\n    let ip: IpAddr = \"104.18.6.192\".parse().unwrap();\n    let result = check_provider_ranges(ip, \u0026default_ranges());\n    assert\\!(result.matches);\n    assert_eq\\!(result.provider, Some(\"cloudflare\".to_string()));\n}\n\n#[test]\nfn test_ip_in_provider_range_google() {\n    let ip: IpAddr = \"142.250.185.208\".parse().unwrap();\n    let result = check_provider_ranges(ip, \u0026default_ranges());\n    assert\\!(result.matches);\n    assert_eq\\!(result.provider, Some(\"google\".to_string()));\n}\n\n#[test]\nfn test_ip_not_in_any_range() {\n    let ip: IpAddr = \"93.184.216.34\".parse().unwrap(); // example.com\n    let result = check_provider_ranges(ip, \u0026default_ranges());\n    assert\\!(\\!result.matches);\n}\n\n#[test]\nfn test_aggregated_decision_domain_match() {\n    // Domain in targets -\u003e would proxy\n    let decision = aggregate_routing_decision(\n        true,   // domain_in_targets\n        false,  // ip_in_ipset\n        false,  // provider_range_match\n    );\n    assert\\!(decision.would_proxy);\n}\n\n#[test]\nfn test_aggregated_decision_provider_range() {\n    // IP in provider range (domain not in targets) -\u003e would proxy\n    let decision = aggregate_routing_decision(\n        false,  // domain_in_targets\n        false,  // ip_in_ipset\n        true,   // provider_range_match\n    );\n    assert\\!(decision.would_proxy);\n}\n\n#[test]\nfn test_aggregated_decision_no_match() {\n    let decision = aggregate_routing_decision(false, false, false);\n    assert\\!(\\!decision.would_proxy);\n}\n```\n\n### Daemon Detection Tests\n```rust\n#[tokio::test]\nasync fn test_daemon_detection_running() {\n    // Start a listener on the port\n    let listener = TcpListener::bind(\"127.0.0.1:12345\").await.unwrap();\n    assert\\!(is_daemon_running(12345));\n    drop(listener);\n}\n\n#[tokio::test]\nasync fn test_daemon_detection_not_running() {\n    assert\\!(\\!is_daemon_running(54321)); // Unlikely to be in use\n}\n```\n\n### Suggestion Generation Tests\n```rust\n#[test]\nfn test_suggestions_for_unmatched_domain() {\n    let suggestions = generate_suggestions(\"example.com\", \u0026RoutingDecision {\n        would_proxy: false,\n        domain_in_targets: false,\n        ..\n    });\n    assert\\!(suggestions.iter().any(|s| s.contains(\"targets add example.com\")));\n}\n\n#[test]\nfn test_no_suggestions_when_matched() {\n    let suggestions = generate_suggestions(\"api.openai.com\", \u0026RoutingDecision {\n        would_proxy: true,\n        ..\n    });\n    assert\\!(suggestions.is_empty());\n}\n```\n\n## Integration Tests (`tests/test_command.rs`)\n\n```rust\n#[test]\nfn test_command_with_proxied_domain() {\n    let output = Command::new(\"./target/debug/rust_proxy\")\n        .args([\"test\", \"https://api.openai.com\"])\n        .output()\n        .unwrap();\n    \n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    assert\\!(stdout.contains(\"WOULD BE PROXIED\") || stdout.contains(\"would_proxy\": true));\n}\n\n#[test]\nfn test_command_with_non_proxied_domain() {\n    let output = Command::new(\"./target/debug/rust_proxy\")\n        .args([\"test\", \"https://example.com\"])\n        .output()\n        .unwrap();\n    \n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    assert\\!(stdout.contains(\"WOULD NOT BE PROXIED\"));\n    assert\\!(stdout.contains(\"Suggestions\"));\n}\n\n#[test]\nfn test_command_json_output() {\n    let output = Command::new(\"./target/debug/rust_proxy\")\n        .args([\"test\", \"https://api.openai.com\", \"--json\"])\n        .output()\n        .unwrap();\n    \n    let json: serde_json::Value = serde_json::from_slice(\u0026output.stdout).unwrap();\n    assert\\!(json.get(\"would_proxy\").is_some());\n    assert\\!(json.get(\"domain\").is_some());\n}\n\n#[test]\nfn test_command_verbose_output() {\n    let output = Command::new(\"./target/debug/rust_proxy\")\n        .args([\"test\", \"https://api.openai.com\", \"-v\"])\n        .output()\n        .unwrap();\n    \n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    assert\\!(stdout.contains(\"[1/5]\"));  // Step indicators\n    assert\\!(stdout.contains(\"Parsing\"));\n}\n\n#[test]\nfn test_command_no_dns_mode() {\n    let output = Command::new(\"./target/debug/rust_proxy\")\n        .args([\"test\", \"https://api.openai.com\", \"--no-dns\"])\n        .output()\n        .unwrap();\n    \n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    // Should show config-based decision without IP info\n    assert\\!(\\!stdout.contains(\"Resolved IPs\") || stdout.contains(\"skipped\"));\n}\n\n#[test]\nfn test_command_invalid_domain() {\n    let output = Command::new(\"./target/debug/rust_proxy\")\n        .args([\"test\", \"https://definitely-not-real-domain-xyz.invalid\"])\n        .output()\n        .unwrap();\n    \n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    assert\\!(stdout.contains(\"DNS\") \u0026\u0026 (stdout.contains(\"FAILED\") || stdout.contains(\"failed\")));\n}\n```\n\n## E2E Test Script (`tests/e2e/test_command.sh`)\n\n```bash\n#\\!/bin/bash\nset -euo pipefail\n\necho \"=== E2E Test: rust_proxy test ===\"\n\nBIN=\"./target/release/rust_proxy\"\n\n# Test 1: Known proxied domain\necho \"[1/6] Testing known proxied domain...\"\nOUTPUT=$($BIN test https://api.openai.com)\nif echo \"$OUTPUT\" | grep -q \"WOULD BE PROXIED\"; then\n    echo \"✓ PASS: api.openai.com correctly identified as proxied\"\nelse\n    echo \"✗ FAIL: api.openai.com should be proxied\"\n    echo \"$OUTPUT\"\n    exit 1\nfi\n\n# Test 2: Known non-proxied domain\necho \"[2/6] Testing non-proxied domain...\"\nOUTPUT=$($BIN test https://example.com)\nif echo \"$OUTPUT\" | grep -q \"WOULD NOT BE PROXIED\"; then\n    echo \"✓ PASS: example.com correctly identified as not proxied\"\nelse\n    echo \"✗ FAIL: example.com should not be proxied\"\n    exit 1\nfi\n\n# Test 3: JSON output format\necho \"[3/6] Testing JSON output...\"\nOUTPUT=$($BIN test https://api.openai.com --json)\nif echo \"$OUTPUT\" | jq -e '.would_proxy' \u003e /dev/null 2\u003e\u00261; then\n    echo \"✓ PASS: JSON output is valid\"\nelse\n    echo \"✗ FAIL: JSON output should be valid JSON\"\n    exit 1\nfi\n\n# Test 4: Verbose mode\necho \"[4/6] Testing verbose mode...\"\nOUTPUT=$($BIN test https://api.openai.com -v)\nif echo \"$OUTPUT\" | grep -q \"\\[1/5\\]\"; then\n    echo \"✓ PASS: Verbose mode shows step indicators\"\nelse\n    echo \"✗ FAIL: Verbose mode should show steps\"\n    exit 1\nfi\n\n# Test 5: Domain-only input (no https://)\necho \"[5/6] Testing domain-only input...\"\nOUTPUT=$($BIN test api.anthropic.com)\nif echo \"$OUTPUT\" | grep -q \"Domain: api.anthropic.com\"; then\n    echo \"✓ PASS: Domain-only input works\"\nelse\n    echo \"✗ FAIL: Domain-only input should work\"\n    exit 1\nfi\n\n# Test 6: Provider range matching\necho \"[6/6] Testing provider range matching...\"\nOUTPUT=$($BIN test https://storage.googleapis.com -v)\nif echo \"$OUTPUT\" | grep -qi \"google\"; then\n    echo \"✓ PASS: Google Cloud storage matched by provider range\"\nelse\n    echo \"⚠ SKIP: Provider range matching may vary\"\nfi\n\necho \"=== All Tests Passed ===\"\n```\n\n## Test Coverage Requirements\n- URL parsing: all formats (full URL, domain only, with port, IP address)\n- Routing logic: all decision paths\n- Output formats: standard, JSON, verbose\n- Edge cases: DNS failure, no active proxy, daemon not running\n- Suggestions: verify actionable commands are shown","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T03:08:41.669279262-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:35:41.851415941-05:00","closed_at":"2026-01-18T04:35:41.851415941-05:00","close_reason":"Test command fully implemented and verified: URL parsing, DNS lookup, routing decision logic, output formatting (standard/JSON/verbose), all 55 tests passing","dependencies":[{"issue_id":"rust_proxy-0fx.4","depends_on_id":"rust_proxy-0fx","type":"parent-child","created_at":"2026-01-18T03:08:41.696932275-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-0sm","title":"Add metrics configuration options","description":"## Scope\n\nAdd configuration options for the Prometheus metrics endpoint.\n\n## Configuration Schema\n\nAdd to `Settings` struct in `config.rs`:\n\n```rust\npub struct Settings {\n    // ... existing fields ...\n\n    /// Enable Prometheus metrics endpoint (default: true)\n    #[serde(default = \"default_metrics_enabled\")]\n    pub metrics_enabled: bool,\n\n    /// Port for metrics HTTP server (default: 9090)\n    #[serde(default = \"default_metrics_port\")]\n    pub metrics_port: u16,\n\n    /// Path for metrics endpoint (default: \"/metrics\")\n    #[serde(default = \"default_metrics_path\")]\n    pub metrics_path: String,\n\n    /// Bind address for metrics server (default: \"0.0.0.0\")\n    #[serde(default = \"default_metrics_bind\")]\n    pub metrics_bind: String,\n}\n\nfn default_metrics_enabled() -\u003e bool { true }\nfn default_metrics_port() -\u003e u16 { 9090 }\nfn default_metrics_path() -\u003e String { \"/metrics\".to_string() }\nfn default_metrics_bind() -\u003e String { \"0.0.0.0\".to_string() }\n```\n\n## Example Config\n\n```toml\n[settings]\n# Prometheus metrics\nmetrics_enabled = true\nmetrics_port = 9090\nmetrics_path = \"/metrics\"\nmetrics_bind = \"127.0.0.1\"  # Bind to localhost only for security\n```\n\n## Validation\n\nAdd to `validation.rs` to check:\n- Port conflict (metrics_port != proxy_port)\n- Path starts with \"/\"\n- Valid bind address\n\n## Default Config Generation\n\nUpdate `init` command to include metrics config in generated file with comments.\n\n## Acceptance Criteria\n\n- New config fields with sensible defaults\n- Validation catches common errors\n- Init command generates config with metrics section\n- Existing configs without metrics fields continue to work (defaults apply)","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:07:00.183186453-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:07:00.183186453-05:00"}
{"id":"rust_proxy-0zp","title":"Prometheus metrics endpoint for production monitoring","description":"## Overview\n\nExpose a standard Prometheus metrics endpoint that emits metrics about proxy operations, health status, and performance. This is THE industry standard for infrastructure monitoring and is essential for any production deployment.\n\n## Why This Matters\n\nWithout Prometheus metrics, rust_proxy cannot be:\n- Monitored via Grafana dashboards\n- Integrated with alerting systems (PagerDuty, OpsGenie, AlertManager)\n- Correlated with other system metrics\n- Properly observed in production\n\nThis is table stakes for production-grade infrastructure software. Every serious tool (nginx, haproxy, envoy, etc.) exposes Prometheus metrics.\n\n## Metrics to Expose\n\n### Counters\n- `rust_proxy_requests_total{proxy, status}` - Total requests by proxy and success/failure\n- `rust_proxy_bytes_sent_total{proxy}` - Total bytes sent through each proxy\n- `rust_proxy_bytes_received_total{proxy}` - Total bytes received through each proxy\n- `rust_proxy_health_checks_total{proxy, result}` - Health check results\n- `rust_proxy_failovers_total{from, to}` - Failover events\n- `rust_proxy_connections_total{proxy}` - Total connections established\n\n### Gauges\n- `rust_proxy_active_connections{proxy}` - Current active connections\n- `rust_proxy_proxy_health{proxy}` - Health status (1=healthy, 0=unhealthy)\n- `rust_proxy_effective_proxy{proxy}` - Which proxy is currently effective (1 or 0)\n- `rust_proxy_targets_count` - Number of configured targets\n- `rust_proxy_proxies_count` - Number of configured proxies\n\n### Histograms\n- `rust_proxy_connection_duration_seconds{proxy}` - Connection duration distribution\n- `rust_proxy_health_check_latency_seconds{proxy}` - Health check latency distribution\n\n## Configuration\n\n```toml\n[settings]\n# Enable/disable metrics endpoint\nmetrics_enabled = true\n\n# Port for metrics HTTP server (separate from proxy port)\nmetrics_port = 9090\n\n# Path for metrics endpoint\nmetrics_path = \"/metrics\"\n\n# Optional: bind address (default: 0.0.0.0)\nmetrics_bind = \"127.0.0.1\"\n```\n\n## Implementation Approach\n\n1. Add `prometheus` crate for metric types and encoding\n2. Add lightweight HTTP server (axum or warp) for /metrics endpoint\n3. Define metric types in new `metrics.rs` module\n4. Instrument existing code paths (proxy.rs, health.rs)\n5. Spawn metrics server alongside daemon\n6. Add configuration options\n\n## Example Output\n\n```\n# HELP rust_proxy_requests_total Total proxy requests\n# TYPE rust_proxy_requests_total counter\nrust_proxy_requests_total{proxy=\"mesh-us\",status=\"success\"} 15234\nrust_proxy_requests_total{proxy=\"mesh-us\",status=\"failure\"} 23\n\n# HELP rust_proxy_proxy_health Proxy health status\n# TYPE rust_proxy_proxy_health gauge\nrust_proxy_proxy_health{proxy=\"mesh-us\"} 1\nrust_proxy_proxy_health{proxy=\"mesh-eu\"} 0\n```\n\n## Success Criteria\n\n- Metrics endpoint responds at configured port/path\n- All defined metrics are populated correctly\n- Prometheus can scrape the endpoint\n- Grafana dashboard can visualize the metrics\n- Minimal performance impact on proxy operations\n\n## Estimated Effort: 3-4 hours","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:05:20.914689894-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:05:20.914689894-05:00","dependencies":[{"issue_id":"rust_proxy-0zp","depends_on_id":"rust_proxy-s05","type":"blocks","created_at":"2026-01-18T15:07:40.446177886-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-0zp","depends_on_id":"rust_proxy-0sm","type":"blocks","created_at":"2026-01-18T15:08:11.808762023-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-166","title":"E2E tests for Load Balancing","description":"## E2E Tests for Load Balancing\n\n### Test Scenarios\n\n1. **Single Strategy (Default Behavior)**\n   ```rust\n   #[tokio::test]\n   async fn test_single_strategy_uses_active_proxy() {\n       let mut harness = TestHarness::with_config(r#\"\n           [settings]\n           load_balance_strategy = \"single\"\n           active = \"primary\"\n\n           [[proxies]]\n           id = \"primary\"\n           url = \"http://localhost:MOCK1_PORT\"\n\n           [[proxies]]\n           id = \"secondary\"\n           url = \"http://localhost:MOCK2_PORT\"\n       \"#).await;\n\n       let primary = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       let secondary = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       harness.start_daemon().await.unwrap();\n\n       // Make multiple requests through proxy\n       for _ in 0..10 {\n           make_request_through_proxy(\u0026harness).await;\n       }\n\n       // All requests should go to primary\n       assert_eq!(primary.request_count(), 10);\n       assert_eq!(secondary.request_count(), 0);\n   }\n   ```\n\n2. **Round-Robin Distribution**\n   ```rust\n   #[tokio::test]\n   async fn test_round_robin_distributes_evenly() {\n       let mut harness = TestHarness::with_config(r#\"\n           [settings]\n           load_balance_strategy = \"round_robin\"\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:MOCK1_PORT\"\n\n           [[proxies]]\n           id = \"proxy-b\"\n           url = \"http://localhost:MOCK2_PORT\"\n\n           [[proxies]]\n           id = \"proxy-c\"\n           url = \"http://localhost:MOCK3_PORT\"\n       \"#).await;\n\n       let mocks = harness.add_mock_proxies(3, MockBehavior::Healthy { latency_ms: 50 }).await;\n       harness.start_daemon().await.unwrap();\n\n       // Make 30 requests\n       for _ in 0..30 {\n           make_request_through_proxy(\u0026harness).await;\n       }\n\n       // Each should get ~10 requests\n       for mock in \u0026mocks {\n           let count = mock.request_count();\n           assert!(count \u003e= 8 \u0026\u0026 count \u003c= 12, \"Expected ~10 requests, got {}\", count);\n       }\n   }\n   ```\n\n3. **Least-Latency Selection**\n   ```rust\n   #[tokio::test]\n   async fn test_least_latency_prefers_fastest() {\n       let mut harness = TestHarness::with_config(r#\"\n           [settings]\n           load_balance_strategy = \"least_latency\"\n           health_check_interval_secs = 1\n\n           [[proxies]]\n           id = \"slow\"\n           url = \"http://localhost:MOCK1_PORT\"\n\n           [[proxies]]\n           id = \"fast\"\n           url = \"http://localhost:MOCK2_PORT\"\n       \"#).await;\n\n       let slow = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 200 }).await;\n       let fast = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 20 }).await;\n       harness.start_daemon().await.unwrap();\n\n       // Wait for health checks to establish latency\n       tokio::time::sleep(Duration::from_secs(5)).await;\n\n       // Make requests\n       for _ in 0..20 {\n           make_request_through_proxy(\u0026harness).await;\n       }\n\n       // Fast proxy should get most requests\n       assert!(fast.request_count() \u003e 15);\n   }\n   ```\n\n4. **Weighted Distribution**\n   ```rust\n   #[tokio::test]\n   async fn test_weighted_respects_weights() {\n       let mut harness = TestHarness::with_config(r#\"\n           [settings]\n           load_balance_strategy = \"weighted\"\n\n           [[proxies]]\n           id = \"heavy\"\n           url = \"http://localhost:MOCK1_PORT\"\n           weight = 80\n\n           [[proxies]]\n           id = \"light\"\n           url = \"http://localhost:MOCK2_PORT\"\n           weight = 20\n       \"#).await;\n\n       let heavy = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       let light = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       harness.start_daemon().await.unwrap();\n\n       // Make 100 requests\n       for _ in 0..100 {\n           make_request_through_proxy(\u0026harness).await;\n       }\n\n       // Heavy should get ~80, light ~20 (with tolerance)\n       assert!(heavy.request_count() \u003e 60 \u0026\u0026 heavy.request_count() \u003c 95);\n       assert!(light.request_count() \u003e 5 \u0026\u0026 light.request_count() \u003c 40);\n   }\n   ```\n\n5. **Status Command Shows Load Balancing Info**\n   ```rust\n   #[tokio::test]\n   async fn test_status_shows_load_balancing() {\n       let harness = lb_test_harness(\"round_robin\").await;\n       let output = harness.run_command(\u0026[\"status\"]);\n\n       assert!(output.stdout.contains(\"Load Balancing: round_robin\"));\n   }\n   ```\n\n### Logging Requirements\n- Log each request routing decision\n- Log proxy selection with strategy context\n- Log request counts per proxy at end of test\n- On failure, dump full mock proxy request logs\n\n### Dependencies\n- Requires: rust_proxy-cux (E2E Test Infrastructure)","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:53:59.650939449-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:53:59.650939449-05:00","dependencies":[{"issue_id":"rust_proxy-166","depends_on_id":"rust_proxy-cux","type":"blocks","created_at":"2026-01-18T14:56:35.745704376-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-166","depends_on_id":"rust_proxy-xw7","type":"blocks","created_at":"2026-01-18T14:56:49.768984987-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-1g6","title":"Implement fail_closed degradation policy","description":"## Scope\n\nImplement the fail_closed degradation policy that immediately rejects connections when no healthy proxy is available.\n\n## Rationale\n\nThis is the safest default - if no proxy is healthy, it's better to reject the connection than to potentially leak traffic or behave unpredictably.\n\n## Implementation Details\n\n```rust\npub async fn apply_fail_closed_policy() -\u003e Result\u003c()\u003e {\n    tracing::warn!(\"Connection rejected: no healthy proxies available (fail_closed policy)\");\n    Err(anyhow::anyhow!(\"No healthy proxies available\"))\n}\n```\n\n### Integration Point\n\nIn the connection handler:\n\n```rust\nasync fn handle_connection(stream: TcpStream, ...) {\n    let proxy_id = load_balancer.select_proxy(...).await;\n\n    let proxy_id = match proxy_id {\n        Some(id) =\u003e id,\n        None =\u003e {\n            // No healthy proxy - apply degradation policy\n            match config.settings.degradation_policy {\n                DegradationPolicy::FailClosed =\u003e {\n                    apply_fail_closed_policy().await;\n                    return;\n                }\n                // ... other policies\n            }\n        }\n    };\n    // ... continue with connection\n}\n```\n\n### Error Response\n\nFor HTTP CONNECT requests, send proper error response before closing:\n\n```rust\nasync fn send_degradation_error(stream: \u0026mut TcpStream) -\u003e Result\u003c()\u003e {\n    let response = \"HTTP/1.1 503 Service Unavailable\\r\\n\\\n                    Content-Type: text/plain\\r\\n\\\n                    Connection: close\\r\\n\\\n                    \\r\\n\\\n                    No healthy proxy available\";\n    stream.write_all(response.as_bytes()).await?;\n    Ok(())\n}\n```\n\n## Acceptance Criteria\n\n- Connections rejected when no healthy proxy and policy is fail_closed\n- Clear log message indicating rejection reason\n- Proper HTTP 503 response for HTTP clients\n- No connection attempts made when rejecting","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:04:52.236426582-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:04:52.236426582-05:00","dependencies":[{"issue_id":"rust_proxy-1g6","depends_on_id":"rust_proxy-ny9","type":"blocks","created_at":"2026-01-18T14:07:30.931066168-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-1yw","title":"Add health check target validation","description":"Add rp check --validate-health-target that tests the configured health check target actually works. Warn if target appears unreachable through any proxy.","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:16:38.806110887-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:16:38.806110887-05:00","dependencies":[{"issue_id":"rust_proxy-1yw","depends_on_id":"rust_proxy-78m","type":"blocks","created_at":"2026-01-18T14:16:54.772361431-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-28m","title":"Add shell detection logic","description":"## Scope\n\nImplement logic to detect the user's current shell (bash, zsh, fish) for automatic completion installation.\n\n## Implementation Details\n\n### Detection Strategy\n\nMultiple fallback methods for robustness:\n\n```rust\n#[derive(Debug, Clone, Copy, PartialEq)]\npub enum Shell {\n    Bash,\n    Zsh,\n    Fish,\n    Unknown,\n}\n\npub fn detect_shell() -\u003e Shell {\n    // Method 1: Check $SHELL environment variable\n    if let Ok(shell) = std::env::var(\"SHELL\") {\n        if shell.ends_with(\"/bash\") || shell.ends_with(\"/bash.exe\") {\n            return Shell::Bash;\n        }\n        if shell.ends_with(\"/zsh\") {\n            return Shell::Zsh;\n        }\n        if shell.ends_with(\"/fish\") {\n            return Shell::Fish;\n        }\n    }\n\n    // Method 2: Check parent process name (Linux)\n    #[cfg(target_os = \"linux\")]\n    if let Some(shell) = detect_from_parent_process() {\n        return shell;\n    }\n\n    // Method 3: Check common shell rc files\n    let home = dirs::home_dir();\n    if let Some(home) = home {\n        if home.join(\".zshrc\").exists() {\n            return Shell::Zsh;\n        }\n        if home.join(\".bashrc\").exists() {\n            return Shell::Bash;\n        }\n        if home.join(\".config/fish/config.fish\").exists() {\n            return Shell::Fish;\n        }\n    }\n\n    Shell::Unknown\n}\n\n#[cfg(target_os = \"linux\")]\nfn detect_from_parent_process() -\u003e Option\u003cShell\u003e {\n    let ppid = std::process::id();\n    let cmdline = std::fs::read_to_string(format!(\"/proc/{}/comm\", ppid)).ok()?;\n    let name = cmdline.trim();\n\n    match name {\n        \"bash\" =\u003e Some(Shell::Bash),\n        \"zsh\" =\u003e Some(Shell::Zsh),\n        \"fish\" =\u003e Some(Shell::Fish),\n        _ =\u003e None,\n    }\n}\n```\n\n### Shell Display Names\n\n```rust\nimpl Shell {\n    pub fn name(\u0026self) -\u003e \u0026'static str {\n        match self {\n            Shell::Bash =\u003e \"bash\",\n            Shell::Zsh =\u003e \"zsh\",\n            Shell::Fish =\u003e \"fish\",\n            Shell::Unknown =\u003e \"unknown\",\n        }\n    }\n}\n```\n\n## Acceptance Criteria\n\n- Detects bash, zsh, fish correctly\n- Falls back through multiple detection methods\n- Returns Unknown rather than guessing wrong\n- Works on Linux and macOS","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:58:08.91667934-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:58:08.91667934-05:00"}
{"id":"rust_proxy-2jn","title":"E2E tests for Network Diagnostics","description":"## E2E Tests for Network Diagnostics\n\n### Test Scenarios\n\n1. **Doctor Command Basic Output**\n   ```rust\n   #[tokio::test]\n   async fn test_doctor_runs_all_checks() {\n       let harness = TestHarness::new().await;\n\n       let result = harness.run_command(\u0026[\"doctor\"]);\n\n       assert!(result.success || result.exit_code == 1); // May have issues\n       assert!(result.stdout.contains(\"Checking configuration\"));\n       assert!(result.stdout.contains(\"Checking proxy connectivity\"));\n       assert!(result.stdout.contains(\"Checking state directory\"));\n   }\n   ```\n\n2. **Doctor Shows Proxy Health**\n   ```rust\n   #[tokio::test]\n   async fn test_doctor_shows_proxy_status() {\n       let mut harness = TestHarness::new().await;\n       let healthy = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       let failing = harness.add_mock_proxy(MockBehavior::Failing {\n           error: MockError::ConnectionRefused\n       }).await;\n\n       let result = harness.run_command(\u0026[\"doctor\"]);\n\n       assert!(result.stdout.contains(\"OK\") || result.stdout.contains(\"✓\"));\n       assert!(result.stdout.contains(\"FAIL\") || result.stdout.contains(\"✗\"));\n   }\n   ```\n\n3. **Doctor JSON Output**\n   ```rust\n   #[tokio::test]\n   async fn test_doctor_json_output() {\n       let harness = TestHarness::new().await;\n\n       let result = harness.run_command(\u0026[\"doctor\", \"--json\"]);\n\n       assert!(result.success || result.exit_code == 1);\n       let json: Value = serde_json::from_str(\u0026result.stdout).unwrap();\n       assert!(json[\"checks\"].is_array());\n       assert!(json[\"summary\"].is_object());\n   }\n   ```\n\n4. **Doctor Summary Shows Issue Count**\n   ```rust\n   #[tokio::test]\n   async fn test_doctor_summary() {\n       let mut harness = TestHarness::new().await;\n       harness.add_mock_proxy(MockBehavior::Failing {\n           error: MockError::ConnectionRefused\n       }).await;\n\n       let result = harness.run_command(\u0026[\"doctor\"]);\n\n       assert!(result.stdout.contains(\"issue\") ||\n               result.stdout.contains(\"problem\"));\n   }\n   ```\n\n5. **Ping Command Basic**\n   ```rust\n   #[tokio::test]\n   async fn test_ping_proxy() {\n       let mut harness = TestHarness::new().await;\n       let mock = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n\n       let result = harness.run_command(\u0026[\"ping\", \u0026mock.id]);\n\n       assert!(result.success);\n       assert!(result.stdout.contains(\"PING\"));\n       assert!(result.stdout.contains(\"time=\"));\n   }\n   ```\n\n6. **Ping Shows Statistics**\n   ```rust\n   #[tokio::test]\n   async fn test_ping_shows_statistics() {\n       let mut harness = TestHarness::new().await;\n       let mock = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n\n       let result = harness.run_command(\u0026[\"ping\", \u0026mock.id, \"-c\", \"5\"]);\n\n       assert!(result.stdout.contains(\"min/avg/max\"));\n       assert!(result.stdout.contains(\"loss\"));\n   }\n   ```\n\n7. **Ping Unknown Proxy Fails**\n   ```rust\n   #[tokio::test]\n   async fn test_ping_unknown_proxy() {\n       let harness = TestHarness::new().await;\n\n       let result = harness.run_command(\u0026[\"ping\", \"nonexistent-proxy\"]);\n\n       assert!(!result.success);\n       assert!(result.stderr.contains(\"not found\") ||\n               result.stderr.contains(\"unknown\"));\n   }\n   ```\n\n8. **Trace Command Shows Flow**\n   ```rust\n   #[tokio::test]\n   async fn test_trace_shows_connection_flow() {\n       let mut harness = TestHarness::new().await;\n       harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       harness.start_daemon().await.unwrap();\n\n       let result = harness.run_command(\u0026[\"trace\", \"https://example.com\"]);\n\n       assert!(result.stdout.contains(\"Resolving\"));\n       assert!(result.stdout.contains(\"Connecting to proxy\"));\n       assert!(result.stdout.contains(\"CONNECT\"));\n   }\n   ```\n\n9. **Trace Shows Failure Point**\n   ```rust\n   #[tokio::test]\n   async fn test_trace_shows_failure_point() {\n       let mut harness = TestHarness::new().await;\n       harness.add_mock_proxy(MockBehavior::Failing {\n           error: MockError::ConnectionRefused\n       }).await;\n       harness.start_daemon().await.unwrap();\n\n       let result = harness.run_command(\u0026[\"trace\", \"https://example.com\"]);\n\n       assert!(result.stdout.contains(\"FAIL\") || result.stdout.contains(\"Error\"));\n       // Should identify where the failure occurred\n   }\n   ```\n\n10. **Trace JSON Output**\n    ```rust\n    #[tokio::test]\n    async fn test_trace_json_output() {\n        let harness = TestHarness::new().await;\n        harness.start_daemon().await.unwrap();\n\n        let result = harness.run_command(\u0026[\"trace\", \"https://example.com\", \"--json\"]);\n\n        let json: Value = serde_json::from_str(\u0026result.stdout).unwrap();\n        assert!(json[\"steps\"].is_array());\n        assert!(json[\"total_time_ms\"].is_number());\n    }\n    ```\n\n### Logging Requirements\n- Log each diagnostic check being run\n- Log network operations with timing\n- Log failure details with context\n- On assertion failure, dump full command output\n\n### Dependencies\n- Requires: rust_proxy-cux (E2E Test Infrastructure)","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:28.924703036-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:28.924703036-05:00","dependencies":[{"issue_id":"rust_proxy-2jn","depends_on_id":"rust_proxy-cux","type":"blocks","created_at":"2026-01-18T14:56:37.205750182-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-2jn","depends_on_id":"rust_proxy-o4n","type":"blocks","created_at":"2026-01-18T14:56:55.035941804-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-2ni","title":"Add unit tests for util.rs and config.rs","status":"closed","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-17T23:23:56.207640936-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-17T23:25:56.839254024-05:00","closed_at":"2026-01-17T23:25:56.839254024-05:00","close_reason":"Added 35 unit tests for util.rs and config.rs"}
{"id":"rust_proxy-2tt","title":"Integrate rich errors throughout codebase","description":"Replace anyhow::bail\\! with typed errors where appropriate. Ensure all user-facing error paths produce helpful messages with context and suggestions.","status":"closed","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:15:40.27582016-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:19:33.946096725-05:00","closed_at":"2026-01-18T15:19:33.946096725-05:00","close_reason":"Closed","dependencies":[{"issue_id":"rust_proxy-2tt","depends_on_id":"rust_proxy-ous","type":"blocks","created_at":"2026-01-18T14:15:56.219548841-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-3p5","title":"Implement dry-run for stop command","description":"Add --dry-run to stop command. Show: Would stop daemon (PID 12345), Would remove PID file, Would close N active connections.","status":"closed","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:14:46.505920022-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:19:33.930437347-05:00","closed_at":"2026-01-18T15:19:33.930437347-05:00","close_reason":"Closed","dependencies":[{"issue_id":"rust_proxy-3p5","depends_on_id":"rust_proxy-ar9","type":"blocks","created_at":"2026-01-18T14:15:02.738027323-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-3q7","title":"Add SIGHUP handler for manual reload trigger","description":"## Scope\n\nAdd a SIGHUP signal handler that triggers config reload, following Unix conventions used by nginx, HAProxy, and other production services.\n\n## Rationale\n\nSIGHUP-triggered reload is the standard Unix pattern for daemon reconfiguration. Users familiar with other services will expect `kill -HUP \u003cpid\u003e` to reload config. This also enables integration with systemd's `systemctl reload` mechanism.\n\n## Implementation Details\n\n### Signal Handler Setup\n\n```rust\nuse tokio::signal::unix::{signal, SignalKind};\n\nasync fn setup_sighup_handler(config_holder: Arc\u003cConfigHolder\u003e) {\n    let mut sighup = signal(SignalKind::hangup())\n        .expect(\"Failed to register SIGHUP handler\");\n\n    tokio::spawn(async move {\n        loop {\n            sighup.recv().await;\n            tracing::info!(\"Received SIGHUP, reloading configuration\");\n\n            match config_holder.reload().await {\n                Ok(Some(diff)) =\u003e {\n                    tracing::info!(\n                        added = diff.proxies_added.len(),\n                        removed = diff.proxies_removed.len(),\n                        settings = diff.settings_changed.len(),\n                        \"Configuration reloaded\"\n                    );\n                }\n                Ok(None) =\u003e {\n                    tracing::info!(\"Configuration unchanged\");\n                }\n                Err(e) =\u003e {\n                    tracing::error!(error = %e, \"Failed to reload configuration\");\n                }\n            }\n        }\n    });\n}\n```\n\n### Platform Considerations\n\nSIGHUP is Unix-only. On Windows, we'd need a different mechanism (named pipe, file trigger, etc.). For now, conditionally compile:\n\n```rust\n#[cfg(unix)]\nasync fn setup_signal_handlers(config_holder: Arc\u003cConfigHolder\u003e) {\n    setup_sighup_handler(config_holder).await;\n}\n\n#[cfg(not(unix))]\nasync fn setup_signal_handlers(_config_holder: Arc\u003cConfigHolder\u003e) {\n    // No-op on Windows for now\n    tracing::debug!(\"SIGHUP handler not available on this platform\");\n}\n```\n\n### Integration with Daemon Startup\n\nCall `setup_signal_handlers()` early in `run_daemon()`:\n\n```rust\npub async fn run_daemon() -\u003e Result\u003c()\u003e {\n    let config_holder = Arc::new(ConfigHolder::new(config, config_path));\n\n    setup_signal_handlers(config_holder.clone()).await;\n\n    // ... rest of daemon startup\n}\n```\n\n## Acceptance Criteria\n\n- SIGHUP triggers config reload on Unix systems\n- Handler logs success/failure clearly\n- Graceful no-op on non-Unix platforms\n- Multiple rapid SIGHUPs handled correctly (not queued up)","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:56:08.480076867-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:56:08.480076867-05:00","dependencies":[{"issue_id":"rust_proxy-3q7","depends_on_id":"rust_proxy-7or","type":"blocks","created_at":"2026-01-18T13:57:06.937533371-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-46g","title":"E2E tests for Customizable Health Check","description":"## E2E Tests for Customizable Health Check\n\n### Test Scenarios\n\n1. **Custom CONNECT Target**\n   ```rust\n   #[tokio::test]\n   async fn test_custom_connect_target() {\n       let mut harness = TestHarness::new().await;\n\n       // Start mock HTTP server to be the health check target\n       let target_server = harness.start_mock_server().await;\n\n       let config = format!(r#\"\n           [settings]\n           health_check_target = \"CONNECT 127.0.0.1:{}\"\n           health_check_interval_secs = 1\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:MOCK_PROXY_PORT\"\n       \"#, target_server.port());\n\n       harness.set_config(\u0026config).await;\n       let mock_proxy = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       harness.start_daemon().await.unwrap();\n\n       tokio::time::sleep(Duration::from_secs(3)).await;\n\n       let status = harness.run_command(\u0026[\"status\", \"--json\"]);\n       let json: Value = serde_json::from_str(\u0026status.stdout).unwrap();\n\n       // Health check should use custom target\n       assert_eq!(json[\"proxies\"][\"proxy-a\"][\"health\"], \"healthy\");\n   }\n   ```\n\n2. **Custom GET Target**\n   ```rust\n   #[tokio::test]\n   async fn test_custom_get_target() {\n       let mut harness = TestHarness::new().await;\n\n       // Mock HTTP health endpoint\n       let health_server = harness.start_mock_http_server(|req| {\n           if req.uri().path() == \"/health\" {\n               Response::builder().status(200).body(\"OK\".into()).unwrap()\n           } else {\n               Response::builder().status(404).body(\"Not Found\".into()).unwrap()\n           }\n       }).await;\n\n       let config = format!(r#\"\n           [settings]\n           health_check_target = \"GET http://127.0.0.1:{}/health\"\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:MOCK_PORT\"\n       \"#, health_server.port());\n\n       harness.set_config(\u0026config).await;\n       harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       harness.start_daemon().await.unwrap();\n\n       tokio::time::sleep(Duration::from_secs(3)).await;\n\n       // Verify health checks hit the custom endpoint\n       assert!(health_server.request_count() \u003e 0);\n   }\n   ```\n\n3. **Invalid Target Fails Validation**\n   ```rust\n   #[tokio::test]\n   async fn test_invalid_target_validation() {\n       let harness = TestHarness::with_config(r#\"\n           [settings]\n           health_check_target = \"CONNECT unresolvable.invalid.hostname.test:443\"\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:8080\"\n       \"#).await;\n\n       let result = harness.run_command(\u0026[\"check\"]);\n\n       // Should warn about unresolvable target\n       assert!(result.stderr.contains(\"resolve\") ||\n               result.stderr.contains(\"DNS\") ||\n               result.stdout.contains(\"warning\"));\n   }\n   ```\n\n4. **Per-Proxy Custom Target**\n   ```rust\n   #[tokio::test]\n   async fn test_per_proxy_target() {\n       let mut harness = TestHarness::new().await;\n\n       let target_a = harness.start_mock_tcp_server().await;\n       let target_b = harness.start_mock_tcp_server().await;\n\n       let config = format!(r#\"\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:MOCK1_PORT\"\n           health_check_target = \"CONNECT 127.0.0.1:{}\"\n\n           [[proxies]]\n           id = \"proxy-b\"\n           url = \"http://localhost:MOCK2_PORT\"\n           health_check_target = \"CONNECT 127.0.0.1:{}\"\n       \"#, target_a.port(), target_b.port());\n\n       harness.set_config(\u0026config).await;\n       harness.add_mock_proxies(2, MockBehavior::Healthy { latency_ms: 50 }).await;\n       harness.start_daemon().await.unwrap();\n\n       tokio::time::sleep(Duration::from_secs(5)).await;\n\n       // Both targets should have been contacted\n       assert!(target_a.connection_count() \u003e 0);\n       assert!(target_b.connection_count() \u003e 0);\n   }\n   ```\n\n5. **Target Unreachable Marks Unhealthy**\n   ```rust\n   #[tokio::test]\n   async fn test_unreachable_target_marks_unhealthy() {\n       let harness = TestHarness::with_config(r#\"\n           [settings]\n           health_check_target = \"CONNECT 127.0.0.1:59999\"  # Nothing listening\n           consecutive_failures_threshold = 1\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:MOCK_PORT\"\n       \"#).await;\n\n       let mock_proxy = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       harness.start_daemon().await.unwrap();\n\n       tokio::time::sleep(Duration::from_secs(5)).await;\n\n       let status = harness.run_command(\u0026[\"status\", \"--json\"]);\n       let json: Value = serde_json::from_str(\u0026status.stdout).unwrap();\n\n       // Should be unhealthy because target is unreachable\n       assert_eq!(json[\"proxies\"][\"proxy-a\"][\"health\"], \"unhealthy\");\n   }\n   ```\n\n6. **Status Shows Health Check Target**\n   ```rust\n   #[tokio::test]\n   async fn test_status_shows_target() {\n       let harness = TestHarness::with_config(r#\"\n           [settings]\n           health_check_target = \"CONNECT custom.target.example:443\"\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:8080\"\n       \"#).await;\n\n       let result = harness.run_command(\u0026[\"status\", \"-v\"]);  // verbose\n\n       assert!(result.stdout.contains(\"custom.target.example\") ||\n               result.stdout.contains(\"health_check_target\"));\n   }\n   ```\n\n7. **HEAD Method Works**\n   ```rust\n   #[tokio::test]\n   async fn test_head_method_health_check() {\n       let mut harness = TestHarness::new().await;\n\n       let health_server = harness.start_mock_http_server(|req| {\n           if req.method() == \"HEAD\" {\n               Response::builder().status(200).body(\"\".into()).unwrap()\n           } else {\n               Response::builder().status(405).body(\"Method Not Allowed\".into()).unwrap()\n           }\n       }).await;\n\n       let config = format!(r#\"\n           [settings]\n           health_check_target = \"HEAD http://127.0.0.1:{}\"\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:MOCK_PORT\"\n       \"#, health_server.port());\n\n       harness.set_config(\u0026config).await;\n       harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       harness.start_daemon().await.unwrap();\n\n       tokio::time::sleep(Duration::from_secs(3)).await;\n\n       assert!(health_server.request_count() \u003e 0);\n   }\n   ```\n\n### Logging Requirements\n- Log health check target being used for each check\n- Log target validation results\n- Log custom target configuration at startup\n- On failure, log which target failed and why\n\n### Dependencies\n- Requires: rust_proxy-cux (E2E Test Infrastructure)","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:44.447107556-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:44.447107556-05:00","dependencies":[{"issue_id":"rust_proxy-46g","depends_on_id":"rust_proxy-cux","type":"blocks","created_at":"2026-01-18T14:56:37.350121807-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-46g","depends_on_id":"rust_proxy-wl1","type":"blocks","created_at":"2026-01-18T14:56:57.583190901-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-49q","title":"Add connection retry with exponential backoff for upstream proxy","status":"closed","priority":3,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T00:30:11.088754166-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:08:29.998777982-05:00","closed_at":"2026-01-18T01:08:29.998777982-05:00","close_reason":"Completed: added exponential backoff retry for upstream proxy connections"}
{"id":"rust_proxy-4ce","title":"Implement 'rust_proxy check' configuration validation command","description":"## Overview\n\nAdd a `rust_proxy check` command that validates configuration without side effects, similar to `nginx -t`. This provides users with a safe way to verify their configuration before running the daemon, catch errors early, and enable CI/CD validation.\n\n## Background \u0026 Motivation\n\n**Current Problems:**\n- Users discover configuration errors only when running the daemon\n- Typos in proxy URLs cause cryptic runtime failures\n- Missing environment variables for credentials fail at connect time\n- Invalid target domains aren't caught until DNS resolution\n- No way to validate config changes before deploying\n\n**What `rust_proxy check` Provides:**\n1. **Pre-flight validation**: Catch errors before they cause production issues\n2. **CI/CD integration**: Validate configuration in pipelines\n3. **Clear feedback**: Actionable error messages with suggestions\n4. **Confidence**: Users know their setup is correct before running daemon\n\n## CLI Interface\n\n```\nrust_proxy check [OPTIONS]\n\nOPTIONS:\n    --strict              Treat warnings as errors (exit code 2)\n    --json                Output validation results as JSON\n    --quiet               Only output errors (no success messages)\n    --test-connectivity   Actually test proxy connectivity (slower, requires network)\n```\n\n## Validation Categories\n\n### 1. File \u0026 Permission Validation\n- Config file exists and is readable\n- Config file is valid TOML syntax\n- State directory is writable (for daemon)\n- Warn if config has insecure permissions (world-readable with plaintext passwords)\n\n### 2. Proxy Validation\n- URL format: must be http:// or https://\n- Host must be present and valid\n- Port must be specified and in range 1-65535\n- Auth validation:\n  - If `username`/`password`: warn about plaintext credentials\n  - If `username_env`/`password_env`: verify env vars exist AND are non-empty\n- No duplicate proxy IDs\n- Optional: --test-connectivity performs actual TCP connect + CONNECT handshake\n\n### 3. Target Validation\n- Domain format: no protocol prefix, no path component, valid hostname chars\n- Provider hint: must be recognized provider (anthropic, openai, google, aws, cloudflare, vercel, supabase) or empty\n- No duplicate domains\n- Warn if domain looks like URL (`http://` or `/` present)\n\n### 4. Settings Validation\n| Setting | Valid Range | Warning Threshold |\n|---------|-------------|-------------------|\n| listen_port | 1024-65535 | \u003c1024 (requires root) |\n| dns_refresh_secs | 1-86400 | \u003c60 (too frequent) |\n| ping_interval_secs | 1-3600 | \u003c10 (too frequent) |\n| ping_timeout_ms | 1-60000 | \u003e= ping_interval_secs×1000 |\n| ipset_name | 1-31 chars, [a-zA-Z0-9_] | n/a |\n| chain_name | 1-28 chars, [a-zA-Z0-9_] | n/a |\n| connect_max_retries | 0-100 | n/a |\n| connect_initial_backoff_ms | 1-60000 | n/a |\n| connect_max_backoff_ms | \u003e= initial | n/a |\n\n### 5. Active Proxy Validation\n- If set: must reference a defined proxy ID\n- If set: referenced proxy should pass its own validation\n- If not set: warning (no proxy will be used)\n\n### 6. Cross-Reference Validation\n- Warn if all defined proxies have errors\n- Warn if no targets configured (proxy won't route anything)\n\n## Output Formats\n\n### Standard Output (Success)\n```\nrust_proxy check\n\nConfiguration: /home/user/.config/rust_proxy/config.toml\n✓ File readable, valid TOML syntax\n✓ State directory writable\n\nProxies (2 defined):\n✓ mesh-us: http://us-wa.proxymesh.com:31280 (auth: env vars)\n✓ mesh-eu: http://eu.proxymesh.com:31280 (auth: env vars)\n\nActive Proxy:\n✓ mesh-us (defined and valid)\n\nTargets:\n✓ 87 domains configured\n✓ Provider hints valid\n\nSettings:\n✓ All settings within valid ranges\n\nConfiguration valid.\n```\n\n### Standard Output (Errors)\n```\nrust_proxy check\n\nConfiguration: /home/user/.config/rust_proxy/config.toml\n✓ File readable, valid TOML syntax\n✓ State directory writable\n\nProxies (2 defined):\n✗ mesh-us: PROXY_PASS environment variable not set\n  → Set PROXY_PASS or use --password flag when adding proxy\n⚠ mesh-eu: using plaintext credentials\n  → Consider using --username-env/--password-env for security\n\nActive Proxy:\n✗ mesh-us references proxy with validation errors\n\nTargets:\n✗ \"https://api.openai.com\": remove protocol prefix (use \"api.openai.com\")\n✗ \"example.com/v1\": domains should not include paths\n\nSettings:\n✗ ping_timeout_ms (65000) must be less than ping_interval_secs × 1000 (60000)\n⚠ dns_refresh_secs (30) is very frequent, consider \u003e= 60\n\nConfiguration invalid: 4 errors, 2 warnings\n```\n\n### JSON Output\n```json\n{\n  \"valid\": false,\n  \"config_path\": \"/home/user/.config/rust_proxy/config.toml\",\n  \"errors\": [\n    {\n      \"category\": \"proxy\",\n      \"id\": \"mesh-us\",\n      \"message\": \"PROXY_PASS environment variable not set\",\n      \"suggestion\": \"Set PROXY_PASS or use --password flag when adding proxy\"\n    }\n  ],\n  \"warnings\": [\n    {\n      \"category\": \"proxy\",\n      \"id\": \"mesh-eu\",\n      \"message\": \"using plaintext credentials\",\n      \"suggestion\": \"Consider using --username-env/--password-env for security\"\n    }\n  ],\n  \"summary\": {\n    \"proxies_valid\": 1,\n    \"proxies_invalid\": 1,\n    \"targets_valid\": 85,\n    \"targets_invalid\": 2\n  }\n}\n```\n\n## Exit Codes\n\n| Code | Meaning |\n|------|---------|\n| 0 | Configuration valid (no errors, may have warnings) |\n| 1 | Configuration has errors |\n| 2 | Configuration has warnings (only with --strict) |\n| 3 | Configuration file not found or unreadable |\n\n## Code Structure\n\n### New Module: `src/validation.rs`\n```rust\npub enum ValidationSeverity {\n    Error,\n    Warning,\n    Info,\n}\n\npub struct ValidationResult {\n    pub severity: ValidationSeverity,\n    pub category: \u0026'static str,  // \"file\", \"proxy\", \"target\", \"settings\", \"active\"\n    pub id: Option\u003cString\u003e,       // proxy id, domain, setting name\n    pub message: String,\n    pub suggestion: Option\u003cString\u003e,\n}\n\npub struct ValidationReport {\n    pub config_path: PathBuf,\n    pub results: Vec\u003cValidationResult\u003e,\n}\n\nimpl ValidationReport {\n    pub fn has_errors(\u0026self) -\u003e bool;\n    pub fn has_warnings(\u0026self) -\u003e bool;\n    pub fn error_count(\u0026self) -\u003e usize;\n    pub fn warning_count(\u0026self) -\u003e usize;\n}\n\n// Main entry point\npub fn validate_config(config: \u0026Config, options: \u0026CheckOptions) -\u003e ValidationReport;\n\n// Individual validators (for reuse)\npub fn validate_file_access(path: \u0026Path) -\u003e Vec\u003cValidationResult\u003e;\npub fn validate_proxies(proxies: \u0026[ProxyDef]) -\u003e Vec\u003cValidationResult\u003e;\npub fn validate_targets(targets: \u0026[Target]) -\u003e Vec\u003cValidationResult\u003e;\npub fn validate_settings(settings: \u0026Settings) -\u003e Vec\u003cValidationResult\u003e;\npub fn validate_active_proxy(active: Option\u003c\u0026str\u003e, proxies: \u0026[ProxyDef]) -\u003e Vec\u003cValidationResult\u003e;\n```\n\n## File Changes Summary\n\n| File | Change |\n|------|--------|\n| `src/validation.rs` | New module with all validation logic |\n| `src/main.rs` | Add `check` subcommand and handler |\n| `src/main.rs` | Add `mod validation;` |\n\n## Testing Requirements\n\nSee dedicated subtasks for per-validator unit tests.\n\n### Integration Test (`tests/check_command.rs`)\n```rust\n#[test]\nfn test_check_valid_config() {\n    let output = Command::new(\"./target/debug/rust_proxy\")\n        .args([\"check\"])\n        .env(\"PROXY_USER\", \"test\")\n        .env(\"PROXY_PASS\", \"test\")\n        .output()\n        .unwrap();\n    assert!(output.status.success());\n    assert!(String::from_utf8_lossy(\u0026output.stdout).contains(\"Configuration valid\"));\n}\n\n#[test]\nfn test_check_missing_env_var() {\n    let output = Command::new(\"./target/debug/rust_proxy\")\n        .args([\"check\"])\n        .env_remove(\"PROXY_PASS\")\n        .output()\n        .unwrap();\n    assert_eq!(output.status.code(), Some(1));\n    assert!(String::from_utf8_lossy(\u0026output.stdout).contains(\"not set\"));\n}\n\n#[test]\nfn test_check_json_output() {\n    let output = Command::new(\"./target/debug/rust_proxy\")\n        .args([\"check\", \"--json\"])\n        .output()\n        .unwrap();\n    let json: serde_json::Value = serde_json::from_slice(\u0026output.stdout).unwrap();\n    assert!(json.get(\"valid\").is_some());\n}\n\n#[test]\nfn test_check_strict_mode() {\n    // With warnings present and --strict, should exit 2\n}\n```\n\n### E2E Test Script (`tests/e2e/check_command.sh`)\n```bash\n#!/bin/bash\nset -euo pipefail\n\necho \"=== E2E Test: rust_proxy check ===\"\n\n# Setup\nexport PROXY_USER=\"testuser\"\nexport PROXY_PASS=\"testpass\"\nCONFIG_DIR=\"$HOME/.config/rust_proxy\"\nCONFIG_FILE=\"$CONFIG_DIR/config.toml\"\n\n# Test 1: Valid config\necho \"[1/5] Testing valid configuration...\"\n./target/release/rust_proxy check\nif [ $? -eq 0 ]; then\n    echo \"✓ PASS: Valid config returns exit code 0\"\nelse\n    echo \"✗ FAIL: Valid config should return exit code 0\"\n    exit 1\nfi\n\n# Test 2: Missing env var\necho \"[2/5] Testing missing environment variable...\"\nunset PROXY_PASS\n./target/release/rust_proxy check 2\u003e\u00261 || EXIT_CODE=$?\nif [ \"${EXIT_CODE:-0}\" -eq 1 ]; then\n    echo \"✓ PASS: Missing env var returns exit code 1\"\nelse\n    echo \"✗ FAIL: Missing env var should return exit code 1\"\n    exit 1\nfi\nexport PROXY_PASS=\"testpass\"\n\n# Test 3: JSON output\necho \"[3/5] Testing JSON output...\"\n./target/release/rust_proxy check --json | jq -e '.valid' \u003e /dev/null\nif [ $? -eq 0 ]; then\n    echo \"✓ PASS: JSON output is valid\"\nelse\n    echo \"✗ FAIL: JSON output should be valid JSON\"\n    exit 1\nfi\n\n# Test 4: Quiet mode\necho \"[4/5] Testing quiet mode...\"\nOUTPUT=$(./target/release/rust_proxy check --quiet)\nif [ -z \"$OUTPUT\" ]; then\n    echo \"✓ PASS: Quiet mode produces no output for valid config\"\nelse\n    echo \"✗ FAIL: Quiet mode should produce no output\"\n    exit 1\nfi\n\n# Test 5: Invalid config\necho \"[5/5] Testing invalid configuration...\"\n# (Would need to temporarily corrupt config)\n\necho \"=== Test Complete ===\"\n```\n\n## Risk Assessment\n\n- **Complexity**: Medium (new module, multiple validation rules)\n- **Impact**: High (major UX improvement, enables CI/CD)\n- **Risk**: Very low (read-only command, no side effects)\n- **Confidence**: Very high (well-defined scope, clear success criteria)\n\n## Dependencies\n\nNone directly, but shares validation patterns with 'rust_proxy test' command.","status":"closed","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:49:12.826658186-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:04:33.461674607-05:00","closed_at":"2026-01-18T04:04:33.461674607-05:00","close_reason":"Implemented check command with proxy/target/settings/active validation, JSON output, --strict, --quiet flags. All tests pass."}
{"id":"rust_proxy-4ce.1","title":"Subtask: Implement proxy validation for check command","description":"## Scope\nImplement validation logic for proxy definitions in the 'rust_proxy check' command.\n\n## Validation Checks\n1. URL format validation (http:// or https://)\n2. Port is specified and in valid range (1-65535)\n3. Host is resolvable (warning if not)\n4. Auth validation:\n   - If username/password specified: warn about plaintext\n   - If username_env/password_env: verify env vars exist and are non-empty\n5. No duplicate proxy IDs\n\n## Output Format\n```\n✓ Proxy 'mesh-us': URL valid, auth configured (env vars)\n✗ Proxy 'mesh-eu': PROXY_EU_PASS environment variable not set\n⚠ Proxy 'mesh-jp': using plaintext credentials (consider env vars)\n```\n\n## Code Location\nNew function in `src/validation.rs`: `validate_proxies(config: \u0026Config) -\u003e Vec\u003cValidationResult\u003e`\n\n## Testing\n- Test valid proxy configuration\n- Test missing env vars\n- Test invalid URL formats\n- Test duplicate proxy IDs","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:49:52.148554346-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:00:09.388237192-05:00","closed_at":"2026-01-18T04:00:09.388237192-05:00","close_reason":"Implemented in validation.rs with CLI integration in main.rs","dependencies":[{"issue_id":"rust_proxy-4ce.1","depends_on_id":"rust_proxy-4ce","type":"parent-child","created_at":"2026-01-18T02:49:52.149981384-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-4ce.2","title":"Subtask: Implement target validation for check command","description":"## Scope\nImplement validation logic for target domains in the 'rust_proxy check' command.\n\n## Validation Checks\n1. Domain format validation:\n   - No protocol prefix (http://, https://)\n   - No path component\n   - Valid hostname characters\n2. Provider hint validation:\n   - If specified, must be recognized provider\n   - Warn if provider hint doesn't match domain pattern\n3. No duplicate domains\n4. Warn if no targets configured\n\n## Output Format\n```\n✓ Targets: 87 domains configured\n  ✓ api.openai.com (provider: openai)\n  ✓ api.anthropic.com (provider: anthropic)\n  ⚠ https://example.com: remove protocol prefix\n  ✗ example.com/api: domains should not include paths\n```\n\n## Code Location\nNew function in `src/validation.rs`: `validate_targets(config: \u0026Config) -\u003e Vec\u003cValidationResult\u003e`\n\n## Testing\n- Test valid target configurations\n- Test invalid domain formats\n- Test unrecognized provider hints\n- Test duplicate domains","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:49:53.613904681-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:00:09.406164568-05:00","closed_at":"2026-01-18T04:00:09.406164568-05:00","close_reason":"Implemented in validation.rs with CLI integration in main.rs","dependencies":[{"issue_id":"rust_proxy-4ce.2","depends_on_id":"rust_proxy-4ce","type":"parent-child","created_at":"2026-01-18T02:49:53.615681087-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-4ce.3","title":"Subtask: Implement settings validation for check command","description":"## Scope\nImplement validation logic for settings in the 'rust_proxy check' command.\n\n## Validation Checks\n1. listen_port: 1024-65535 (warn if \u003c1024 requires root)\n2. dns_refresh_secs: \u003e 0, warn if \u003c 60 (too frequent)\n3. ping_interval_secs: \u003e 0\n4. ping_timeout_ms: \u003e 0, \u003c ping_interval_secs * 1000\n5. ipset_name: valid identifier (alphanumeric + underscore, \u003c= 31 chars)\n6. chain_name: valid identifier\n7. connect_max_retries: \u003e= 0\n8. connect_initial_backoff_ms: \u003e 0\n9. connect_max_backoff_ms: \u003e= connect_initial_backoff_ms\n\n## Output Format\n```\n✓ Settings validation:\n  ✓ listen_port: 12345\n  ✓ dns_refresh_secs: 300\n  ✗ ping_timeout_ms: 60000 exceeds ping_interval (60s)\n  ⚠ dns_refresh_secs: 10 is very frequent, consider \u003e= 60\n```\n\n## Code Location\nNew function in `src/validation.rs`: `validate_settings(config: \u0026Config) -\u003e Vec\u003cValidationResult\u003e`\n\n## Testing\n- Test valid settings\n- Test out-of-range values\n- Test boundary conditions\n- Test warning thresholds","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:49:54.931673579-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:00:09.41982059-05:00","closed_at":"2026-01-18T04:00:09.41982059-05:00","close_reason":"Implemented in validation.rs with CLI integration in main.rs","dependencies":[{"issue_id":"rust_proxy-4ce.3","depends_on_id":"rust_proxy-4ce","type":"parent-child","created_at":"2026-01-18T02:49:54.933786329-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-4ce.4","title":"Subtask: Implement active proxy validation for check command","description":"## Scope\nImplement validation logic for active proxy configuration.\n\n## Validation Checks\n1. If active_proxy is set:\n   - Must reference a defined proxy ID\n   - Referenced proxy must pass its own validation\n2. If active_proxy is not set:\n   - Warning: no proxy will be used until activated\n3. Cross-reference check:\n   - Warn if all proxies have validation errors\n\n## Output Format\n```\n✓ Active proxy: mesh-us (defined and valid)\n```\nor\n```\n⚠ No active proxy configured (run 'rust_proxy activate')\n```\nor\n```\n✗ Active proxy 'mesh-unknown' is not defined\n```\n\n## Code Location\nNew function in `src/validation.rs`: `validate_active_proxy(config: \u0026Config) -\u003e Vec\u003cValidationResult\u003e`\n\n## Testing\n- Test valid active proxy reference\n- Test missing active proxy\n- Test invalid active proxy reference","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:49:55.986576702-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:00:09.431598844-05:00","closed_at":"2026-01-18T04:00:09.431598844-05:00","close_reason":"Implemented in validation.rs with CLI integration in main.rs","dependencies":[{"issue_id":"rust_proxy-4ce.4","depends_on_id":"rust_proxy-4ce","type":"parent-child","created_at":"2026-01-18T02:49:55.988003861-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-4ce.5","title":"Subtask: Create validation module and CLI integration","description":"## Scope\nCreate the validation module structure and integrate with CLI.\n\n## Tasks\n1. Create new file `src/validation.rs`\n2. Define ValidationResult enum:\n   ```rust\n   pub enum ValidationSeverity { Error, Warning, Info }\n   pub struct ValidationResult {\n       pub severity: ValidationSeverity,\n       pub category: String,  // \"proxy\", \"target\", \"settings\"\n       pub message: String,\n       pub suggestion: Option\u003cString\u003e,\n   }\n   ```\n3. Create aggregation function:\n   ```rust\n   pub fn validate_config(config: \u0026Config) -\u003e ValidationReport\n   ```\n4. Add CLI subcommand:\n   ```rust\n   #[derive(Subcommand)]\n   enum Commands {\n       Check {\n           #[arg(long)]\n           strict: bool,\n           #[arg(long)]\n           json: bool,\n           #[arg(long)]\n           quiet: bool,\n       },\n   }\n   ```\n5. Implement output formatting (colored, JSON)\n6. Implement exit codes (0/1/2)\n\n## Code Locations\n- New module: `src/validation.rs`\n- CLI integration: `src/main.rs`\n- Module declaration: `src/main.rs` or `src/lib.rs`\n\n## Testing\n- Integration test for full check command\n- Test exit codes\n- Test JSON output format\n- Test --quiet and --strict flags","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:49:57.360529379-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:00:09.445842793-05:00","closed_at":"2026-01-18T04:00:09.445842793-05:00","close_reason":"Implemented in validation.rs with CLI integration in main.rs","dependencies":[{"issue_id":"rust_proxy-4ce.5","depends_on_id":"rust_proxy-4ce","type":"parent-child","created_at":"2026-01-18T02:49:57.36244111-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-4ce.6","title":"Subtask: Implement --test-connectivity flag for check command","description":"## Scope\nImplement optional network connectivity testing for the check command.\n\n## Feature Description\nWhen `--test-connectivity` flag is provided, actually test that proxies are reachable:\n\n```bash\nrust_proxy check --test-connectivity\n```\n\n## Implementation\n\n### Connection Test Logic\n```rust\nasync fn test_proxy_connectivity(proxy: \u0026ProxyDef, timeout_ms: u64) -\u003e ConnectivityResult {\n    let timeout = Duration::from_millis(timeout_ms);\n    let start = Instant::now();\n    \n    // 1. Resolve proxy host\n    let addrs = match tokio::net::lookup_host(\u0026proxy.url_host_port()).await {\n        Ok(addrs) =\u003e addrs.collect::\u003cVec\u003c_\u003e\u003e(),\n        Err(e) =\u003e return ConnectivityResult::DnsFailure(e.to_string()),\n    };\n    \n    // 2. TCP connect\n    let stream = match tokio::time::timeout(timeout, TcpStream::connect(\u0026addrs[0])).await {\n        Ok(Ok(s)) =\u003e s,\n        Ok(Err(e)) =\u003e return ConnectivityResult::ConnectFailure(e.to_string()),\n        Err(_) =\u003e return ConnectivityResult::Timeout,\n    };\n    \n    // 3. Send CONNECT request (to httpbin or configurable endpoint)\n    // ... send CONNECT httpbin.org:443 HTTP/1.1 ...\n    \n    ConnectivityResult::Success {\n        latency_ms: start.elapsed().as_millis() as u64,\n    }\n}\n\nenum ConnectivityResult {\n    Success { latency_ms: u64 },\n    DnsFailure(String),\n    ConnectFailure(String),\n    AuthFailure(String),\n    Timeout,\n}\n```\n\n### Output Format\n```\nProxies (2 defined):\n✓ mesh-us: http://us-wa.proxymesh.com:31280 (auth: env vars)\n  → Connectivity: ✓ reachable (45ms)\n✗ mesh-eu: http://eu.proxymesh.com:31280 (auth: env vars)\n  → Connectivity: ✗ connection refused\n```\n\n### JSON Output\n```json\n{\n  \"id\": \"mesh-us\",\n  \"url\": \"http://us-wa.proxymesh.com:31280\",\n  \"connectivity\": {\n    \"status\": \"success\",\n    \"latency_ms\": 45\n  }\n}\n```\n\n## Considerations\n- This is optional and slower (network I/O)\n- Should have reasonable timeout (5 seconds default)\n- Should run connectivity tests in parallel for multiple proxies\n- Auth failures vs connection failures should be distinguished\n\n## Testing\n- Test with reachable proxy (mock server)\n- Test with unreachable host\n- Test timeout behavior\n- Test DNS failure handling","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T03:06:19.525994755-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T10:48:44.119544639-05:00","closed_at":"2026-01-18T10:48:44.119544639-05:00","close_reason":"Implemented --test-connectivity flag for check command. Tests proxies in parallel using health check logic, outputs both human-readable and JSON formats.","dependencies":[{"issue_id":"rust_proxy-4ce.6","depends_on_id":"rust_proxy-4ce","type":"parent-child","created_at":"2026-01-18T03:06:19.570075785-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-4ce.7","title":"Subtask: Comprehensive test suite for check command","description":"## Scope\nCreate comprehensive unit tests, integration tests, and E2E tests for the check command.\n\n## Unit Tests (`src/validation.rs`)\n\n### File Validation Tests\n```rust\n#[test]\nfn test_validate_file_readable() {\n    let result = validate_file_access(Path::new(\"/etc/passwd\")); // readable\n    assert!(result.iter().all(|r| r.severity != Severity::Error));\n}\n\n#[test]\nfn test_validate_file_not_found() {\n    let result = validate_file_access(Path::new(\"/nonexistent/file\"));\n    assert!(result.iter().any(|r| r.severity == Severity::Error));\n}\n\n#[test]\nfn test_validate_file_insecure_permissions() {\n    // Create temp file with 644 containing plaintext password\n    // Should warn about permissions\n}\n```\n\n### Proxy Validation Tests\n```rust\n#[test]\nfn test_proxy_valid_url() {\n    let proxy = ProxyDef { url: \"http://proxy.example.com:8080\".into(), .. };\n    let result = validate_proxy(\u0026proxy);\n    assert!(result.is_empty());\n}\n\n#[test]\nfn test_proxy_missing_port() {\n    let proxy = ProxyDef { url: \"http://proxy.example.com\".into(), .. };\n    let result = validate_proxy(\u0026proxy);\n    assert!(result.iter().any(|r| r.message.contains(\"port\")));\n}\n\n#[test]\nfn test_proxy_invalid_url() {\n    let proxy = ProxyDef { url: \"not-a-url\".into(), .. };\n    let result = validate_proxy(\u0026proxy);\n    assert!(result.iter().any(|r| r.severity == Severity::Error));\n}\n\n#[test]\nfn test_proxy_missing_env_var() {\n    // Proxy with username_env pointing to unset var\n    std::env::remove_var(\"TEST_PROXY_USER\");\n    let proxy = ProxyDef { \n        auth: Some(Auth { username_env: Some(\"TEST_PROXY_USER\".into()), .. }),\n        ..\n    };\n    let result = validate_proxy(\u0026proxy);\n    assert!(result.iter().any(|r| r.message.contains(\"not set\")));\n}\n\n#[test]\nfn test_proxy_plaintext_credentials_warning() {\n    let proxy = ProxyDef {\n        auth: Some(Auth { username: Some(\"user\".into()), password: Some(\"pass\".into()), .. }),\n        ..\n    };\n    let result = validate_proxy(\u0026proxy);\n    assert!(result.iter().any(|r| r.severity == Severity::Warning \u0026\u0026 r.message.contains(\"plaintext\")));\n}\n\n#[test]\nfn test_duplicate_proxy_ids() {\n    let proxies = vec![\n        ProxyDef { id: \"proxy1\".into(), .. },\n        ProxyDef { id: \"proxy1\".into(), .. },\n    ];\n    let result = validate_proxies(\u0026proxies);\n    assert!(result.iter().any(|r| r.message.contains(\"duplicate\")));\n}\n```\n\n### Target Validation Tests\n```rust\n#[test]\nfn test_target_valid_domain() {\n    let target = Target { domain: \"api.example.com\".into(), provider: None };\n    assert!(validate_target(\u0026target).is_empty());\n}\n\n#[test]\nfn test_target_with_protocol() {\n    let target = Target { domain: \"https://api.example.com\".into(), provider: None };\n    let result = validate_target(\u0026target);\n    assert!(result.iter().any(|r| r.message.contains(\"protocol\")));\n}\n\n#[test]\nfn test_target_with_path() {\n    let target = Target { domain: \"api.example.com/v1\".into(), provider: None };\n    let result = validate_target(\u0026target);\n    assert!(result.iter().any(|r| r.message.contains(\"path\")));\n}\n\n#[test]\nfn test_target_invalid_provider() {\n    let target = Target { domain: \"api.example.com\".into(), provider: Some(\"invalid\".into()) };\n    let result = validate_target(\u0026target);\n    assert!(result.iter().any(|r| r.message.contains(\"provider\")));\n}\n```\n\n### Settings Validation Tests\n```rust\n#[test]\nfn test_settings_port_range() {\n    let mut settings = Settings::default();\n    settings.listen_port = 80;\n    let result = validate_settings(\u0026settings);\n    assert!(result.iter().any(|r| r.severity == Severity::Warning \u0026\u0026 r.message.contains(\"root\")));\n    \n    settings.listen_port = 70000;\n    let result = validate_settings(\u0026settings);\n    assert!(result.iter().any(|r| r.severity == Severity::Error));\n}\n\n#[test]\nfn test_settings_ipset_name_length() {\n    let mut settings = Settings::default();\n    settings.ipset_name = \"a\".repeat(32); // Too long (max 31)\n    let result = validate_settings(\u0026settings);\n    assert!(result.iter().any(|r| r.message.contains(\"31\")));\n}\n\n#[test]\nfn test_settings_ping_timeout_vs_interval() {\n    let mut settings = Settings::default();\n    settings.ping_interval_secs = 60;\n    settings.ping_timeout_ms = 65000; // \u003e 60 * 1000\n    let result = validate_settings(\u0026settings);\n    assert!(result.iter().any(|r| r.message.contains(\"timeout\")));\n}\n```\n\n## Integration Tests (`tests/check_integration.rs`)\nSee parent bead for integration test examples.\n\n## E2E Tests (`tests/e2e/check_command.sh`)\nSee parent bead for E2E test script.\n\n## Test Coverage Requirements\n- All error conditions in each validator\n- All warning conditions\n- JSON output format validation\n- Exit code verification\n- --strict mode behavior\n- --quiet mode behavior","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T03:06:36.733230549-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T03:06:36.733230549-05:00","dependencies":[{"issue_id":"rust_proxy-4ce.7","depends_on_id":"rust_proxy-4ce","type":"parent-child","created_at":"2026-01-18T03:06:36.758549024-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-4t2","title":"Complete Beads setup (hooks + version tracking + sync divergence)","description":"Finish Beads setup: install recommended git hooks, initialize version tracking, and clear sync divergence by syncing .beads JSONL/metadata once git tracking/upstream is configured.","notes":"Progress: ran bd ready (version tracking initialized) and installed hooks via bd hooks install. Sync divergence still pending until repo tracking/upstream is decided.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-17T19:41:43.657107619-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-17T21:36:41.535732551-05:00","closed_at":"2026-01-17T21:36:41.535732551-05:00","close_reason":"Beads setup complete after upstream configured and initial sync committed."}
{"id":"rust_proxy-51u","title":"Integrate load balancer with proxy connection handling","description":"## Scope\n\nIntegrate the load balancer with the proxy connection handling code so that each new connection uses the configured load balancing strategy.\n\n## Current State\n\nCurrently in `proxy.rs`, the effective proxy is determined once at daemon start or on failover:\n```rust\nlet proxy_url = runtime.get_effective_proxy().await;\n```\n\n## New Behavior\n\nEach incoming connection should select a proxy via the load balancer:\n```rust\n// In the connection handler\nlet proxy_id = load_balancer.select_proxy(\n    config.settings.load_balance_strategy,\n    \u0026config.proxies,\n    \u0026state,\n).await;\n\nlet proxy = config.proxies.iter().find(|p| p.id == proxy_id);\n```\n\n## Integration Points\n\n### run_daemon() Changes\n\n```rust\npub async fn run_daemon() -\u003e Result\u003c()\u003e {\n    let config = AppConfig::load()?;\n    let state = Arc::new(StateStore::load().await?);\n    let load_balancer = Arc::new(LoadBalancer::new());\n\n    // Pass load_balancer to accept loop\n    // ...\n}\n```\n\n### Accept Loop Changes\n\n```rust\nasync fn handle_connection(\n    stream: TcpStream,\n    config: Arc\u003cAppConfig\u003e,\n    state: Arc\u003cStateStore\u003e,\n    load_balancer: Arc\u003cLoadBalancer\u003e,\n) {\n    // Select proxy for this connection\n    let proxy_id = load_balancer.select_proxy(\n        config.settings.load_balance_strategy,\n        \u0026config.proxies,\n        \u0026state,\n    ).await;\n\n    // If no proxy selected, apply degradation policy (separate feature)\n    let proxy_id = match proxy_id {\n        Some(id) =\u003e id,\n        None =\u003e {\n            tracing::warn!(\"No healthy proxy available\");\n            // TODO: Apply degradation policy\n            return;\n        }\n    };\n\n    // Get proxy config and proceed\n    let proxy = config.proxies.iter()\n        .find(|p| p.id == proxy_id)\n        .expect(\"proxy must exist\");\n\n    // Continue with proxy connection...\n}\n```\n\n## Logging\n\nAdd logging to show which proxy was selected:\n```rust\ntracing::debug!(\n    proxy = %proxy_id,\n    strategy = ?config.settings.load_balance_strategy,\n    \"Selected proxy for connection\"\n);\n```\n\n## Acceptance Criteria\n\n- Each connection goes through load balancer selection\n- Strategy from config is used\n- Correct proxy selected per strategy\n- Graceful handling when no healthy proxies\n- Performance acceptable (selection should be fast)","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:08:49.974471534-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:08:49.974471534-05:00","dependencies":[{"issue_id":"rust_proxy-51u","depends_on_id":"rust_proxy-uue","type":"blocks","created_at":"2026-01-18T13:10:01.321476897-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-5b1","title":"Add completions uninstall command for cleanup","description":"## Scope\n\nAdd a `completions uninstall` command to cleanly remove installed completion scripts.\n\n## Rationale\n\nUsers should be able to cleanly remove completions if:\n- They're switching shells\n- They're uninstalling the tool\n- The completions are causing issues\n- They want to reinstall fresh\n\n## Implementation Details\n\n### CLI Addition\n\n```rust\n#[derive(Debug, Subcommand)]\nenum CompletionsAction {\n    // ... existing\n\n    /// Remove installed shell completions\n    Uninstall {\n        /// Override shell detection\n        #[arg(long, value_enum)]\n        shell: Option\u003cShellArg\u003e,\n\n        /// Remove completions for all shells\n        #[arg(long)]\n        all: bool,\n    },\n}\n```\n\n### Uninstall Logic\n\n```rust\nfn completions_uninstall(shell_override: Option\u003cShellArg\u003e, all: bool) -\u003e Result\u003c()\u003e {\n    if all {\n        // Remove from all known locations\n        let shells = [Shell::Bash, Shell::Zsh, Shell::Fish];\n        let mut removed = 0;\n\n        for shell in shells {\n            if let Ok(path) = shell.completion_path() {\n                if path.exists() {\n                    std::fs::remove_file(\u0026path)?;\n                    println!(\"Removed {}\", path.display());\n                    removed += 1;\n                }\n            }\n        }\n\n        if removed == 0 {\n            println!(\"No completion files found\");\n        } else {\n            println!(\"Removed {} completion file(s)\", removed);\n        }\n        return Ok(());\n    }\n\n    let shell = match shell_override {\n        Some(s) =\u003e s.into(),\n        None =\u003e {\n            let detected = detect_shell();\n            if detected == Shell::Unknown {\n                anyhow::bail!(\n                    \"Could not detect shell. Use --shell or --all\"\n                );\n            }\n            detected\n        }\n    };\n\n    let path = shell.completion_path()?;\n\n    if path.exists() {\n        std::fs::remove_file(\u0026path)?;\n        println!(\"Removed {}\", path.display());\n    } else {\n        println!(\"No completion file found at {}\", path.display());\n    }\n\n    Ok(())\n}\n```\n\n### User Experience\n\n```\n$ rp completions uninstall\nRemoved /home/user/.zsh/completions/_rp\n\n$ rp completions uninstall --all\nRemoved /home/user/.local/share/bash-completion/completions/rp\nRemoved /home/user/.zsh/completions/_rp\nRemoved 2 completion file(s)\n\n$ rp completions uninstall --shell fish\nNo completion file found at /home/user/.config/fish/completions/rp.fish\n```\n\n## Acceptance Criteria\n\n- `rp completions uninstall` removes detected shell's completions\n- `--shell` overrides detection\n- `--all` removes from all shell locations\n- Graceful handling when file doesn't exist\n- Clear feedback on what was removed","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:02:37.303368154-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:02:37.303368154-05:00","dependencies":[{"issue_id":"rust_proxy-5b1","depends_on_id":"rust_proxy-hxd","type":"blocks","created_at":"2026-01-18T14:02:49.038214309-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-5gs","title":"Add doctor command for comprehensive health check","description":"Implement the rp doctor command that performs comprehensive health checks: config validation, proxy connectivity, DNS resolution, listen port availability, and state directory writeability. Output should be clear and actionable with JSON option for scripting.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:13:19.620247318-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:13:19.620247318-05:00"}
{"id":"rust_proxy-663","title":"Update status command to show load balancing info","description":"## Scope\n\nEnhance the `status` command output to display current load balancing configuration and per-connection selection statistics.\n\n## Rationale\n\nUsers need visibility into how load balancing is working in production. Without this, they can't tell which strategy is active, how connections are distributed, or whether the load balancer is behaving as expected.\n\n## Implementation Details\n\n### Status Output Additions\n\nAdd a \"Load Balancing\" section to status output:\n\n```\nLoad Balancing:\n  Strategy: round_robin\n  Selection stats (last 1000 connections):\n    proxy-a: 502 (50.2%)\n    proxy-b: 498 (49.8%)\n```\n\n### Required Changes\n\n1. **Track selection statistics** - Maintain counters for how many times each proxy was selected\n2. **Add to status JSON output** - Include `load_balance_strategy` and `selection_stats` fields\n3. **Human-readable formatting** - Display percentage distribution clearly\n\n### Statistics Storage\n\nSelection stats should be stored in RuntimeState or StateStore:\n```rust\npub struct LoadBalanceStats {\n    pub strategy: LoadBalanceStrategy,\n    pub selections: HashMap\u003cString, u64\u003e,\n    pub total_selections: u64,\n}\n```\n\n## Acceptance Criteria\n\n- Status command shows current load balance strategy\n- Status command shows selection distribution across proxies\n- JSON output includes structured load balance information\n- Statistics reset on daemon restart (ephemeral, not persisted)","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:10:16.328950945-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:10:16.328950945-05:00","dependencies":[{"issue_id":"rust_proxy-663","depends_on_id":"rust_proxy-51u","type":"blocks","created_at":"2026-01-18T13:10:20.943316809-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-66v","title":"Add cargo test to CI workflow","description":"The CI workflow (.github/workflows/ci.yml) runs fmt, clippy, and check, but does NOT run the test suite. The project has 35 unit tests that should be verified in CI. Add a cargo test step to the workflow.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T01:33:42.738447513-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:34:16.41519774-05:00","closed_at":"2026-01-18T01:34:16.41519774-05:00","close_reason":"Added cargo test step to CI workflow"}
{"id":"rust_proxy-685","title":"Instrument proxy connection code with metrics","description":"## Scope\n\nAdd metric instrumentation to the proxy connection handling code in `proxy.rs`.\n\n## Instrumentation Points\n\n### Connection Start\n```rust\n// In handle_connection or similar\nmetrics::ACTIVE_CONNECTIONS.with_label_values(\u0026[\u0026proxy_id]).inc();\nlet connection_start = Instant::now();\n```\n\n### Connection End\n```rust\n// When connection completes (success or failure)\nmetrics::ACTIVE_CONNECTIONS.with_label_values(\u0026[\u0026proxy_id]).dec();\nmetrics::CONNECTION_DURATION\n    .with_label_values(\u0026[\u0026proxy_id])\n    .observe(connection_start.elapsed().as_secs_f64());\n```\n\n### Request Success/Failure\n```rust\n// On successful proxy\nmetrics::REQUESTS_TOTAL\n    .with_label_values(\u0026[\u0026proxy_id, \"success\"])\n    .inc();\n\n// On failure\nmetrics::REQUESTS_TOTAL\n    .with_label_values(\u0026[\u0026proxy_id, \"failure\"])\n    .inc();\n```\n\n### Bytes Transferred\n```rust\n// After bidirectional copy completes\nmetrics::BYTES_SENT.with_label_values(\u0026[\u0026proxy_id]).inc_by(bytes_sent);\nmetrics::BYTES_RECEIVED.with_label_values(\u0026[\u0026proxy_id]).inc_by(bytes_received);\n```\n\n## Implementation Notes\n\n- Use `Instant::now()` for timing, not wall clock\n- Ensure metrics are recorded even on error paths (use guard patterns or defer)\n- Proxy ID should match what is shown in status/config\n- Consider using a guard struct that decrements active connections on drop:\n\n```rust\nstruct ConnectionGuard {\n    proxy_id: String,\n    start: Instant,\n}\n\nimpl Drop for ConnectionGuard {\n    fn drop(\u0026mut self) {\n        metrics::ACTIVE_CONNECTIONS.with_label_values(\u0026[\u0026self.proxy_id]).dec();\n        metrics::CONNECTION_DURATION\n            .with_label_values(\u0026[\u0026self.proxy_id])\n            .observe(self.start.elapsed().as_secs_f64());\n    }\n}\n```\n\n## Acceptance Criteria\n\n- All connection lifecycle events are instrumented\n- Metrics update correctly during proxy operation\n- No panics or errors from metrics code\n- Minimal performance impact (metrics operations are fast)\n- Error paths also record metrics correctly","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:06:02.947011152-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:06:02.947011152-05:00","dependencies":[{"issue_id":"rust_proxy-685","depends_on_id":"rust_proxy-l96","type":"blocks","created_at":"2026-01-18T13:07:08.375729489-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-6ox","title":"E2E tests for Systemd Service Generation","description":"## E2E Tests for Systemd Service Generation\n\n### Test Scenarios\n\n1. **Service Generate Creates File**\n   ```rust\n   #[tokio::test]\n   async fn test_service_generate_creates_file() {\n       let harness = TestHarness::new().await;\n       let output_path = harness.temp_dir.path().join(\"rp.service\");\n\n       let result = harness.run_command(\u0026[\n           \"service\", \"generate\",\n           \"--output\", \u0026output_path.to_string_lossy()\n       ]);\n\n       assert!(result.success);\n       assert!(output_path.exists());\n\n       let content = fs::read_to_string(\u0026output_path).unwrap();\n       assert!(content.contains(\"[Unit]\"));\n       assert!(content.contains(\"[Service]\"));\n   }\n   ```\n\n2. **Service Generate Default Output**\n   ```rust\n   #[tokio::test]\n   async fn test_service_generate_default_path() {\n       let harness = TestHarness::new().await;\n\n       let result = harness.run_command(\u0026[\"service\", \"generate\"]);\n\n       assert!(result.success);\n       assert!(result.stdout.contains(\"Generated\") ||\n               result.stdout.contains(\"service file\"));\n   }\n   ```\n\n3. **Service Generate With Options**\n   ```rust\n   #[tokio::test]\n   async fn test_service_generate_with_user() {\n       let harness = TestHarness::new().await;\n       let output_path = harness.temp_dir.path().join(\"rp.service\");\n\n       let result = harness.run_command(\u0026[\n           \"service\", \"generate\",\n           \"--output\", \u0026output_path.to_string_lossy(),\n           \"--user\", \"proxy\",\n           \"--group\", \"proxy\"\n       ]);\n\n       assert!(result.success);\n       let content = fs::read_to_string(\u0026output_path).unwrap();\n       assert!(content.contains(\"User=proxy\"));\n       assert!(content.contains(\"Group=proxy\"));\n   }\n   ```\n\n4. **Service Generate Hardened**\n   ```rust\n   #[tokio::test]\n   async fn test_service_generate_hardened() {\n       let harness = TestHarness::new().await;\n       let output_path = harness.temp_dir.path().join(\"rp.service\");\n\n       let result = harness.run_command(\u0026[\n           \"service\", \"generate\",\n           \"--output\", \u0026output_path.to_string_lossy(),\n           \"--hardened\"\n       ]);\n\n       assert!(result.success);\n       let content = fs::read_to_string(\u0026output_path).unwrap();\n       assert!(content.contains(\"ProtectSystem=\"));\n       assert!(content.contains(\"NoNewPrivileges=true\"));\n   }\n   ```\n\n5. **Service File Is Valid Systemd**\n   ```rust\n   #[tokio::test]\n   async fn test_service_file_validates() {\n       // Skip if systemd-analyze not available\n       if !which::which(\"systemd-analyze\").is_ok() {\n           return;\n       }\n\n       let harness = TestHarness::new().await;\n       let output_path = harness.temp_dir.path().join(\"rp.service\");\n\n       harness.run_command(\u0026[\n           \"service\", \"generate\",\n           \"--output\", \u0026output_path.to_string_lossy()\n       ]);\n\n       // Use systemd-analyze to validate\n       let result = Command::new(\"systemd-analyze\")\n           .arg(\"verify\")\n           .arg(\u0026output_path)\n           .output()\n           .unwrap();\n\n       assert!(result.status.success() ||\n               String::from_utf8_lossy(\u0026result.stderr).contains(\"not found\"));\n   }\n   ```\n\n6. **Service Generate With Config Path**\n   ```rust\n   #[tokio::test]\n   async fn test_service_generate_with_config() {\n       let harness = TestHarness::new().await;\n       let output_path = harness.temp_dir.path().join(\"rp.service\");\n\n       let result = harness.run_command(\u0026[\n           \"service\", \"generate\",\n           \"--output\", \u0026output_path.to_string_lossy(),\n           \"--config\", \"/etc/rp/production.toml\"\n       ]);\n\n       assert!(result.success);\n       let content = fs::read_to_string(\u0026output_path).unwrap();\n       assert!(content.contains(\"/etc/rp/production.toml\"));\n   }\n   ```\n\n7. **Service Install Helper (Dry Run)**\n   ```rust\n   #[tokio::test]\n   async fn test_service_install_dry_run() {\n       let harness = TestHarness::new().await;\n\n       let result = harness.run_command(\u0026[\n           \"service\", \"install\",\n           \"--dry-run\"\n       ]);\n\n       assert!(result.success);\n       assert!(result.stdout.contains(\"Would copy\"));\n       assert!(result.stdout.contains(\"/etc/systemd/system\"));\n   }\n   ```\n\n8. **Service Shows Install Instructions**\n   ```rust\n   #[tokio::test]\n   async fn test_service_shows_instructions() {\n       let harness = TestHarness::new().await;\n\n       let result = harness.run_command(\u0026[\"service\", \"generate\"]);\n\n       assert!(result.success);\n       // Should include instructions for installing\n       assert!(result.stdout.contains(\"sudo\") ||\n               result.stdout.contains(\"systemctl\"));\n   }\n   ```\n\n### Logging Requirements\n- Log all generation options being used\n- Log output file path\n- Log security hardening features applied\n- On failure, log file permission issues\n\n### Dependencies\n- Requires: rust_proxy-cux (E2E Test Infrastructure)\n- Note: systemd validation tests require systemd-analyze","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:21.122379424-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:21.122379424-05:00","dependencies":[{"issue_id":"rust_proxy-6ox","depends_on_id":"rust_proxy-cux","type":"blocks","created_at":"2026-01-18T14:56:37.157132999-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-6ox","depends_on_id":"rust_proxy-giu","type":"blocks","created_at":"2026-01-18T14:56:53.818514003-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-6q6","title":"Define rich error types with context","description":"Create error enum with variants for common failures: ConfigError, ProxyConnectionError, DnsError, etc. Each variant includes context (proxy_id, address, original error) and implements Display with helpful messages.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:15:40.181370892-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:23:15.413353683-05:00"}
{"id":"rust_proxy-6xn","title":"Unit tests for Customizable Health Check","description":"## Unit Tests for Customizable Health Check\n\n### Test Coverage Areas\n\n1. **Health Check Target Parsing**\n   ```rust\n   #[test]\n   fn test_parse_connect_target() {\n       let target = HealthCheckTarget::parse(\"CONNECT example.com:443\").unwrap();\n       assert_eq!(target.method, HealthCheckMethod::Connect);\n       assert_eq!(target.host, \"example.com\");\n       assert_eq!(target.port, 443);\n   }\n\n   #[test]\n   fn test_parse_get_target() {\n       let target = HealthCheckTarget::parse(\"GET http://example.com/health\").unwrap();\n       assert_eq!(target.method, HealthCheckMethod::Get);\n       assert_eq!(target.url, \"http://example.com/health\");\n   }\n\n   #[test]\n   fn test_parse_head_target() {\n       let target = HealthCheckTarget::parse(\"HEAD http://example.com\").unwrap();\n       assert_eq!(target.method, HealthCheckMethod::Head);\n   }\n\n   #[test]\n   fn test_parse_invalid_target() {\n       let result = HealthCheckTarget::parse(\"INVALID\");\n       assert!(result.is_err());\n   }\n\n   #[test]\n   fn test_parse_default_port() {\n       let target = HealthCheckTarget::parse(\"CONNECT example.com\").unwrap();\n       assert_eq!(target.port, 443); // Default for CONNECT\n   }\n   ```\n\n2. **Health Check Method Execution**\n   ```rust\n   #[tokio::test]\n   async fn test_connect_method_checks_tcp() {\n       let mock = start_mock_tcp_server().await;\n       let target = HealthCheckTarget {\n           method: HealthCheckMethod::Connect,\n           host: \"127.0.0.1\".to_string(),\n           port: mock.port,\n           url: None,\n       };\n\n       let result = target.execute(\u0026mock_proxy_addr()).await;\n       assert!(result.success);\n   }\n\n   #[tokio::test]\n   async fn test_get_method_checks_http() {\n       let mock = start_mock_http_server(200).await;\n       let target = HealthCheckTarget {\n           method: HealthCheckMethod::Get,\n           host: \"\".to_string(),\n           port: 0,\n           url: Some(format!(\"http://127.0.0.1:{}/health\", mock.port)),\n       };\n\n       let result = target.execute(\u0026mock_proxy_addr()).await;\n       assert!(result.success);\n   }\n\n   #[tokio::test]\n   async fn test_get_method_fails_on_non_2xx() {\n       let mock = start_mock_http_server(500).await;\n       let target = HealthCheckTarget {\n           method: HealthCheckMethod::Get,\n           host: \"\".to_string(),\n           port: 0,\n           url: Some(format!(\"http://127.0.0.1:{}/health\", mock.port)),\n       };\n\n       let result = target.execute(\u0026mock_proxy_addr()).await;\n       assert!(!result.success);\n   }\n   ```\n\n3. **Target Validation**\n   ```rust\n   #[test]\n   fn test_validate_resolvable_hostname() {\n       let target = HealthCheckTarget::parse(\"CONNECT www.google.com:443\").unwrap();\n       let result = target.validate();\n       assert!(result.is_ok());\n   }\n\n   #[test]\n   fn test_validate_unresolvable_hostname() {\n       let target = HealthCheckTarget::parse(\"CONNECT invalid.hostname.that.does.not.exist.example:443\").unwrap();\n       let result = target.validate();\n       assert!(result.is_err());\n       assert!(result.unwrap_err().to_string().contains(\"DNS\") ||\n               result.unwrap_err().to_string().contains(\"resolve\"));\n   }\n\n   #[test]\n   fn test_validate_invalid_url() {\n       let target = HealthCheckTarget::parse(\"GET not-a-valid-url\").unwrap();\n       let result = target.validate();\n       assert!(result.is_err());\n   }\n\n   #[test]\n   fn test_validate_localhost_always_valid() {\n       let target = HealthCheckTarget::parse(\"CONNECT localhost:443\").unwrap();\n       let result = target.validate();\n       assert!(result.is_ok());\n   }\n   ```\n\n4. **Configuration Integration**\n   ```rust\n   #[test]\n   fn test_config_parse_health_check_target() {\n       let config = r#\"\n           [settings]\n           health_check_target = \"CONNECT internal.proxy.test:443\"\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:8080\"\n       \"#;\n\n       let parsed: AppConfig = toml::from_str(config).unwrap();\n       assert_eq!(parsed.settings.health_check_target,\n                  Some(\"CONNECT internal.proxy.test:443\".to_string()));\n   }\n\n   #[test]\n   fn test_config_default_health_check_target() {\n       let config = r#\"\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:8080\"\n       \"#;\n\n       let parsed: AppConfig = toml::from_str(config).unwrap();\n       // Should use default (www.google.com:443 or similar)\n       assert!(parsed.settings.health_check_target.is_none() ||\n               parsed.settings.health_check_target.as_ref()\n                   .map(|t| t.contains(\"google\") || t.contains(\"443\"))\n                   .unwrap_or(true));\n   }\n   ```\n\n5. **Per-Proxy Health Check Target**\n   ```rust\n   #[test]\n   fn test_per_proxy_health_check_target() {\n       let config = r#\"\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:8080\"\n           health_check_target = \"CONNECT internal-a.test:443\"\n\n           [[proxies]]\n           id = \"proxy-b\"\n           url = \"http://localhost:8081\"\n           health_check_target = \"GET http://health.internal/check\"\n       \"#;\n\n       let parsed: AppConfig = toml::from_str(config).unwrap();\n       assert_eq!(parsed.proxies[0].health_check_target,\n                  Some(\"CONNECT internal-a.test:443\".to_string()));\n       assert_eq!(parsed.proxies[1].health_check_target,\n                  Some(\"GET http://health.internal/check\".to_string()));\n   }\n   ```\n\n6. **Error Handling**\n   ```rust\n   #[test]\n   fn test_health_check_target_error_includes_target() {\n       let target = HealthCheckTarget::parse(\"CONNECT unreachable.test:443\").unwrap();\n\n       let result = futures::executor::block_on(async {\n           target.execute(\u0026\"127.0.0.1:9999\".to_string()).await\n       });\n\n       if !result.success {\n           assert!(result.failure_reason.as_ref().unwrap().contains(\"unreachable.test\") ||\n                   result.failure_reason.as_ref().unwrap().contains(\"443\"));\n       }\n   }\n   ```\n\n### Test Files\n- `src/health.rs` - inline unit tests (extended)\n- `tests/unit/health_check_target_test.rs` - extended tests","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:41.566993757-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:41.566993757-05:00","dependencies":[{"issue_id":"rust_proxy-6xn","depends_on_id":"rust_proxy-wl1","type":"blocks","created_at":"2026-01-18T14:56:57.533302486-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-77a","title":"Unit tests for Prometheus metrics","description":"## Unit Tests for Prometheus Metrics\n\n### Test Coverage Areas\n\n1. **Metric Registration**\n   - Test that all metric types (counters, gauges, histograms) register without panic\n   - Test duplicate registration is idempotent\n   - Test metric naming follows Prometheus conventions\n\n2. **Counter Operations**\n   ```rust\n   #[test]\n   fn test_request_counter_increments() {\n       let metrics = Metrics::new();\n       metrics.record_request(\"proxy-a\", RequestStatus::Success);\n       assert_eq!(metrics.requests_total(\"proxy-a\", \"success\"), 1);\n   }\n   ```\n\n3. **Gauge Operations**\n   ```rust\n   #[test]\n   fn test_health_gauge_updates() {\n       let metrics = Metrics::new();\n       metrics.set_proxy_health(\"proxy-a\", true);\n       assert_eq!(metrics.proxy_health(\"proxy-a\"), 1.0);\n       metrics.set_proxy_health(\"proxy-a\", false);\n       assert_eq!(metrics.proxy_health(\"proxy-a\"), 0.0);\n   }\n   ```\n\n4. **Histogram Operations**\n   ```rust\n   #[test]\n   fn test_latency_histogram_records() {\n       let metrics = Metrics::new();\n       metrics.record_connection_duration(\"proxy-a\", Duration::from_millis(150));\n       let histogram = metrics.connection_duration_histogram(\"proxy-a\");\n       assert!(histogram.count() \u003e= 1);\n   }\n   ```\n\n5. **Metrics Endpoint Encoding**\n   ```rust\n   #[test]\n   fn test_prometheus_encoding() {\n       let metrics = Metrics::new();\n       metrics.record_request(\"proxy-a\", RequestStatus::Success);\n       let output = metrics.encode_prometheus();\n       assert!(output.contains(\"rust_proxy_requests_total\"));\n       assert!(output.contains(\"proxy=\\\"proxy-a\\\"\"));\n   }\n   ```\n\n6. **Thread Safety**\n   ```rust\n   #[tokio::test]\n   async fn test_concurrent_metric_updates() {\n       let metrics = Arc::new(Metrics::new());\n       let handles: Vec\u003c_\u003e = (0..100).map(|i| {\n           let m = metrics.clone();\n           tokio::spawn(async move {\n               m.record_request(\"proxy-a\", RequestStatus::Success);\n           })\n       }).collect();\n       for h in handles { h.await.unwrap(); }\n       assert_eq!(metrics.requests_total(\"proxy-a\", \"success\"), 100);\n   }\n   ```\n\n### Test Files\n- `src/metrics.rs` - inline unit tests\n- `tests/unit/metrics_test.rs` - extended unit tests\n\n### Logging Requirements\n- Log test setup/teardown phases\n- Log metric values before/after operations\n- On failure, dump full metric registry state","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:53:55.834457007-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:53:55.834457007-05:00","dependencies":[{"issue_id":"rust_proxy-77a","depends_on_id":"rust_proxy-0zp","type":"blocks","created_at":"2026-01-18T14:56:49.624820983-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-78m","title":"Implement configurable health check methods","description":"Modify check_proxy_health() to use configured target instead of hardcoded google.com. Support both CONNECT and GET methods. GET method useful for HTTP-only proxies or internal health endpoints.","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:16:38.757707993-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:16:38.757707993-05:00","dependencies":[{"issue_id":"rust_proxy-78m","depends_on_id":"rust_proxy-8fy","type":"blocks","created_at":"2026-01-18T14:16:54.721151389-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-7n2","title":"Instrument health check code with metrics","description":"## Scope\n\nAdd metric instrumentation to the health check code in `health.rs`.\n\n## Instrumentation Points\n\n### Health Check Results\n```rust\n// In run_health_checks() after each proxy check\nlet result_label = if result.success { \"healthy\" } else { \"unhealthy\" };\nmetrics::HEALTH_CHECKS\n    .with_label_values(\u0026[\u0026proxy.id, result_label])\n    .inc();\n\n// Also update the gauge\nmetrics::PROXY_HEALTH\n    .with_label_values(\u0026[\u0026proxy.id])\n    .set(if result.success { 1.0 } else { 0.0 });\n```\n\n### Health Check Latency\n```rust\n// Record latency for successful checks\nif result.success {\n    metrics::HEALTH_CHECK_LATENCY\n        .with_label_values(\u0026[\u0026proxy.id])\n        .observe(result.latency_ms / 1000.0);  // Convert ms to seconds\n}\n```\n\n### Failover Events\n```rust\n// In check_and_perform_failover() when failover occurs\nif let Some(event) = check_and_perform_failover(\u0026config, \u0026state, \u0026runtime).await {\n    metrics::FAILOVERS\n        .with_label_values(\u0026[\u0026event.from_proxy, \u0026event.to_proxy])\n        .inc();\n    // ... rest of failover handling\n}\n```\n\n### Failback Events\n```rust\n// In health_check_loop when failback occurs\nif check_and_perform_failback(\u0026config, \u0026state, \u0026runtime).await {\n    let original = runtime.get_original_proxy().await;\n    if let (Some(from), Some(to)) = (runtime.get_effective_proxy().await, original) {\n        metrics::FAILOVERS\n            .with_label_values(\u0026[\u0026from, \u0026to])\n            .inc();\n    }\n    // ... rest of failback handling\n}\n```\n\n## Implementation Notes\n\n- Health check latency should be in seconds (Prometheus convention)\n- PROXY_HEALTH gauge should be updated on every check, not just on change\n- Failover metric can be used to count both failovers and failbacks (direction is in labels)\n- Consider adding a startup metric to mark when health checks began\n\n## Acceptance Criteria\n\n- Health check results update metrics correctly\n- Proxy health gauge reflects current health state\n- Latency histogram populated with reasonable values\n- Failover counter increments on failover/failback events\n- Metrics visible at /metrics endpoint after health checks run","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:06:17.336264895-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:06:17.336264895-05:00","dependencies":[{"issue_id":"rust_proxy-7n2","depends_on_id":"rust_proxy-l96","type":"blocks","created_at":"2026-01-18T13:07:08.424002491-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-7nv","title":"Implement try_all degradation policy","description":"## Scope\n\nImplement the try_all degradation policy that attempts connection through each proxy sequentially until one succeeds.\n\n## Rationale\n\nHealth checks can have false negatives (proxy actually works but health check fails). For availability-critical use cases, it's better to try each proxy and see if any work, rather than giving up immediately.\n\n## Implementation Details\n\n```rust\npub async fn apply_try_all_policy(\n    config: \u0026AppConfig,\n    target: \u0026str,\n) -\u003e Result\u003c(TcpStream, String)\u003e {\n    tracing::warn!(\n        \"All proxies unhealthy, trying each sequentially (try_all policy)\"\n    );\n\n    // Sort by priority for deterministic order\n    let mut proxies: Vec\u003c_\u003e = config.proxies.iter().collect();\n    proxies.sort_by_key(|p| p.priority.unwrap_or(100));\n\n    let mut last_error = None;\n\n    for proxy in proxies {\n        tracing::debug!(proxy = %proxy.id, \"Attempting connection\");\n\n        match connect_through_proxy(proxy, target).await {\n            Ok(stream) =\u003e {\n                tracing::info!(\n                    proxy = %proxy.id,\n                    \"Connection succeeded despite unhealthy status\"\n                );\n                return Ok((stream, proxy.id.clone()));\n            }\n            Err(e) =\u003e {\n                tracing::debug!(\n                    proxy = %proxy.id,\n                    error = %e,\n                    \"Connection attempt failed\"\n                );\n                last_error = Some(e);\n            }\n        }\n    }\n\n    Err(last_error.unwrap_or_else(|| anyhow::anyhow!(\"No proxies configured\")))\n}\n\nasync fn connect_through_proxy(\n    proxy: \u0026ProxyConfig,\n    target: \u0026str,\n) -\u003e Result\u003cTcpStream\u003e {\n    let proxy_addr = parse_proxy_address(\u0026proxy.url)?;\n    let timeout = Duration::from_secs(10); // Connection attempt timeout\n\n    let stream = tokio::time::timeout(\n        timeout,\n        TcpStream::connect(\u0026proxy_addr)\n    ).await\n        .context(\"Connection timeout\")?\n        .context(\"Failed to connect to proxy\")?;\n\n    // Could add CONNECT handshake here if needed\n    Ok(stream)\n}\n```\n\n### Timeout Handling\n\nEach proxy attempt should have a reasonable timeout to avoid blocking forever:\n\n```rust\nconst TRY_ALL_TIMEOUT_PER_PROXY_SECS: u64 = 10;\nconst TRY_ALL_TOTAL_TIMEOUT_SECS: u64 = 60;\n```\n\n### Metrics\n\nTrack try_all attempts for observability:\n- `degradation_try_all_attempts_total` - total attempts made\n- `degradation_try_all_successes_total` - attempts that eventually succeeded\n- `degradation_try_all_failures_total` - all proxies failed\n\n## Acceptance Criteria\n\n- Tries each proxy in priority order\n- Stops on first success\n- Proper timeout per attempt\n- Clear logging of attempts and results\n- Returns success with proxy ID that worked","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:05:25.704408915-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:05:25.704408915-05:00","dependencies":[{"issue_id":"rust_proxy-7nv","depends_on_id":"rust_proxy-ny9","type":"blocks","created_at":"2026-01-18T14:07:30.980704217-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-7or","title":"Add atomic config reload mechanism with synchronization","description":"## Scope\n\nImplement the atomic config reload mechanism that safely swaps the active configuration while the daemon is running, with proper synchronization to avoid race conditions.\n\n## Rationale\n\nConfig reload must be atomic to prevent partial updates that could leave the daemon in an inconsistent state. For example, if we update the proxy list but crash before updating health check settings, we could have health checks running against stale proxy IDs.\n\n## Implementation Details\n\n### Config Holder with Arc\u003cRwLock\u003e\n\nThe daemon needs a shared, mutable config holder:\n\n```rust\npub struct ConfigHolder {\n    inner: Arc\u003cRwLock\u003cAppConfig\u003e\u003e,\n    path: PathBuf,\n}\n\nimpl ConfigHolder {\n    pub fn new(config: AppConfig, path: PathBuf) -\u003e Self {\n        Self {\n            inner: Arc::new(RwLock::new(config)),\n            path,\n        }\n    }\n\n    /// Get current config (cheap clone of Arc)\n    pub async fn get(\u0026self) -\u003e AppConfig {\n        self.inner.read().await.clone()\n    }\n\n    /// Attempt to reload config from disk\n    /// Returns Ok(Some(diff)) if reload succeeded with changes\n    /// Returns Ok(None) if config unchanged\n    /// Returns Err if config invalid (keeps running with old config)\n    pub async fn reload(\u0026self) -\u003e Result\u003cOption\u003cConfigDiff\u003e\u003e {\n        // 1. Load new config from disk\n        let new_config = match AppConfig::load_from(\u0026self.path) {\n            Ok(c) =\u003e c,\n            Err(e) =\u003e {\n                tracing::error!(error = %e, \"Failed to parse config, keeping current\");\n                return Err(e);\n            }\n        };\n\n        // 2. Validate new config\n        if let Err(e) = new_config.validate() {\n            tracing::error!(error = %e, \"New config invalid, keeping current\");\n            return Err(e.into());\n        }\n\n        // 3. Compute diff\n        let old_config = self.inner.read().await;\n        let diff = diff_configs(\u0026old_config, \u0026new_config);\n\n        if diff.is_empty() {\n            return Ok(None);\n        }\n\n        // 4. Log what's changing\n        diff.log();\n\n        // 5. Atomic swap\n        drop(old_config);\n        *self.inner.write().await = new_config;\n\n        tracing::info!(\"Configuration reloaded successfully\");\n        Ok(Some(diff))\n    }\n}\n```\n\n### Thread Safety Considerations\n\n- Use `RwLock` not `Mutex` - allows concurrent reads during normal operation\n- Write lock only held briefly during swap\n- All components that need config should hold `Arc\u003cConfigHolder\u003e` and call `get()` when needed\n- Avoid caching config in local variables for extended periods\n\n### Handling Components That Need Notification\n\nSome components need to react to config changes:\n- Health check loop: may need to adjust interval\n- Load balancer: may need to update proxy list\n\nUse a broadcast channel for change notifications:\n\n```rust\npub struct ConfigHolder {\n    inner: Arc\u003cRwLock\u003cAppConfig\u003e\u003e,\n    path: PathBuf,\n    change_tx: broadcast::Sender\u003cConfigDiff\u003e,\n}\n\nimpl ConfigHolder {\n    pub fn subscribe(\u0026self) -\u003e broadcast::Receiver\u003cConfigDiff\u003e {\n        self.change_tx.subscribe()\n    }\n}\n```\n\n## Acceptance Criteria\n\n- ConfigHolder provides thread-safe config access\n- reload() atomically swaps config\n- Invalid configs are rejected without affecting running config\n- Change notifications sent to subscribers\n- No race conditions during concurrent access and reload","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:55:48.314807599-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:55:48.314807599-05:00","dependencies":[{"issue_id":"rust_proxy-7or","depends_on_id":"rust_proxy-7s9","type":"blocks","created_at":"2026-01-18T13:57:06.89179342-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-7s9","title":"Implement config diff logic to detect what changed","description":"## Scope\n\nImplement logic to compare two AppConfig instances and produce a structured diff describing what changed. This enables targeted reload (only update what changed) and clear logging.\n\n## Rationale\n\nBlind full reload is wasteful and potentially disruptive. By knowing exactly what changed, we can:\n- Only restart components that need it\n- Provide clear logging (\"Added proxy 'new-proxy', changed health_check_interval from 30s to 60s\")\n- Avoid unnecessary connection disruption\n\n## Implementation Details\n\n### ConfigDiff Structure\n\n```rust\n#[derive(Debug, Default)]\npub struct ConfigDiff {\n    /// Proxies that were added\n    pub proxies_added: Vec\u003cString\u003e,\n    /// Proxies that were removed\n    pub proxies_removed: Vec\u003cString\u003e,\n    /// Proxies whose config changed (id, field, old, new)\n    pub proxies_modified: Vec\u003c(String, String, String, String)\u003e,\n    /// Settings that changed (name, old, new)\n    pub settings_changed: Vec\u003c(String, String, String)\u003e,\n    /// Whether listen address changed (requires restart)\n    pub listen_changed: bool,\n}\n\nimpl ConfigDiff {\n    pub fn is_empty(\u0026self) -\u003e bool {\n        self.proxies_added.is_empty()\n            \u0026\u0026 self.proxies_removed.is_empty()\n            \u0026\u0026 self.proxies_modified.is_empty()\n            \u0026\u0026 self.settings_changed.is_empty()\n            \u0026\u0026 !self.listen_changed\n    }\n\n    pub fn requires_restart(\u0026self) -\u003e bool {\n        self.listen_changed\n    }\n}\n```\n\n### Diff Function\n\n```rust\npub fn diff_configs(old: \u0026AppConfig, new: \u0026AppConfig) -\u003e ConfigDiff {\n    let mut diff = ConfigDiff::default();\n\n    // Compare proxy lists\n    let old_ids: HashSet\u003c_\u003e = old.proxies.iter().map(|p| \u0026p.id).collect();\n    let new_ids: HashSet\u003c_\u003e = new.proxies.iter().map(|p| \u0026p.id).collect();\n\n    for id in new_ids.difference(\u0026old_ids) {\n        diff.proxies_added.push(id.to_string());\n    }\n    for id in old_ids.difference(\u0026new_ids) {\n        diff.proxies_removed.push(id.to_string());\n    }\n\n    // Compare settings\n    if old.settings.health_check_interval_secs != new.settings.health_check_interval_secs {\n        diff.settings_changed.push((\n            \"health_check_interval_secs\".to_string(),\n            old.settings.health_check_interval_secs.to_string(),\n            new.settings.health_check_interval_secs.to_string(),\n        ));\n    }\n    // ... more settings comparisons\n\n    // Check listen address\n    if old.listen != new.listen {\n        diff.listen_changed = true;\n    }\n\n    diff\n}\n```\n\n### Logging Integration\n\n```rust\nimpl ConfigDiff {\n    pub fn log(\u0026self) {\n        for id in \u0026self.proxies_added {\n            tracing::info!(proxy_id = %id, \"Proxy added\");\n        }\n        for id in \u0026self.proxies_removed {\n            tracing::info!(proxy_id = %id, \"Proxy removed\");\n        }\n        for (name, old, new) in \u0026self.settings_changed {\n            tracing::info!(setting = %name, old = %old, new = %new, \"Setting changed\");\n        }\n        if self.listen_changed {\n            tracing::warn!(\"Listen address changed - restart required for this to take effect\");\n        }\n    }\n}\n```\n\n## Acceptance Criteria\n\n- ConfigDiff struct captures all meaningful changes\n- diff_configs() correctly identifies added/removed/modified proxies\n- diff_configs() correctly identifies changed settings\n- is_empty() and requires_restart() helpers work correctly\n- log() produces clear, actionable log output","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:11:31.627030973-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:11:31.627030973-05:00"}
{"id":"rust_proxy-7vt","title":"E2E tests for Prometheus metrics","description":"## E2E Tests for Prometheus Metrics\n\n### Test Scenarios\n\n1. **Metrics Endpoint Responds**\n   ```rust\n   #[tokio::test]\n   async fn test_metrics_endpoint_responds() {\n       let harness = TestHarness::with_config(r#\"\n           [settings]\n           metrics_enabled = true\n           metrics_port = 19090\n       \"#).await;\n       harness.start_daemon().await.unwrap();\n\n       let resp = reqwest::get(\"http://127.0.0.1:19090/metrics\").await.unwrap();\n       assert_eq!(resp.status(), 200);\n       let body = resp.text().await.unwrap();\n       assert!(body.contains(\"rust_proxy_\"));\n   }\n   ```\n\n2. **Metrics Reflect Health Check Activity**\n   ```rust\n   #[tokio::test]\n   async fn test_health_check_metrics() {\n       let mut harness = TestHarness::new().await;\n       harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       harness.start_daemon().await.unwrap();\n\n       // Wait for health checks\n       tokio::time::sleep(Duration::from_secs(10)).await;\n\n       let body = fetch_metrics(\u0026harness).await;\n       assert!(body.contains(\"rust_proxy_health_checks_total\"));\n       assert_metric_value(\u0026body, \"rust_proxy_proxy_health\", \"1\");\n   }\n   ```\n\n3. **Failover Events Tracked**\n   ```rust\n   #[tokio::test]\n   async fn test_failover_metric_increments() {\n       let mut harness = failover_test_harness().await;\n       trigger_failover(\u0026harness).await;\n\n       let body = fetch_metrics(\u0026harness).await;\n       assert!(body.contains(\"rust_proxy_failovers_total\"));\n   }\n   ```\n\n4. **Metrics Disabled When Configured**\n   ```rust\n   #[tokio::test]\n   async fn test_metrics_disabled() {\n       let harness = TestHarness::with_config(r#\"\n           [settings]\n           metrics_enabled = false\n       \"#).await;\n       harness.start_daemon().await.unwrap();\n\n       let result = reqwest::get(\"http://127.0.0.1:9090/metrics\").await;\n       assert!(result.is_err() || result.unwrap().status() != 200);\n   }\n   ```\n\n5. **Prometheus Scrape Compatible**\n   ```rust\n   #[tokio::test]\n   async fn test_prometheus_scrape_format() {\n       let harness = metrics_enabled_harness().await;\n       let body = fetch_metrics(\u0026harness).await;\n\n       // Verify Prometheus text format\n       assert!(body.lines().any(|l| l.starts_with(\"# HELP \")));\n       assert!(body.lines().any(|l| l.starts_with(\"# TYPE \")));\n   }\n   ```\n\n### Logging Requirements\n- Log daemon startup with metrics config\n- Log each metrics fetch response\n- Log metric values extracted for assertions\n- On failure, dump full metrics response\n\n### Dependencies\n- Requires: rust_proxy-cux (E2E Test Infrastructure)","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:53:57.113754662-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:53:57.113754662-05:00","dependencies":[{"issue_id":"rust_proxy-7vt","depends_on_id":"rust_proxy-cux","type":"blocks","created_at":"2026-01-18T14:56:35.696303047-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-7vt","depends_on_id":"rust_proxy-0zp","type":"blocks","created_at":"2026-01-18T14:56:49.672955468-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-8fy","title":"Add health check target configuration","description":"Add health_check_target setting to config: format 'CONNECT host:port' or 'GET url'. Parse and validate at config load time. Default to current behavior (CONNECT www.google.com:443).","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:16:38.710792311-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:16:38.710792311-05:00"}
{"id":"rust_proxy-8tb","title":"E2E tests for Shell Completion","description":"## E2E Tests for Shell Completion\n\n### Test Scenarios\n\n1. **Completions Install Detects Shell**\n   ```rust\n   #[tokio::test]\n   async fn test_completions_install_detects_shell() {\n       std::env::set_var(\"SHELL\", \"/bin/zsh\");\n       let harness = TestHarness::new().await;\n\n       let result = harness.run_command(\u0026[\"completions\", \"install\", \"--dry-run\"]);\n       assert!(result.success);\n       assert!(result.stdout.contains(\"Detected shell: zsh\"));\n   }\n   ```\n\n2. **Completions Install Creates File**\n   ```rust\n   #[tokio::test]\n   async fn test_completions_install_creates_file() {\n       let harness = TestHarness::new().await;\n       let temp_dir = harness.temp_dir.path();\n\n       let result = harness.run_command(\u0026[\n           \"completions\", \"install\",\n           \"--shell\", \"bash\",\n           \"--path\", \u0026temp_dir.join(\"completions/rp\").to_string_lossy()\n       ]);\n\n       assert!(result.success);\n       assert!(temp_dir.join(\"completions/rp\").exists());\n\n       let content = fs::read_to_string(temp_dir.join(\"completions/rp\")).unwrap();\n       assert!(content.contains(\"complete\"));\n   }\n   ```\n\n3. **Completions Install --shell Override**\n   ```rust\n   #[tokio::test]\n   async fn test_completions_install_shell_override() {\n       std::env::set_var(\"SHELL\", \"/bin/zsh\"); // Will be overridden\n       let harness = TestHarness::new().await;\n\n       let result = harness.run_command(\u0026[\n           \"completions\", \"install\",\n           \"--shell\", \"fish\",\n           \"--dry-run\"\n       ]);\n\n       assert!(result.success);\n       assert!(result.stdout.contains(\"fish\"));\n       assert!(!result.stdout.contains(\"zsh\"));\n   }\n   ```\n\n4. **Completions Uninstall Removes File**\n   ```rust\n   #[tokio::test]\n   async fn test_completions_uninstall() {\n       let harness = TestHarness::new().await;\n       let path = harness.temp_dir.path().join(\"rp\");\n\n       // First install\n       harness.run_command(\u0026[\n           \"completions\", \"install\",\n           \"--shell\", \"bash\",\n           \"--path\", \u0026path.to_string_lossy()\n       ]);\n       assert!(path.exists());\n\n       // Then uninstall\n       let result = harness.run_command(\u0026[\n           \"completions\", \"uninstall\",\n           \"--shell\", \"bash\",\n           \"--path\", \u0026path.to_string_lossy()\n       ]);\n\n       assert!(result.success);\n       assert!(!path.exists());\n       assert!(result.stdout.contains(\"Removed\"));\n   }\n   ```\n\n5. **Dry-Run Shows What Would Happen**\n   ```rust\n   #[tokio::test]\n   async fn test_completions_dry_run() {\n       let harness = TestHarness::new().await;\n\n       let result = harness.run_command(\u0026[\n           \"completions\", \"install\",\n           \"--shell\", \"bash\",\n           \"--dry-run\"\n       ]);\n\n       assert!(result.success);\n       assert!(result.stdout.contains(\"Would install\"));\n       assert!(result.stdout.contains(\"bash\"));\n\n       // Verify no file was created\n       let default_path = get_default_bash_completion_path();\n       // File shouldn't be created in dry-run\n   }\n   ```\n\n6. **Completions Print Outputs Script**\n   ```rust\n   #[tokio::test]\n   async fn test_completions_print() {\n       let harness = TestHarness::new().await;\n\n       let result = harness.run_command(\u0026[\"completions\", \"bash\"]);\n\n       assert!(result.success);\n       assert!(result.stdout.contains(\"complete -F\"));\n       assert!(result.stdout.contains(\"_rp\"));\n   }\n   ```\n\n7. **Actual Completion Works in Shell**\n   ```rust\n   #[tokio::test]\n   async fn test_completion_works_in_bash() {\n       let harness = TestHarness::new().await;\n       let completion_script = harness.run_command(\u0026[\"completions\", \"bash\"]).stdout;\n\n       // Source completion in bash and test\n       let bash_test = format!(r#\"\n           source \u003c(echo '{}')\n           # Simulate completion\n           COMP_WORDS=(rp sta)\n           COMP_CWORD=1\n           _rp\n           echo \"${{COMPREPLY[@]}}\"\n       \"#, completion_script);\n\n       let result = Command::new(\"bash\")\n           .arg(\"-c\")\n           .arg(\u0026bash_test)\n           .output()\n           .unwrap();\n\n       let output = String::from_utf8_lossy(\u0026result.stdout);\n       assert!(output.contains(\"start\") || output.contains(\"status\"));\n   }\n   ```\n\n### Logging Requirements\n- Log detected shell and source of detection\n- Log installation path being used\n- Log file operations (create, overwrite, delete)\n- On failure, log permission errors with suggestions\n\n### Dependencies\n- Requires: rust_proxy-cux (E2E Test Infrastructure)\n- Note: Shell-specific tests may need those shells installed","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:18.629854165-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:18.629854165-05:00","dependencies":[{"issue_id":"rust_proxy-8tb","depends_on_id":"rust_proxy-cux","type":"blocks","created_at":"2026-01-18T14:56:35.889126543-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-8tb","depends_on_id":"rust_proxy-ck6","type":"blocks","created_at":"2026-01-18T14:56:53.723521395-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-95g","title":"Feature: Better error messages with actionable suggestions","description":"Improve error messages to include context and suggested fixes. Instead of 'Connection refused', show 'Connection refused to proxy-a (192.168.1.50:3128). Check that the proxy is running and the address is correct.' Use thiserror or custom error types with rich context. Include suggestions based on common failure patterns.","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:15:20.420670021-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:15:20.420670021-05:00","dependencies":[{"issue_id":"rust_proxy-95g","depends_on_id":"rust_proxy-6q6","type":"blocks","created_at":"2026-01-18T15:04:33.25908216-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-95g","depends_on_id":"rust_proxy-x3z","type":"blocks","created_at":"2026-01-18T15:04:34.767891917-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-95g","depends_on_id":"rust_proxy-b2v","type":"blocks","created_at":"2026-01-18T15:04:35.870171249-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-98d","title":"Unit tests for Systemd Service Generation","description":"## Unit Tests for Systemd Service Generation\n\n### Test Coverage Areas\n\n1. **Service File Template**\n   ```rust\n   #[test]\n   fn test_service_file_has_required_sections() {\n       let service = generate_service_file(\u0026default_options());\n\n       assert!(service.contains(\"[Unit]\"));\n       assert!(service.contains(\"[Service]\"));\n       assert!(service.contains(\"[Install]\"));\n   }\n\n   #[test]\n   fn test_service_file_has_description() {\n       let service = generate_service_file(\u0026default_options());\n       assert!(service.contains(\"Description=\"));\n   }\n\n   #[test]\n   fn test_service_file_has_exec_start() {\n       let service = generate_service_file(\u0026default_options());\n       assert!(service.contains(\"ExecStart=\"));\n       assert!(service.contains(\"rp start\"));\n   }\n   ```\n\n2. **Executable Path Detection**\n   ```rust\n   #[test]\n   fn test_finds_current_executable() {\n       let path = get_executable_path().unwrap();\n       assert!(path.exists());\n   }\n\n   #[test]\n   fn test_custom_executable_path() {\n       let opts = ServiceOptions {\n           executable_path: Some(PathBuf::from(\"/usr/local/bin/rp\")),\n           ..default_options()\n       };\n       let service = generate_service_file(\u0026opts);\n       assert!(service.contains(\"/usr/local/bin/rp\"));\n   }\n   ```\n\n3. **User/Group Configuration**\n   ```rust\n   #[test]\n   fn test_default_user_is_root() {\n       let service = generate_service_file(\u0026default_options());\n       // Default should either be root or not specify User (which means root)\n   }\n\n   #[test]\n   fn test_custom_user_group() {\n       let opts = ServiceOptions {\n           user: Some(\"proxy\".to_string()),\n           group: Some(\"proxy\".to_string()),\n           ..default_options()\n       };\n       let service = generate_service_file(\u0026opts);\n       assert!(service.contains(\"User=proxy\"));\n       assert!(service.contains(\"Group=proxy\"));\n   }\n   ```\n\n4. **Security Hardening**\n   ```rust\n   #[test]\n   fn test_hardened_has_protections() {\n       let opts = ServiceOptions {\n           hardened: true,\n           ..default_options()\n       };\n       let service = generate_service_file(\u0026opts);\n\n       assert!(service.contains(\"ProtectSystem=\"));\n       assert!(service.contains(\"ProtectHome=\"));\n       assert!(service.contains(\"PrivateTmp=\"));\n       assert!(service.contains(\"NoNewPrivileges=\"));\n   }\n\n   #[test]\n   fn test_hardened_has_capability_restrictions() {\n       let opts = ServiceOptions {\n           hardened: true,\n           ..default_options()\n       };\n       let service = generate_service_file(\u0026opts);\n\n       assert!(service.contains(\"CapabilityBoundingSet=\"));\n   }\n\n   #[test]\n   fn test_non_hardened_minimal() {\n       let opts = ServiceOptions {\n           hardened: false,\n           ..default_options()\n       };\n       let service = generate_service_file(\u0026opts);\n\n       // Should not have aggressive restrictions\n       assert!(!service.contains(\"ProtectSystem=strict\"));\n   }\n   ```\n\n5. **Config Path Configuration**\n   ```rust\n   #[test]\n   fn test_config_path_in_exec() {\n       let opts = ServiceOptions {\n           config_path: Some(PathBuf::from(\"/etc/rp/config.toml\")),\n           ..default_options()\n       };\n       let service = generate_service_file(\u0026opts);\n       assert!(service.contains(\"--config /etc/rp/config.toml\") ||\n               service.contains(\"-c /etc/rp/config.toml\"));\n   }\n   ```\n\n6. **Reload Configuration**\n   ```rust\n   #[test]\n   fn test_has_exec_reload() {\n       let service = generate_service_file(\u0026default_options());\n       assert!(service.contains(\"ExecReload=\"));\n   }\n   ```\n\n7. **Logging Configuration**\n   ```rust\n   #[test]\n   fn test_logging_to_journal() {\n       let service = generate_service_file(\u0026default_options());\n       assert!(service.contains(\"StandardOutput=journal\") ||\n               service.contains(\"StandardOutput=syslog\"));\n       assert!(service.contains(\"SyslogIdentifier=\"));\n   }\n   ```\n\n### Validation Tests\n```rust\n#[test]\nfn test_validate_service_file_syntax() {\n    let service = generate_service_file(\u0026default_options());\n\n    // Basic INI format validation\n    for line in service.lines() {\n        let line = line.trim();\n        if line.is_empty() || line.starts_with('#') || line.starts_with('[') {\n            continue;\n        }\n        assert!(line.contains('='), \"Invalid line: {}\", line);\n    }\n}\n\n#[test]\nfn test_no_placeholder_left() {\n    let service = generate_service_file(\u0026default_options());\n    assert!(!service.contains(\"{{\"), \"Unresolved placeholder in service file\");\n    assert!(!service.contains(\"}}\"), \"Unresolved placeholder in service file\");\n}\n```\n\n### Test Files\n- `src/service.rs` - inline unit tests\n- `tests/unit/service_test.rs` - extended tests","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:20.358184448-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:20.358184448-05:00","dependencies":[{"issue_id":"rust_proxy-98d","depends_on_id":"rust_proxy-giu","type":"blocks","created_at":"2026-01-18T14:56:53.771180275-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-99b","title":"Implement service file template with placeholders","description":"## Scope\n\nImplement the systemd service file template with configurable placeholders.\n\n## Implementation Details\n\n```rust\nfn generate_service_file(\n    binary_path: \u0026Path,\n    config_path: \u0026Path,\n    user: \u0026str,\n    group: \u0026str,\n    hardened: bool,\n) -\u003e String {\n    let mut service = format!(r#\"[Unit]\nDescription=Rust Proxy - High-performance HTTPS proxy\nDocumentation=https://github.com/yourorg/rust_proxy\nAfter=network-online.target\nWants=network-online.target\n\n[Service]\nType=simple\nExecStart={binary} start --foreground --config {config}\nExecReload=/bin/kill -HUP $MAINPID\nRestart=on-failure\nRestartSec=5\nTimeoutStopSec=30\n\nUser={user}\nGroup={group}\n\n# Logging\nStandardOutput=journal\nStandardError=journal\nSyslogIdentifier=rp\n\n# Resource limits\nLimitNOFILE=65535\n\n\"#,\n        binary = binary_path.display(),\n        config = config_path.display(),\n        user = user,\n        group = group,\n    );\n\n    if hardened {\n        service.push_str(\u0026generate_hardening_section());\n    }\n\n    service.push_str(r#\"\n[Install]\nWantedBy=multi-user.target\n\"#);\n\n    service\n}\n```\n\n### Template Variables\n\n- `{binary}` - Full path to rp binary\n- `{config}` - Path to config file\n- `{user}` - Service user\n- `{group}` - Service group\n\n## Acceptance Criteria\n\n- Valid systemd unit file syntax\n- All placeholders replaced correctly\n- Works with systemd-analyze verify","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:09:36.864929167-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:09:36.864929167-05:00"}
{"id":"rust_proxy-amd","title":"Implement dry-run for service commands","description":"Add --dry-run to service install/uninstall. Show file operations that would be performed without actually executing them.","status":"closed","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:14:46.553053466-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:19:33.938400162-05:00","closed_at":"2026-01-18T15:19:33.938400162-05:00","close_reason":"Closed","dependencies":[{"issue_id":"rust_proxy-amd","depends_on_id":"rust_proxy-ar9","type":"blocks","created_at":"2026-01-18T14:15:02.790279472-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-ar9","title":"Add dry-run flag infrastructure","description":"Add DryRun trait/helper that provides consistent dry-run messaging across commands. Include would_do() method that prints 'Would: \u003caction\u003e' and returns early when dry_run is true.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:14:46.460319194-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:23:15.347234745-05:00"}
{"id":"rust_proxy-auj","title":"Add shell completion generation (bash/zsh/fish)","status":"closed","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T00:30:06.959425837-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T00:52:43.609528877-05:00","closed_at":"2026-01-18T00:52:43.609528877-05:00","close_reason":"Completed: added shell completion generation for bash/zsh/fish/powershell/elvish"}
{"id":"rust_proxy-b2v","title":"Integrate rich errors throughout codebase","description":"## Integrate Rich Errors Throughout Codebase\n\n### Overview\n\nReplace generic error messages throughout the codebase with rich error types that include context and suggestions. This is the integration work to make the error system actually useful.\n\n### Files to Update\n\n1. **src/proxy.rs** - Connection errors\n2. **src/health.rs** - Health check failures\n3. **src/config.rs** - Config parsing/validation\n4. **src/daemon.rs** - Startup failures\n5. **src/commands/*.rs** - CLI command errors\n\n### Migration Pattern\n\n**Before:**\n```rust\nTcpStream::connect(\u0026proxy_addr).await?;\n// Generic \"connection refused\" error\n```\n\n**After:**\n```rust\nTcpStream::connect(\u0026proxy_addr).await\n    .map_err(|e| ProxyError::ConnectionFailed {\n        proxy_id: proxy.id.clone(),\n        address: proxy_addr.clone(),\n        source: e,\n    })?;\n// Rich error with proxy context\n```\n\n### Integration Checklist\n\n**Proxy Connection (src/proxy.rs):**\n- [ ] Wrap connection errors with ProxyError::ConnectionFailed\n- [ ] Wrap timeout errors with ProxyError::Timeout\n- [ ] Wrap TLS errors with ProxyError::TlsError\n- [ ] Include proxy_id in all errors\n\n**Health Check (src/health.rs):**\n- [ ] Wrap check failures with HealthCheckError\n- [ ] Include target information\n- [ ] Include latency on timeout\n\n**Config (src/config.rs):**\n- [ ] Wrap TOML parse errors with line/column\n- [ ] Wrap validation errors with field information\n- [ ] Include file path in all errors\n\n**Daemon (src/daemon.rs):**\n- [ ] Wrap bind failures with DaemonError::PortInUse\n- [ ] Wrap PID file errors with DaemonError::PidFile\n- [ ] Include relevant paths/ports\n\n**CLI Commands:**\n- [ ] Use format_error_with_suggestions for all user-facing errors\n- [ ] Ensure JSON output includes error structure\n- [ ] Exit codes match error severity\n\n### Error Display Implementation\n\n```rust\n// In main.rs or cli.rs\nfn main() {\n    if let Err(e) = run() {\n        let formatted = if args.json {\n            error_to_json(\u0026*e)\n        } else {\n            format_error_with_suggestions(\u0026*e)\n        };\n        eprintln!(\"{}\", formatted);\n        std::process::exit(1);\n    }\n}\n```\n\n### Testing the Integration\n\nFor each error path:\n1. Trigger the error condition\n2. Verify error message includes context\n3. Verify suggestions are relevant\n4. Verify JSON format is valid\n\n### Acceptance Criteria\n\n- [ ] All proxy connection errors use ProxyError\n- [ ] All config errors use ConfigError with location\n- [ ] All daemon errors use DaemonError\n- [ ] format_error_with_suggestions used for CLI output\n- [ ] JSON output includes structured errors\n- [ ] No generic \"Error:\" messages without context\n- [ ] All errors have at least one suggestion","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:56:12.983528237-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:56:12.983528237-05:00","dependencies":[{"issue_id":"rust_proxy-b2v","depends_on_id":"rust_proxy-x3z","type":"blocks","created_at":"2026-01-18T14:57:07.455789467-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-b5m","title":"Implement automatic proxy health checks with failover","description":"## Overview\n\nAdd automatic health monitoring for configured proxies with intelligent failover to healthy alternatives when the active proxy becomes unavailable. This is a significant reliability feature that makes rust_proxy suitable for production use.\n\n## Background \u0026 Motivation\n\n**Current Problem:**\n- If active proxy becomes unreachable, connections fail silently or with cryptic errors\n- Users must manually detect the issue (often via user complaints)\n- Users must manually switch to another proxy via CLI\n- No visibility into proxy health status\n- Downtime continues until human intervention\n\n**Solution Benefits:**\n1. Continuous health monitoring of all proxies\n2. Quick detection of unhealthy proxies (configurable threshold)\n3. Automatic traffic rerouting to healthy alternatives\n4. Clear visibility into health status via `rust_proxy status`\n5. Reduced downtime from minutes/hours to seconds\n\n## Critical Design Decisions\n\n### 1. Runtime Active Proxy Management\n\n**Problem:** Current architecture loads config once at startup. Failover requires changing active proxy at runtime.\n\n**Solution:** Introduce `RuntimeState` separate from file-based Config:\n```rust\npub struct RuntimeState {\n    /// Currently active proxy (may differ from config.active_proxy during failover)\n    pub effective_proxy: Arc\u003cRwLock\u003cOption\u003cString\u003e\u003e\u003e,\n    /// Original active proxy (for failback)\n    pub original_proxy: Option\u003cString\u003e,\n    /// When failover occurred\n    pub failover_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n}\n\n// Daemon uses RuntimeState.effective_proxy instead of config.active_proxy\n// Failover updates RuntimeState without touching config file\n```\n\n### 2. Health Check Method\n\n**Problem:** Using external endpoints (httpbin.org) is unreliable and has privacy concerns.\n\n**Solution:** Test proxy connectivity directly:\n```rust\nasync fn health_check(proxy: \u0026ProxyDef, timeout: Duration) -\u003e HealthCheckResult {\n    // 1. TCP connect to proxy host:port\n    let stream = TcpStream::connect(\u0026proxy.addr()).await?;\n    \n    // 2. Send CONNECT to a well-known, stable endpoint\n    let request = format!(\n        \"CONNECT www.google.com:443 HTTP/1.1\\r\\nHost: www.google.com\\r\\n\\r\\n\"\n    );\n    stream.write_all(request.as_bytes()).await?;\n    \n    // 3. Read response line\n    let mut buf = [0u8; 1024];\n    let n = stream.read(\u0026mut buf).await?;\n    let response = String::from_utf8_lossy(\u0026buf[..n]);\n    \n    // 4. Check for success (200, 407 for auth, etc.)\n    if response.starts_with(\"HTTP/1.1 200\") || response.starts_with(\"HTTP/1.0 200\") {\n        Ok(HealthCheckResult::Healthy)\n    } else if response.contains(\"407\") {\n        // Proxy requires auth - still \"reachable\" but may need credentials\n        Ok(HealthCheckResult::AuthRequired)\n    } else {\n        Err(anyhow!(\"Unexpected response: {}\", response.lines().next().unwrap_or(\"\")))\n    }\n}\n```\n\n### 3. All Proxies Unhealthy Behavior\n\n**Problem:** What happens when ALL proxies are unhealthy?\n\n**Solution:** Configurable policy with safe default:\n```toml\n[settings]\n# When all proxies unhealthy:\n# - \"use_last\": keep using last proxy that was healthy (default, safest)\n# - \"fail_closed\": reject new connections (explicit failure)\n# - \"round_robin\": try proxies in rotation hoping one recovers\nall_unhealthy_policy = \"use_last\"\n```\n\nRationale for \"use_last\" default:\n- Proxy might still work for some requests\n- Better to try than to fail immediately\n- User gets errors but routing continues\n- Logging clearly indicates degraded state\n\n### 4. Flapping Prevention\n\n**Problem:** Unstable proxy rapidly toggles healthy/unhealthy, causing failover/failback churn.\n\n**Solution:** Multi-level hysteresis:\n```toml\n[settings]\n# Failures needed to mark unhealthy\nconsecutive_failures_threshold = 3\n\n# Successes needed to mark healthy again\nconsecutive_successes_threshold = 2\n\n# Minimum time between failovers (prevents rapid switching)\nmin_failover_interval_secs = 30\n\n# Time to wait after recovery before failback\nfailback_delay_secs = 60\n\n# Cooldown before retrying a failed proxy for failback\nfailed_proxy_cooldown_secs = 300\n```\n\n### 5. Startup Behavior\n\n**Problem:** Should daemon start immediately or wait for health check?\n\n**Solution:** Quick initial check with configurable blocking:\n```toml\n[settings]\n# On startup:\n# - \"async\": start immediately, check in background (default)\n# - \"blocking\": wait for first health check before accepting (slower but safer)\nstartup_health_check = \"async\"\n\n# If blocking, how long to wait for initial check\nstartup_health_timeout_secs = 10\n```\n\n## Configuration Schema\n\n```toml\n[settings]\n# === Health Check Settings ===\n# Master enable/disable\nhealth_check_enabled = true\n\n# How often to check each proxy\nhealth_check_interval_secs = 30\n\n# Timeout for individual health check\nhealth_check_timeout_ms = 5000\n\n# === Failure Detection ===\n# Consecutive failures before marking unhealthy\nconsecutive_failures_threshold = 3\n\n# Consecutive successes before marking healthy\nconsecutive_successes_threshold = 2\n\n# === Failover Settings ===\n# Automatically switch to healthy proxy\nauto_failover = true\n\n# What to do when all unhealthy: use_last | fail_closed | round_robin\nall_unhealthy_policy = \"use_last\"\n\n# Minimum seconds between failovers (flapping prevention)\nmin_failover_interval_secs = 30\n\n# === Failback Settings ===\n# Return to original proxy when it recovers\nauto_failback = true\n\n# Seconds to wait after recovery before failback\nfailback_delay_secs = 60\n\n# Seconds before retrying a failed proxy for failback consideration\nfailed_proxy_cooldown_secs = 300\n\n# === Startup ===\n# Startup mode: async | blocking\nstartup_health_check = \"async\"\n\n[[proxies]]\nid = \"mesh-us\"\nurl = \"http://us-wa.proxymesh.com:31280\"\npriority = 1  # Lower = higher priority for failover\n# Optional: custom health check endpoint (defaults to proxy's own CONNECT)\n# health_check_host = \"www.google.com\"\n# health_check_port = 443\n```\n\n## State Schema\n\n```rust\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProxyStats {\n    // Existing fields\n    pub bytes_sent: u64,\n    pub bytes_received: u64,\n    pub last_active: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub activated_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub ping_avg_ms: Option\u003cf64\u003e,\n    pub ping_samples: u64,\n    pub last_ping_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    \n    // New health fields\n    pub health_status: HealthStatus,\n    pub consecutive_failures: u32,\n    pub consecutive_successes: u32,\n    pub last_health_check: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub last_healthy: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub last_unhealthy: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub last_failure_reason: Option\u003cString\u003e,\n    pub health_check_latency_ms: Option\u003cf64\u003e,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, Default, PartialEq, Eq)]\npub enum HealthStatus {\n    #[default]\n    Unknown,\n    Healthy,\n    Unhealthy,\n    // Note: Removed \"Degraded\" - too complex to define, keep it simple\n}\n```\n\n## CLI Status Output\n\n```\nrust_proxy status\n\nActive Proxy: mesh-us\n  Status: ✓ Healthy\n  Latency: 45ms (last check: 5s ago)\n\nDaemon: running (pid 12345)\nRules: installed\n\nHealth Summary:\n  ID        Status      Priority  Latency   Last Check  Streak\n  mesh-us   ✓ Healthy   1         45ms      5s ago      5 ✓\n  mesh-eu   ✓ Healthy   2         120ms     5s ago      3 ✓\n  mesh-jp   ✗ Unhealthy 3         -         5s ago      3 ✗ (connection refused)\n\nHealth checks: enabled (interval: 30s, threshold: 3)\nAuto-failover: enabled\nAuto-failback: enabled (delay: 60s)\n```\n\n### Status During Failover\n```\nrust_proxy status\n\nActive Proxy: mesh-eu (FAILOVER from mesh-us)\n  Status: ✓ Healthy\n  Latency: 120ms (last check: 5s ago)\n  Failover at: 2025-01-18T12:00:00Z (2m ago)\n  Original proxy: mesh-us (currently unhealthy)\n\n...\n```\n\n## Logging\n\n### Health Check Events\n```\nINFO  health: Health check passed proxy=\"mesh-us\" latency_ms=45 streak=5\nWARN  health: Health check failed proxy=\"mesh-jp\" error=\"connection refused\" failures=3\nERROR health: Proxy marked unhealthy proxy=\"mesh-jp\" consecutive_failures=3\nINFO  health: Proxy recovered proxy=\"mesh-jp\" was_unhealthy_for=\"5m 23s\"\n```\n\n### Failover Events\n```\nWARN  failover: Active proxy unhealthy, initiating failover from=\"mesh-us\" reason=\"consecutive failures: 3\"\nINFO  failover: Failover complete from=\"mesh-us\" to=\"mesh-eu\" \nINFO  failover: Failback initiated to=\"mesh-us\" reason=\"original proxy recovered\"\nWARN  failover: All proxies unhealthy, policy=use_last using=\"mesh-eu\"\n```\n\n## File Changes Summary\n\n| File | Change |\n|------|--------|\n| `src/config.rs` | Add health check settings to Settings struct |\n| `src/config.rs` | Add priority field to ProxyDef |\n| `src/state.rs` | Add health fields to ProxyStats |\n| `src/state.rs` | Add RuntimeState struct |\n| `src/health.rs` | New module: health check logic |\n| `src/failover.rs` | New module: failover/failback logic |\n| `src/main.rs` | Spawn health check task in daemon |\n| `src/main.rs` | Update status command output |\n| `src/proxy.rs` | Use RuntimeState.effective_proxy |\n\n## Testing Requirements\n\nSee dedicated subtask for comprehensive test suite.\n\n## Rollout Strategy\n\n1. **Phase 1: Health Checks Only**\n   - Implement health check loop\n   - Add status visibility\n   - health_check_enabled = true, auto_failover = false\n   - Users can see health but no automatic action\n\n2. **Phase 2: Manual Failover**\n   - Add `rust_proxy failover \u003cproxy-id\u003e` command\n   - Users can manually trigger failover\n   \n3. **Phase 3: Auto-Failover**\n   - Enable auto_failover = true by default\n   - Full automatic operation\n\n## Risk Assessment\n\n- **Complexity**: High (new modules, state changes, daemon integration)\n- **Impact**: Very high (major reliability improvement for production use)\n- **Risk**: Medium (modifies core daemon behavior, needs careful testing)\n- **Confidence**: High (well-defined patterns, clear success criteria, phased rollout)\n\n## Mitigation Strategies\n\n- Feature flag: health_check_enabled (can disable entirely)\n- Phased rollout: health visibility before auto-failover\n- Extensive logging for debugging\n- Manual override: `rust_proxy activate --force` ignores health\n- Conservative defaults: long intervals, high thresholds\n\n## Dependencies\n\n- **Requires**: Accept loop error recovery (rust_proxy-j41) for robust daemon\n- **Enhances**: Status command with health information","status":"closed","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:49:15.780669041-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T10:49:42.936350577-05:00","closed_at":"2026-01-18T10:49:42.936350577-05:00","close_reason":"All implementation subtasks complete: health check configuration (b5m.1), state management (b5m.2), health check loop (b5m.3), failover logic (b5m.4), failback logic (b5m.5), status visibility (b5m.6), RuntimeState (b5m.8). Test suite (b5m.7) remains open as follow-up.","dependencies":[{"issue_id":"rust_proxy-b5m","depends_on_id":"rust_proxy-j41","type":"blocks","created_at":"2026-01-18T02:53:18.449147042-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-b5m.1","title":"Subtask: Add health check configuration options","description":"## Scope\nExtend the configuration schema to support health check settings.\n\n## Configuration Additions\n\n### Global Settings\nAdd to `[settings]` in config.toml:\n```toml\n[settings]\n# Health check configuration\nhealth_check_enabled = true        # Master toggle\nhealth_check_interval_secs = 30    # How often to check each proxy\nhealth_check_timeout_ms = 5000     # Timeout for health check connection\nconsecutive_failures_threshold = 3  # Failures before marking unhealthy\nauto_failover = true               # Automatically switch to healthy proxy\nauto_failback = true               # Return to original when recovered\nfailback_delay_secs = 60           # Wait before failback after recovery\n```\n\n### Per-Proxy Settings\nAdd to proxy definitions:\n```toml\n[[proxies]]\nid = \"mesh-us\"\nurl = \"http://us-wa.proxymesh.com:31280\"\npriority = 1  # Lower number = higher priority for failover selection\n# health_check_url = \"http://example.com\"  # Optional custom health check endpoint\n```\n\n## Code Changes\n\n### src/config.rs\n1. Add fields to `Settings` struct:\n   ```rust\n   pub health_check_enabled: bool,\n   pub health_check_interval_secs: u64,\n   pub health_check_timeout_ms: u64,\n   pub consecutive_failures_threshold: u32,\n   pub auto_failover: bool,\n   pub auto_failback: bool,\n   pub failback_delay_secs: u64,\n   ```\n2. Add field to `ProxyDef` struct:\n   ```rust\n   pub priority: Option\u003cu32\u003e,\n   pub health_check_url: Option\u003cString\u003e,\n   ```\n3. Add defaults in `impl Default for Settings`\n4. Update config validation (if check command exists)\n\n## Testing\n- Test config parsing with new fields\n- Test default values\n- Test config without new fields (backwards compatibility)\n- Test priority ordering","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:52:15.86666554-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:59:49.240051539-05:00","closed_at":"2026-01-18T04:59:49.240051539-05:00","close_reason":"Health check configuration options added to Settings and ProxyConfig structs with sensible defaults. All 62 tests passing.","dependencies":[{"issue_id":"rust_proxy-b5m.1","depends_on_id":"rust_proxy-b5m","type":"parent-child","created_at":"2026-01-18T02:52:15.891101037-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-b5m.2","title":"Subtask: Extend state management for health tracking","description":"## Scope\nExtend the state management system to track proxy health status.\n\n## State Extensions\n\n### src/state.rs\n\nAdd new types:\n```rust\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, Default, PartialEq)]\npub enum HealthStatus {\n    #[default]\n    Unknown,   // Not yet checked\n    Healthy,   // Passing health checks\n    Degraded,  // Slow but working (optional)\n    Unhealthy, // Failing health checks\n}\n\nimpl std::fmt::Display for HealthStatus {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        match self {\n            Self::Unknown =\u003e write!(f, \"unknown\"),\n            Self::Healthy =\u003e write!(f, \"healthy\"),\n            Self::Degraded =\u003e write!(f, \"degraded\"),\n            Self::Unhealthy =\u003e write!(f, \"unhealthy\"),\n        }\n    }\n}\n```\n\nExtend ProxyStats:\n```rust\n#[derive(Debug, Clone, Serialize, Deserialize, Default)]\npub struct ProxyStats {\n    // Existing fields...\n    pub bytes_sent: u64,\n    pub bytes_received: u64,\n    pub last_active: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub activated_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub ping_avg_ms: Option\u003cf64\u003e,\n    pub ping_samples: u64,\n    pub last_ping_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    \n    // New health fields\n    pub health_status: HealthStatus,\n    pub consecutive_failures: u32,\n    pub last_health_check: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub last_healthy: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub last_failure_reason: Option\u003cString\u003e,\n}\n```\n\nAdd StateStore methods:\n```rust\nimpl StateStore {\n    pub async fn record_health_check(\n        \u0026self, \n        proxy_id: \u0026str, \n        success: bool,\n        latency_ms: Option\u003cf64\u003e,\n        failure_reason: Option\u003cString\u003e,\n        threshold: u32,\n    ) {\n        // Update health status based on result\n        // Track consecutive failures\n        // Determine if status should change\n    }\n    \n    pub async fn get_health_status(\u0026self, proxy_id: \u0026str) -\u003e HealthStatus {\n        // Return current health status\n    }\n    \n    pub async fn get_healthy_proxies(\u0026self) -\u003e Vec\u003cString\u003e {\n        // Return list of healthy proxy IDs\n    }\n}\n```\n\n## Backwards Compatibility\n- New fields should have sensible defaults\n- Existing state.json files should load without error\n- Unknown enum variants should deserialize to Unknown\n\n## Testing\n- Test state serialization/deserialization with new fields\n- Test health status transitions\n- Test consecutive failure counting\n- Test backwards compatibility with old state files","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:52:24.448775593-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T05:04:02.950845722-05:00","closed_at":"2026-01-18T05:04:02.950845722-05:00","close_reason":"Extended state management with HealthStatus enum and health tracking fields in ProxyStats. Added StateStore methods for recording health checks and querying health status. All 62 tests passing.","dependencies":[{"issue_id":"rust_proxy-b5m.2","depends_on_id":"rust_proxy-b5m","type":"parent-child","created_at":"2026-01-18T02:52:24.461847335-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-b5m.3","title":"Subtask: Implement health check logic and daemon task","description":"## Scope\nImplement the core health check logic and integrate as a daemon task.\n\n## Health Check Implementation\n\n### New Module: src/health.rs\n```rust\nuse crate::config::{Config, ProxyDef};\nuse crate::state::StateStore;\nuse anyhow::Result;\nuse std::time::Duration;\nuse tokio::time::timeout;\n\n/// Perform a health check on a single proxy\npub async fn check_proxy_health(proxy: \u0026ProxyDef, timeout_ms: u64) -\u003e HealthCheckResult {\n    let timeout_dur = Duration::from_millis(timeout_ms);\n    let start = std::time::Instant::now();\n    \n    // 1. Resolve proxy host\n    // 2. TCP connect to proxy\n    // 3. Send HTTP CONNECT request\n    // 4. Check for 200 response\n    \n    let result = timeout(timeout_dur, async {\n        // Implementation\n    }).await;\n    \n    HealthCheckResult {\n        success: result.is_ok(),\n        latency_ms: start.elapsed().as_millis() as f64,\n        failure_reason: result.err().map(|e| e.to_string()),\n    }\n}\n\npub struct HealthCheckResult {\n    pub success: bool,\n    pub latency_ms: f64,\n    pub failure_reason: Option\u003cString\u003e,\n}\n\n/// Health check loop task for the daemon\npub async fn health_check_loop(\n    config: Config,\n    state: Arc\u003cStateStore\u003e,\n    mut shutdown: tokio::sync::watch::Receiver\u003cbool\u003e,\n) {\n    let interval = Duration::from_secs(config.settings.health_check_interval_secs);\n    let mut ticker = tokio::time::interval(interval);\n    \n    loop {\n        tokio::select! {\n            _ = ticker.tick() =\u003e {\n                for proxy in \u0026config.proxies {\n                    let result = check_proxy_health(\n                        proxy,\n                        config.settings.health_check_timeout_ms\n                    ).await;\n                    \n                    state.record_health_check(\n                        \u0026proxy.id,\n                        result.success,\n                        Some(result.latency_ms),\n                        result.failure_reason,\n                        config.settings.consecutive_failures_threshold,\n                    ).await;\n                }\n            }\n            _ = shutdown.changed() =\u003e {\n                tracing::info!(\"Health check loop shutting down\");\n                break;\n            }\n        }\n    }\n}\n```\n\n### Daemon Integration (src/main.rs)\nAdd health check task spawn alongside other daemon tasks:\n```rust\nif config.settings.health_check_enabled {\n    let health_state = state.clone();\n    let health_config = config.clone();\n    let health_shutdown = shutdown_rx.clone();\n    tokio::spawn(async move {\n        health::health_check_loop(health_config, health_state, health_shutdown).await;\n    });\n    tracing::info!(\"Health check loop started (interval: {}s)\", \n        config.settings.health_check_interval_secs);\n}\n```\n\n## Health Check Method\n1. TCP connect to proxy host:port\n2. Send: CONNECT httpbin.org:443 HTTP/1.1\\r\\nHost: httpbin.org\\r\\n\\r\\n\n3. Read response, check for HTTP/1.x 200\n4. Success if 200, failure otherwise\n\n## Testing\n- Unit test for health check logic\n- Test timeout handling\n- Test various failure modes\n- Integration test with mock proxy","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:52:34.141962257-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T05:09:30.538404704-05:00","closed_at":"2026-01-18T05:09:30.538404704-05:00","close_reason":"Implemented health check logic and integrated into daemon","dependencies":[{"issue_id":"rust_proxy-b5m.3","depends_on_id":"rust_proxy-b5m","type":"parent-child","created_at":"2026-01-18T02:52:34.153713131-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-b5m.4","title":"Subtask: Implement failover decision logic","description":"## Scope\nImplement the logic for automatic failover when the active proxy becomes unhealthy.\n\n## Failover Logic\n\n### src/health.rs additions\n```rust\n/// Check if failover should occur and perform it\npub async fn check_and_perform_failover(\n    config: \u0026Config,\n    state: \u0026StateStore,\n) -\u003e Option\u003cFailoverEvent\u003e {\n    // 1. Get current active proxy\n    let active = config.active_proxy.as_ref()?;\n    \n    // 2. Check if active proxy is unhealthy\n    let active_health = state.get_health_status(active).await;\n    if active_health != HealthStatus::Unhealthy {\n        return None; // No failover needed\n    }\n    \n    // 3. Find best healthy alternative\n    let alternative = find_best_healthy_proxy(config, state, active).await?;\n    \n    // 4. Perform failover (update config/state)\n    Some(FailoverEvent {\n        from_proxy: active.clone(),\n        to_proxy: alternative,\n        reason: \"health check failure\".to_string(),\n    })\n}\n\n/// Find the highest-priority healthy proxy (excluding current)\nasync fn find_best_healthy_proxy(\n    config: \u0026Config,\n    state: \u0026StateStore,\n    exclude: \u0026str,\n) -\u003e Option\u003cString\u003e {\n    let mut candidates: Vec\u003c_\u003e = config.proxies.iter()\n        .filter(|p| p.id != exclude)\n        .collect();\n    \n    // Sort by priority (lower = higher priority)\n    candidates.sort_by_key(|p| p.priority.unwrap_or(100));\n    \n    for proxy in candidates {\n        let health = state.get_health_status(\u0026proxy.id).await;\n        if health == HealthStatus::Healthy {\n            return Some(proxy.id.clone());\n        }\n    }\n    \n    None // No healthy alternatives\n}\n\npub struct FailoverEvent {\n    pub from_proxy: String,\n    pub to_proxy: String,\n    pub reason: String,\n}\n```\n\n### Failover Actions\nWhen failover is triggered:\n1. Log: \"Failover: {from} -\u003e {to} (reason: {reason})\"\n2. Update runtime active proxy\n3. Optionally: send notification (future enhancement)\n\n### Integration with Health Check Loop\n```rust\n// In health_check_loop, after recording health:\nif config.settings.auto_failover {\n    if let Some(event) = check_and_perform_failover(\u0026config, \u0026state).await {\n        tracing::warn!(\n            \"Failover triggered: {} -\u003e {} ({})\",\n            event.from_proxy, event.to_proxy, event.reason\n        );\n        // Note: actual config update requires careful handling\n        // May need to signal main loop or use shared mutable config\n    }\n}\n```\n\n## Considerations\n- Failover should be logged prominently\n- Consider hysteresis to prevent flapping\n- Runtime config update vs. restart requirement\n\n## Testing\n- Test failover triggers when active becomes unhealthy\n- Test priority ordering in proxy selection\n- Test no failover when no healthy alternatives\n- Test failover logging","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:52:44.17531474-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T10:34:49.132521869-05:00","closed_at":"2026-01-18T10:34:49.132521869-05:00","close_reason":"Implemented failover decision logic in health.rs: check_and_perform_failover(), find_best_healthy_proxy(), FailoverEvent struct, and integrated with health_check_loop","dependencies":[{"issue_id":"rust_proxy-b5m.4","depends_on_id":"rust_proxy-b5m","type":"parent-child","created_at":"2026-01-18T02:52:44.190196742-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-b5m.5","title":"Subtask: Implement failback logic","description":"## Scope\nImplement automatic failback to the original/primary proxy when it recovers.\n\n## Failback Logic\n\n### When to Failback\n1. Original primary proxy was failed away from\n2. Primary proxy health status returns to Healthy\n3. Healthy status persists for failback_delay_secs\n4. auto_failback is enabled\n\n### State Tracking\nNeed to track:\n- Original active proxy before failover\n- Time when recovery detected\n\nAdd to state or use separate tracking:\n```rust\npub struct FailoverState {\n    pub original_proxy: Option\u003cString\u003e,    // Proxy before first failover\n    pub failover_at: Option\u003cDateTime\u003cUtc\u003e\u003e, // When failover occurred\n    pub recovery_detected_at: Option\u003cDateTime\u003cUtc\u003e\u003e, // When original became healthy\n}\n```\n\n### Failback Implementation\n```rust\npub async fn check_and_perform_failback(\n    config: \u0026Config,\n    state: \u0026StateStore,\n    failover_state: \u0026mut FailoverState,\n) -\u003e Option\u003cFailbackEvent\u003e {\n    // 1. Check if we're in a failed-over state\n    let original = failover_state.original_proxy.as_ref()?;\n    \n    // 2. Check if original is now healthy\n    let original_health = state.get_health_status(original).await;\n    if original_health != HealthStatus::Healthy {\n        failover_state.recovery_detected_at = None;\n        return None;\n    }\n    \n    // 3. Track recovery time\n    let now = Utc::now();\n    let recovery_at = failover_state.recovery_detected_at\n        .get_or_insert(now);\n    \n    // 4. Check if delay has passed\n    let delay = Duration::from_secs(config.settings.failback_delay_secs);\n    let elapsed = now.signed_duration_since(*recovery_at);\n    if elapsed \u003c chrono::Duration::from_std(delay).unwrap() {\n        return None; // Still waiting\n    }\n    \n    // 5. Perform failback\n    let current = \u0026config.active_proxy;\n    failover_state.original_proxy = None;\n    failover_state.recovery_detected_at = None;\n    \n    Some(FailbackEvent {\n        from_proxy: current.clone().unwrap_or_default(),\n        to_proxy: original.clone(),\n    })\n}\n```\n\n### Logging\n```\nINFO Failback: mesh-eu -\u003e mesh-us (primary recovered after 65s)\n```\n\n## Considerations\n- Failback delay prevents flapping\n- Should verify primary is actually better (priority check)\n- May want to disable failback via config\n\n## Testing\n- Test failback triggers after recovery + delay\n- Test no failback during delay period\n- Test failback disabled when auto_failback=false\n- Test failback resets on re-failure","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:52:52.855531999-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T10:34:51.623426817-05:00","closed_at":"2026-01-18T10:34:51.623426817-05:00","close_reason":"Implemented failback logic in health.rs: check_and_perform_failback() with recovery detection and failback delay, integrated with health_check_loop","dependencies":[{"issue_id":"rust_proxy-b5m.5","depends_on_id":"rust_proxy-b5m","type":"parent-child","created_at":"2026-01-18T02:52:52.888141232-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-b5m.6","title":"Subtask: Update status command for health visibility","description":"## Scope\nExtend the 'rust_proxy status' command to display proxy health information.\n\n## Updated Status Output\n\n### Current Output\n```\nActive proxy: mesh-us\nRules: installed\nDaemon: running (pid 12345)\n```\n\n### Enhanced Output\n```\nActive proxy: mesh-us\nHealth: ✓ Healthy (last check: 5s ago, latency: 45ms)\nRules: installed\nDaemon: running (pid 12345)\n\nProxy Health Summary:\n  ID        Status     Priority  Latency   Last Check  Failures\n  mesh-us   ✓ Healthy  1         45ms      5s ago      0\n  mesh-eu   ✓ Healthy  2         120ms     5s ago      0  \n  mesh-jp   ✗ Unhealthy 3        -         5s ago      5\n```\n\n### JSON Output Enhancement\n```json\n{\n  \"active_proxy\": \"mesh-us\",\n  \"active_proxy_health\": {\n    \"status\": \"healthy\",\n    \"last_check\": \"2025-01-18T12:00:00Z\",\n    \"latency_ms\": 45,\n    \"consecutive_failures\": 0\n  },\n  \"rules_installed\": true,\n  \"daemon_running\": true,\n  \"proxy_health\": [\n    {\n      \"id\": \"mesh-us\",\n      \"status\": \"healthy\",\n      \"priority\": 1,\n      \"latency_ms\": 45,\n      \"last_check\": \"2025-01-18T12:00:00Z\",\n      \"consecutive_failures\": 0\n    }\n  ]\n}\n```\n\n## Implementation\n\n### src/main.rs status command\n```rust\nfn format_health_status(status: HealthStatus) -\u003e ColoredString {\n    match status {\n        HealthStatus::Healthy =\u003e \"✓ Healthy\".green(),\n        HealthStatus::Degraded =\u003e \"⚠ Degraded\".yellow(),\n        HealthStatus::Unhealthy =\u003e \"✗ Unhealthy\".red(),\n        HealthStatus::Unknown =\u003e \"? Unknown\".dimmed(),\n    }\n}\n\nfn format_time_ago(dt: Option\u003cDateTime\u003cUtc\u003e\u003e) -\u003e String {\n    dt.map(|t| {\n        let ago = Utc::now().signed_duration_since(t);\n        if ago.num_seconds() \u003c 60 {\n            format!(\"{}s ago\", ago.num_seconds())\n        } else if ago.num_minutes() \u003c 60 {\n            format!(\"{}m ago\", ago.num_minutes())\n        } else {\n            format!(\"{}h ago\", ago.num_hours())\n        }\n    }).unwrap_or_else(|| \"never\".to_string())\n}\n```\n\n## Conditional Display\n- Only show health table if health_check_enabled\n- Show \"Health checks disabled\" if not enabled\n\n## Testing\n- Test status output with healthy proxies\n- Test status output with unhealthy proxies\n- Test JSON output format\n- Test when health checks disabled","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:53:03.651618843-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T10:39:28.619471222-05:00","closed_at":"2026-01-18T10:39:28.619471222-05:00","close_reason":"Updated status command to display proxy health information including health status, last check time, latency, and a health summary table. Both human-readable and JSON output formats enhanced.","dependencies":[{"issue_id":"rust_proxy-b5m.6","depends_on_id":"rust_proxy-b5m","type":"parent-child","created_at":"2026-01-18T02:53:03.666369166-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-b5m.7","title":"Subtask: Comprehensive test suite for health checks","description":"## Scope\nCreate comprehensive unit tests, integration tests, and E2E tests for the health check and failover system.\n\n## Unit Tests\n\n### Health Check Logic Tests (`src/health.rs`)\n```rust\n#[tokio::test]\nasync fn test_health_check_success() {\n    let mock_proxy = start_mock_proxy(|_| \"HTTP/1.1 200 OK\\r\\n\\r\\n\");\n    let result = health_check(\u0026mock_proxy.addr(), Duration::from_secs(5)).await;\n    assert!(matches!(result, Ok(HealthCheckResult::Healthy)));\n}\n\n#[tokio::test]\nasync fn test_health_check_auth_required() {\n    let mock_proxy = start_mock_proxy(|_| \"HTTP/1.1 407 Proxy Auth Required\\r\\n\\r\\n\");\n    let result = health_check(\u0026mock_proxy.addr(), Duration::from_secs(5)).await;\n    assert!(matches!(result, Ok(HealthCheckResult::AuthRequired)));\n}\n\n#[tokio::test]\nasync fn test_health_check_connection_refused() {\n    let result = health_check(\"127.0.0.1:59999\", Duration::from_secs(1)).await;\n    assert!(result.is_err());\n}\n\n#[tokio::test]\nasync fn test_health_check_timeout() {\n    let mock_proxy = start_mock_proxy(|_| {\n        std::thread::sleep(Duration::from_secs(10));\n        \"HTTP/1.1 200 OK\\r\\n\\r\\n\"\n    });\n    let result = health_check(\u0026mock_proxy.addr(), Duration::from_millis(100)).await;\n    assert!(result.is_err());\n}\n```\n\n### State Transition Tests\n```rust\n#[test]\nfn test_transition_to_unhealthy() {\n    let mut stats = ProxyStats::default();\n    let threshold = 3;\n    \n    // 2 failures: still healthy/unknown\n    record_health_failure(\u0026mut stats, \"error 1\", threshold);\n    record_health_failure(\u0026mut stats, \"error 2\", threshold);\n    assert_ne!(stats.health_status, HealthStatus::Unhealthy);\n    \n    // 3rd failure: becomes unhealthy\n    record_health_failure(\u0026mut stats, \"error 3\", threshold);\n    assert_eq!(stats.health_status, HealthStatus::Unhealthy);\n    assert_eq!(stats.consecutive_failures, 3);\n}\n\n#[test]\nfn test_transition_to_healthy() {\n    let mut stats = ProxyStats {\n        health_status: HealthStatus::Unhealthy,\n        consecutive_failures: 5,\n        ..Default::default()\n    };\n    let threshold = 2;\n    \n    // 1 success: still unhealthy\n    record_health_success(\u0026mut stats, 45.0, threshold);\n    assert_eq!(stats.health_status, HealthStatus::Unhealthy);\n    \n    // 2nd success: becomes healthy\n    record_health_success(\u0026mut stats, 42.0, threshold);\n    assert_eq!(stats.health_status, HealthStatus::Healthy);\n    assert_eq!(stats.consecutive_failures, 0);\n}\n\n#[test]\nfn test_failure_resets_success_streak() {\n    let mut stats = ProxyStats {\n        health_status: HealthStatus::Unhealthy,\n        consecutive_successes: 1,\n        ..Default::default()\n    };\n    \n    record_health_failure(\u0026mut stats, \"error\", 3);\n    assert_eq!(stats.consecutive_successes, 0);\n}\n```\n\n### Failover Decision Tests (`src/failover.rs`)\n```rust\n#[test]\nfn test_should_failover_active_unhealthy() {\n    let state = test_state_with_health(vec![\n        (\"proxy1\", HealthStatus::Unhealthy),  // active\n        (\"proxy2\", HealthStatus::Healthy),\n    ]);\n    let config = test_config_with_active(\"proxy1\");\n    \n    assert!(should_failover(\u0026config, \u0026state));\n}\n\n#[test]\nfn test_should_not_failover_active_healthy() {\n    let state = test_state_with_health(vec![\n        (\"proxy1\", HealthStatus::Healthy),  // active\n        (\"proxy2\", HealthStatus::Healthy),\n    ]);\n    let config = test_config_with_active(\"proxy1\");\n    \n    assert!(!should_failover(\u0026config, \u0026state));\n}\n\n#[test]\nfn test_select_failover_target_by_priority() {\n    let state = test_state_with_health(vec![\n        (\"proxy1\", HealthStatus::Unhealthy),  // priority 1, active\n        (\"proxy2\", HealthStatus::Healthy),    // priority 3\n        (\"proxy3\", HealthStatus::Healthy),    // priority 2\n    ]);\n    let config = test_config_with_priorities(vec![\n        (\"proxy1\", 1),\n        (\"proxy2\", 3),\n        (\"proxy3\", 2),\n    ]);\n    \n    let target = select_failover_target(\u0026config, \u0026state, \"proxy1\");\n    assert_eq!(target, Some(\"proxy3\".to_string())); // priority 2 is next best\n}\n\n#[test]\nfn test_no_failover_target_all_unhealthy() {\n    let state = test_state_with_health(vec![\n        (\"proxy1\", HealthStatus::Unhealthy),\n        (\"proxy2\", HealthStatus::Unhealthy),\n    ]);\n    \n    let target = select_failover_target(\u0026config, \u0026state, \"proxy1\");\n    assert!(target.is_none());\n}\n```\n\n### Failback Decision Tests\n```rust\n#[test]\nfn test_should_failback_original_recovered() {\n    let runtime_state = RuntimeState {\n        effective_proxy: Arc::new(RwLock::new(Some(\"proxy2\".to_string()))),\n        original_proxy: Some(\"proxy1\".to_string()),\n        failover_at: Some(Utc::now() - chrono::Duration::minutes(5)),\n    };\n    let proxy_state = test_state_with_health(vec![\n        (\"proxy1\", HealthStatus::Healthy),\n    ]);\n    let config = test_config_with_failback_delay(60);\n    \n    // Original is healthy and failback delay passed\n    assert!(should_failback(\u0026config, \u0026runtime_state, \u0026proxy_state));\n}\n\n#[test]\nfn test_should_not_failback_delay_not_passed() {\n    let runtime_state = RuntimeState {\n        original_proxy: Some(\"proxy1\".to_string()),\n        failover_at: Some(Utc::now() - chrono::Duration::seconds(30)),\n        ..\n    };\n    let config = test_config_with_failback_delay(60);\n    \n    // Only 30s passed, need 60s\n    assert!(!should_failback(\u0026config, \u0026runtime_state, \u0026proxy_state));\n}\n\n#[test]\nfn test_should_not_failback_original_still_unhealthy() {\n    let runtime_state = RuntimeState {\n        original_proxy: Some(\"proxy1\".to_string()),\n        failover_at: Some(Utc::now() - chrono::Duration::minutes(5)),\n        ..\n    };\n    let proxy_state = test_state_with_health(vec![\n        (\"proxy1\", HealthStatus::Unhealthy),\n    ]);\n    \n    assert!(!should_failback(\u0026config, \u0026runtime_state, \u0026proxy_state));\n}\n```\n\n### Flapping Prevention Tests\n```rust\n#[test]\nfn test_min_failover_interval() {\n    let runtime_state = RuntimeState {\n        last_failover_at: Some(Utc::now() - chrono::Duration::seconds(10)),\n        ..\n    };\n    let config = test_config_with_min_failover_interval(30);\n    \n    // Only 10s since last failover, need 30s\n    assert!(!can_failover(\u0026config, \u0026runtime_state));\n}\n\n#[test]\nfn test_failover_allowed_after_interval() {\n    let runtime_state = RuntimeState {\n        last_failover_at: Some(Utc::now() - chrono::Duration::seconds(60)),\n        ..\n    };\n    let config = test_config_with_min_failover_interval(30);\n    \n    assert!(can_failover(\u0026config, \u0026runtime_state));\n}\n```\n\n### All Unhealthy Policy Tests\n```rust\n#[test]\nfn test_all_unhealthy_use_last() {\n    let state = test_state_with_all_unhealthy();\n    let config = test_config_with_policy(\"use_last\");\n    \n    let effective = get_effective_proxy(\u0026config, \u0026state, \u0026runtime_state);\n    // Should return the last known proxy\n    assert!(effective.is_some());\n}\n\n#[test]\nfn test_all_unhealthy_fail_closed() {\n    let state = test_state_with_all_unhealthy();\n    let config = test_config_with_policy(\"fail_closed\");\n    \n    let effective = get_effective_proxy(\u0026config, \u0026state, \u0026runtime_state);\n    assert!(effective.is_none());\n}\n```\n\n## Integration Tests (`tests/health_integration.rs`)\n\n```rust\n#[tokio::test]\nasync fn test_health_check_loop_updates_state() {\n    let state = Arc::new(StateStore::new_in_memory());\n    let config = test_config();\n    \n    // Run one iteration of health check loop\n    run_health_check_iteration(\u0026config, \u0026state).await;\n    \n    // Verify state was updated\n    let proxy_state = state.get_proxy_stats(\"proxy1\").await;\n    assert!(proxy_state.last_health_check.is_some());\n}\n\n#[tokio::test]\nasync fn test_failover_updates_runtime_state() {\n    // Setup with unhealthy active proxy\n    let runtime_state = Arc::new(RwLock::new(RuntimeState::new(\"proxy1\")));\n    let proxy_state = test_state_with_health(vec![\n        (\"proxy1\", HealthStatus::Unhealthy),\n        (\"proxy2\", HealthStatus::Healthy),\n    ]);\n    \n    perform_failover(\u0026config, \u0026runtime_state, \u0026proxy_state).await;\n    \n    let rs = runtime_state.read().await;\n    assert_eq!(rs.effective_proxy.as_deref(), Some(\"proxy2\"));\n    assert_eq!(rs.original_proxy.as_deref(), Some(\"proxy1\"));\n}\n```\n\n## E2E Test Script (`tests/e2e/health_failover.sh`)\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\necho \"=== E2E Test: Health Checks \u0026 Failover ===\"\n\n# Setup: Start mock proxy servers\necho \"[1/6] Starting mock proxies...\"\n# mock_proxy1 on :18081 (will be made unhealthy)\n# mock_proxy2 on :18082 (backup)\n\n# Start daemon with both proxies configured\necho \"[2/6] Starting daemon...\"\nsudo ./target/release/rust_proxy daemon \u0026\nDAEMON_PID=$!\nsleep 3\n\n# Verify both proxies show healthy\necho \"[3/6] Verifying initial health status...\"\nOUTPUT=$(./target/release/rust_proxy status)\nif echo \"$OUTPUT\" | grep -q \"✓ Healthy\"; then\n    echo \"✓ PASS: Proxies initially healthy\"\nelse\n    echo \"✗ FAIL: Proxies should be healthy\"\n    exit 1\nfi\n\n# Kill mock_proxy1 to simulate failure\necho \"[4/6] Simulating proxy1 failure...\"\nkill $MOCK_PROXY1_PID\nsleep 5  # Wait for health checks to detect\n\n# Check that proxy1 is unhealthy\necho \"[5/6] Verifying failover occurred...\"\nOUTPUT=$(./target/release/rust_proxy status)\nif echo \"$OUTPUT\" | grep -q \"FAILOVER\"; then\n    echo \"✓ PASS: Failover detected\"\nelse\n    echo \"✗ FAIL: Failover should have occurred\"\n    exit 1\nfi\n\n# Restart mock_proxy1 and verify failback\necho \"[6/6] Testing failback...\"\n# start mock_proxy1 again\nsleep 120  # Wait for failback delay\nOUTPUT=$(./target/release/rust_proxy status)\n# Verify failback occurred\n\n# Cleanup\nsudo kill $DAEMON_PID\n\necho \"=== Test Complete ===\"\n```\n\n## Test Coverage Requirements\n\n1. **Health check logic**\n   - Success, auth required, connection refused, timeout\n   - Various HTTP response codes\n\n2. **State transitions**\n   - Unknown -\u003e Healthy\n   - Healthy -\u003e Unhealthy\n   - Unhealthy -\u003e Healthy\n   - Success/failure streak counting\n\n3. **Failover decisions**\n   - When to trigger failover\n   - Target selection by priority\n   - No target available scenario\n\n4. **Failback decisions**\n   - Delay period enforcement\n   - Original proxy recovery detection\n\n5. **Flapping prevention**\n   - Minimum interval enforcement\n   - Consecutive threshold behavior\n\n6. **All-unhealthy policies**\n   - use_last, fail_closed, round_robin\n\n7. **CLI visibility**\n   - Status output with health info\n   - JSON output format","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T03:11:00.353175106-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T03:11:00.353175106-05:00","dependencies":[{"issue_id":"rust_proxy-b5m.7","depends_on_id":"rust_proxy-b5m","type":"parent-child","created_at":"2026-01-18T03:11:00.354534437-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-b5m.8","title":"Subtask: Implement RuntimeState for dynamic proxy management","description":"## Scope\nImplement RuntimeState to manage dynamic active proxy changes without modifying config file.\n\n## Problem\nCurrent architecture loads config.active_proxy once at startup. Failover requires changing the active proxy at runtime, but:\n- Modifying config file during operation is error-prone\n- Config file should represent user intent, not runtime state\n- Need atomic updates without file I/O\n\n## Solution: RuntimeState\n\n### Data Structure\n```rust\n// src/state.rs\n\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n/// Runtime state that can change during daemon operation\n/// Separate from Config (user intent) and StateStore (persistent stats)\n#[derive(Debug)]\npub struct RuntimeState {\n    /// Currently effective proxy (may differ from config during failover)\n    effective_proxy: Arc\u003cRwLock\u003cOption\u003cString\u003e\u003e\u003e,\n    \n    /// Original active proxy from config (for failback)\n    original_proxy: Option\u003cString\u003e,\n    \n    /// When current failover state began (None if no active failover)\n    failover_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    \n    /// When last failover/failback occurred (for min interval check)\n    last_switch_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    \n    /// Recovery detection timestamp (for failback delay)\n    recovery_detected_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n}\n\nimpl RuntimeState {\n    /// Create from config on daemon startup\n    pub fn from_config(config: \u0026Config) -\u003e Self {\n        Self {\n            effective_proxy: Arc::new(RwLock::new(config.active_proxy.clone())),\n            original_proxy: config.active_proxy.clone(),\n            failover_at: None,\n            last_switch_at: None,\n            recovery_detected_at: None,\n        }\n    }\n    \n    /// Get currently effective proxy (may be failover target)\n    pub async fn get_effective_proxy(\u0026self) -\u003e Option\u003cString\u003e {\n        self.effective_proxy.read().await.clone()\n    }\n    \n    /// Check if we're in a failover state\n    pub fn is_failed_over(\u0026self) -\u003e bool {\n        self.failover_at.is_some()\n    }\n    \n    /// Perform failover to a new proxy\n    pub async fn failover_to(\u0026self, new_proxy: \u0026str) -\u003e Result\u003c()\u003e {\n        let mut effective = self.effective_proxy.write().await;\n        *effective = Some(new_proxy.to_string());\n        self.failover_at = Some(Utc::now());\n        self.last_switch_at = Some(Utc::now());\n        self.recovery_detected_at = None;\n        Ok(())\n    }\n    \n    /// Perform failback to original proxy\n    pub async fn failback(\u0026self) -\u003e Result\u003c()\u003e {\n        let mut effective = self.effective_proxy.write().await;\n        *effective = self.original_proxy.clone();\n        self.failover_at = None;\n        self.last_switch_at = Some(Utc::now());\n        self.recovery_detected_at = None;\n        Ok(())\n    }\n    \n    /// Record that original proxy has recovered (start failback timer)\n    pub fn record_recovery_detected(\u0026mut self) {\n        if self.recovery_detected_at.is_none() {\n            self.recovery_detected_at = Some(Utc::now());\n        }\n    }\n    \n    /// Clear recovery detection (original failed again)\n    pub fn clear_recovery_detected(\u0026mut self) {\n        self.recovery_detected_at = None;\n    }\n    \n    /// Check if enough time has passed for failback\n    pub fn failback_delay_passed(\u0026self, delay_secs: u64) -\u003e bool {\n        self.recovery_detected_at\n            .map(|t| Utc::now().signed_duration_since(t).num_seconds() \u003e= delay_secs as i64)\n            .unwrap_or(false)\n    }\n    \n    /// Check if enough time has passed since last switch (flapping prevention)\n    pub fn can_switch(\u0026self, min_interval_secs: u64) -\u003e bool {\n        self.last_switch_at\n            .map(|t| Utc::now().signed_duration_since(t).num_seconds() \u003e= min_interval_secs as i64)\n            .unwrap_or(true)\n    }\n}\n```\n\n### Integration with Daemon\n\n```rust\n// In daemon startup:\nlet runtime_state = Arc::new(RwLock::new(RuntimeState::from_config(\u0026config)));\n\n// Pass to all tasks that need current proxy:\nlet proxy_runtime = runtime_state.clone();\ntokio::spawn(async move {\n    run_proxy(listener, config, proxy_runtime).await\n});\n\n// In proxy.rs:\nasync fn run_proxy(\n    listener: TcpListener,\n    config: Config,\n    runtime: Arc\u003cRwLock\u003cRuntimeState\u003e\u003e,\n) -\u003e Result\u003c()\u003e {\n    loop {\n        let (client, _) = listener.accept().await?;\n        \n        // Get currently effective proxy\n        let proxy_id = {\n            let rs = runtime.read().await;\n            rs.get_effective_proxy().await\n        };\n        \n        let proxy = config.proxies.iter()\n            .find(|p| Some(\u0026p.id) == proxy_id.as_ref());\n        \n        // Handle connection with current effective proxy\n        tokio::spawn(handle_client(client, proxy.cloned(), config.clone()));\n    }\n}\n```\n\n### Status Display\n\n```rust\n// Show runtime state in status command\nasync fn show_status(config: \u0026Config, state: \u0026StateStore, runtime: \u0026RuntimeState) {\n    let effective = runtime.get_effective_proxy().await;\n    let is_failover = runtime.is_failed_over();\n    \n    if is_failover {\n        println\\!(\"Active Proxy: {} (FAILOVER from {})\", \n            effective.as_deref().unwrap_or(\"none\"),\n            runtime.original_proxy.as_deref().unwrap_or(\"unknown\"));\n        if let Some(at) = runtime.failover_at {\n            println\\!(\"  Failover at: {} ({} ago)\", at, format_duration(Utc::now() - at));\n        }\n    } else {\n        println\\!(\"Active Proxy: {}\", effective.as_deref().unwrap_or(\"none\"));\n    }\n}\n```\n\n## Testing\n- Test RuntimeState initialization from config\n- Test failover updates effective proxy\n- Test failback restores original\n- Test flapping prevention timing\n- Test failback delay timing\n- Test concurrent access (Arc\u003cRwLock\u003e)","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T03:11:27.886394019-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T10:31:09.871760148-05:00","closed_at":"2026-01-18T10:31:09.871760148-05:00","close_reason":"RuntimeState implemented with all required methods: new(), get_effective_proxy(), get_original_proxy(), is_failed_over(), get_failover_at(), failover_to(), failback(), record_recovery_detected(), clear_recovery_detected(), failback_delay_passed(), can_switch(), get_status_snapshot()","dependencies":[{"issue_id":"rust_proxy-b5m.8","depends_on_id":"rust_proxy-b5m","type":"parent-child","created_at":"2026-01-18T03:11:27.888043997-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-bjc","title":"Fix silent proxy error and improve refresh logging","description":"Fixed two issues found during code review:\n1. BUG: Proxy task errors were silently ignored - if run_proxy returned Err (e.g., port already in use), the daemon would exit without logging why. Now properly logs Ok(Ok), Ok(Err), and Err(JoinError) cases.\n2. Minor: Refresh loop only logged when target count changed, not when actual entries changed. Now compares entries directly for accurate change detection.\n3. Minor: Removed unnecessary async from start_flush_loop since it just spawns a task and returns.","status":"closed","priority":2,"issue_type":"bug","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:08:14.778688171-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:08:25.337142219-05:00","closed_at":"2026-01-18T02:08:25.337142219-05:00","close_reason":"Fixed: proxy error logging now handles all cases, refresh logging compares actual entries, removed unnecessary async"}
{"id":"rust_proxy-btn","title":"Implement dry-run for stop command","description":"## Implement Dry-Run for Stop Command\n\n### Overview\n\nAdd --dry-run support to the stop command so users can see what would happen without actually stopping the daemon.\n\n### User Experience\n\n```bash\n$ rp stop --dry-run\nWould stop daemon process (PID: 12345)\nWould remove PID file at /var/run/rp.pid\nWould close 3 active connections\n\nNo changes made (dry-run mode)\n\n$ rp stop -n  # short flag\nWould stop daemon process (PID: 12345)\n...\n```\n\n### Implementation\n\n```rust\npub async fn stop_command(args: StopArgs) -\u003e Result\u003c()\u003e {\n    let ctx = if args.dry_run {\n        Some(DryRunContext::new())\n    } else {\n        None\n    };\n\n    // Check if daemon is running\n    let pid = match read_pid_file() {\n        Ok(pid) =\u003e pid,\n        Err(_) =\u003e {\n            if args.dry_run {\n                println!(\"Daemon is not running. Nothing to do.\");\n            }\n            return Ok(());\n        }\n    };\n\n    if let Some(ref ctx) = ctx {\n        ctx.would_do(\u0026format!(\"Stop daemon process (PID: {})\", pid));\n        ctx.would_do(\u0026format!(\"Remove PID file at {}\", pid_file_path().display()));\n\n        // Check for active connections if possible\n        if let Ok(conn_count) = get_active_connection_count(pid) {\n            if conn_count \u003e 0 {\n                ctx.would_do(\u0026format!(\"Close {} active connection(s)\", conn_count));\n            }\n        }\n\n        println!(\"{}\", ctx.format());\n        println!(\"\\nNo changes made (dry-run mode)\");\n        return Ok(());\n    }\n\n    // Actual stop logic\n    stop_daemon(pid).await?;\n    remove_pid_file()?;\n    println!(\"Daemon stopped\");\n    Ok(())\n}\n```\n\n### CLI Integration\n\n```rust\n#[derive(Parser)]\npub struct StopArgs {\n    /// Show what would happen without actually stopping\n    #[arg(short = 'n', long)]\n    pub dry_run: bool,\n\n    /// Output in JSON format\n    #[arg(long)]\n    pub json: bool,\n}\n```\n\n### JSON Output\n\n```json\n{\n  \"dry_run\": true,\n  \"actions\": [\n    \"Stop daemon process (PID: 12345)\",\n    \"Remove PID file at /var/run/rp.pid\",\n    \"Close 3 active connections\"\n  ],\n  \"would_affect\": {\n    \"pid\": 12345,\n    \"pid_file\": \"/var/run/rp.pid\",\n    \"active_connections\": 3\n  }\n}\n```\n\n### Acceptance Criteria\n\n- [ ] --dry-run flag available on stop command\n- [ ] -n short form works\n- [ ] Shows PID that would be stopped\n- [ ] Shows PID file that would be removed\n- [ ] Shows connection count if available\n- [ ] Does NOT actually stop daemon\n- [ ] JSON output format works","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:56:09.424952893-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:56:09.424952893-05:00","dependencies":[{"issue_id":"rust_proxy-btn","depends_on_id":"rust_proxy-ar9","type":"blocks","created_at":"2026-01-18T15:03:44.717463424-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-c1u","title":"Unit tests for Load Balancing","description":"## Unit Tests for Load Balancing\n\n### Test Coverage Areas\n\n1. **Strategy Configuration Parsing**\n   ```rust\n   #[test]\n   fn test_parse_load_balance_strategy() {\n       assert_eq!(parse_strategy(\"single\").unwrap(), Strategy::Single);\n       assert_eq!(parse_strategy(\"round_robin\").unwrap(), Strategy::RoundRobin);\n       assert_eq!(parse_strategy(\"least_latency\").unwrap(), Strategy::LeastLatency);\n       assert_eq!(parse_strategy(\"weighted\").unwrap(), Strategy::Weighted);\n       assert!(parse_strategy(\"invalid\").is_err());\n   }\n   ```\n\n2. **Single Strategy (Default)**\n   ```rust\n   #[test]\n   fn test_single_strategy_returns_active() {\n       let lb = LoadBalancer::new(Strategy::Single, \u0026proxies);\n       let selected = lb.select(\u0026health_status);\n       assert_eq!(selected, Some(\"active-proxy\"));\n   }\n   ```\n\n3. **Round-Robin Strategy**\n   ```rust\n   #[test]\n   fn test_round_robin_cycles() {\n       let lb = LoadBalancer::new(Strategy::RoundRobin, \u0026proxies);\n       assert_eq!(lb.select(\u0026healthy_all), Some(\"proxy-a\"));\n       assert_eq!(lb.select(\u0026healthy_all), Some(\"proxy-b\"));\n       assert_eq!(lb.select(\u0026healthy_all), Some(\"proxy-c\"));\n       assert_eq!(lb.select(\u0026healthy_all), Some(\"proxy-a\")); // cycles back\n   }\n\n   #[test]\n   fn test_round_robin_skips_unhealthy() {\n       let lb = LoadBalancer::new(Strategy::RoundRobin, \u0026proxies);\n       let health = health_status_with_unhealthy(\"proxy-b\");\n       assert_eq!(lb.select(\u0026health), Some(\"proxy-a\"));\n       assert_eq!(lb.select(\u0026health), Some(\"proxy-c\")); // skips proxy-b\n   }\n   ```\n\n4. **Least-Latency Strategy**\n   ```rust\n   #[test]\n   fn test_least_latency_selects_fastest() {\n       let lb = LoadBalancer::new(Strategy::LeastLatency, \u0026proxies);\n       let latencies = hashmap! {\n           \"proxy-a\" =\u003e 100.0,\n           \"proxy-b\" =\u003e 50.0,\n           \"proxy-c\" =\u003e 150.0,\n       };\n       assert_eq!(lb.select_with_latency(\u0026healthy_all, \u0026latencies), Some(\"proxy-b\"));\n   }\n\n   #[test]\n   fn test_least_latency_skips_unhealthy_even_if_fastest() {\n       let lb = LoadBalancer::new(Strategy::LeastLatency, \u0026proxies);\n       let latencies = hashmap! {\n           \"proxy-a\" =\u003e 100.0,\n           \"proxy-b\" =\u003e 10.0,  // fastest but unhealthy\n           \"proxy-c\" =\u003e 150.0,\n       };\n       let health = health_status_with_unhealthy(\"proxy-b\");\n       assert_eq!(lb.select_with_latency(\u0026health, \u0026latencies), Some(\"proxy-a\"));\n   }\n   ```\n\n5. **Weighted Strategy**\n   ```rust\n   #[test]\n   fn test_weighted_distribution() {\n       let lb = LoadBalancer::new(Strategy::Weighted, \u0026proxies);\n       let weights = hashmap! {\n           \"proxy-a\" =\u003e 70,\n           \"proxy-b\" =\u003e 30,\n       };\n       let mut counts = HashMap::new();\n       for _ in 0..1000 {\n           let selected = lb.select_weighted(\u0026healthy_all, \u0026weights).unwrap();\n           *counts.entry(selected).or_insert(0) += 1;\n       }\n       // Should be roughly 70/30 distribution\n       assert!(counts[\"proxy-a\"] \u003e 600 \u0026\u0026 counts[\"proxy-a\"] \u003c 800);\n       assert!(counts[\"proxy-b\"] \u003e 200 \u0026\u0026 counts[\"proxy-b\"] \u003c 400);\n   }\n   ```\n\n6. **Edge Cases**\n   ```rust\n   #[test]\n   fn test_no_healthy_proxies_returns_none() {\n       let lb = LoadBalancer::new(Strategy::RoundRobin, \u0026proxies);\n       assert_eq!(lb.select(\u0026all_unhealthy), None);\n   }\n\n   #[test]\n   fn test_single_proxy_always_returns_it() {\n       let lb = LoadBalancer::new(Strategy::RoundRobin, \u0026single_proxy);\n       assert_eq!(lb.select(\u0026healthy), Some(\"only-proxy\"));\n       assert_eq!(lb.select(\u0026healthy), Some(\"only-proxy\"));\n   }\n   ```\n\n### Thread Safety Tests\n```rust\n#[tokio::test]\nasync fn test_concurrent_round_robin() {\n    let lb = Arc::new(LoadBalancer::new(Strategy::RoundRobin, \u0026proxies));\n    let handles: Vec\u003c_\u003e = (0..100).map(|_| {\n        let lb = lb.clone();\n        tokio::spawn(async move { lb.select(\u0026healthy_all) })\n    }).collect();\n\n    let results: Vec\u003c_\u003e = futures::future::join_all(handles).await\n        .into_iter().filter_map(|r| r.ok()).collect();\n\n    // All proxies should be selected approximately equally\n    let counts = count_occurrences(\u0026results);\n    for count in counts.values() {\n        assert!(*count \u003e 20 \u0026\u0026 *count \u003c 50);\n    }\n}\n```\n\n### Test Files\n- `src/load_balance.rs` - inline unit tests\n- `tests/unit/load_balance_test.rs` - extended tests","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:53:58.296934582-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:53:58.296934582-05:00","dependencies":[{"issue_id":"rust_proxy-c1u","depends_on_id":"rust_proxy-xw7","type":"blocks","created_at":"2026-01-18T14:56:49.720855262-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-ck6","title":"Feature: Shell completion auto-install","description":"## Overview\n\nAdd a `completions install` command that automatically detects the user's shell and installs tab-completion scripts to the appropriate location.\n\n## Strategic Value (Score: 9/10)\n\nShell completions dramatically improve CLI ergonomics:\n- Users don't need to remember exact command/flag names\n- Reduces typos and frustration\n- Makes the tool feel polished and production-ready\n- Trivial effort, high perceived value\n- Already supported by clap - just needs installation UX\n\n## Background and Rationale\n\n### Current State\nclap already generates completion scripts via `clap_complete`. Users can do:\n```bash\nrp completions bash \u003e ~/.local/share/bash-completion/completions/rp\n```\n\nBut this requires:\n1. Knowing the command exists\n2. Knowing where to put the file\n3. Knowing to reload the shell\n\n### The Problem\nMost users never set up completions because it's friction. They don't know:\n- Where bash/zsh/fish store completions\n- That they need to source the file or restart their shell\n- Which shell they're using (surprisingly common)\n\n### The Solution\nOne command that does everything:\n```bash\n$ rp completions install\nDetected shell: zsh\nInstalling completions to /home/user/.zsh/completions/_rp\nDone! Restart your shell or run: source ~/.zshrc\n```\n\n## Shell-Specific Details\n\n### Bash\n- Completion file: `~/.local/share/bash-completion/completions/rp`\n- Alternative: `/etc/bash_completion.d/rp` (system-wide, needs sudo)\n- Activation: automatic on next shell start, or `source` the file\n\n### Zsh\n- Completion file: First dir in `$fpath` that's writable, or `~/.zsh/completions/_rp`\n- May need to add to fpath: `fpath=(~/.zsh/completions $fpath)`\n- Activation: `compinit` (usually in .zshrc already)\n\n### Fish\n- Completion file: `~/.config/fish/completions/rp.fish`\n- Activation: automatic\n\n## Implementation Plan\n\nThe feature is broken into these subtasks:\n1. Add shell detection logic (from $SHELL, parent process, etc.)\n2. Implement completion script generation using clap_complete\n3. Implement per-shell installation paths and logic\n4. Add `completions install` command to CLI\n5. Add `completions uninstall` command for cleanup\n\n## User Experience\n\n```\n$ rp completions install\nDetected shell: zsh\nInstalling completions to /home/user/.zsh/completions/_rp\nDone! Restart your shell or run: compinit\n\n$ rp completions install --shell bash\nInstalling bash completions to /home/user/.local/share/bash-completion/completions/rp\nDone! Restart your shell or run: source ~/.bashrc\n\n$ rp completions install --dry-run\nWould install zsh completions to /home/user/.zsh/completions/_rp\n\n$ rp completions uninstall\nRemoved /home/user/.zsh/completions/_rp\n```\n\n## Acceptance Criteria\n\n- Auto-detects bash, zsh, and fish\n- Installs to correct location per shell\n- Clear success message with next steps\n- --shell flag for override\n- --dry-run to preview\n- uninstall command for cleanup\n- Handles missing directories gracefully","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:57:46.170915837-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:23:23.338596204-05:00","dependencies":[{"issue_id":"rust_proxy-ck6","depends_on_id":"rust_proxy-28m","type":"blocks","created_at":"2026-01-18T15:06:06.362091696-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-ck6","depends_on_id":"rust_proxy-zap","type":"blocks","created_at":"2026-01-18T15:07:02.708563964-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-ck6","depends_on_id":"rust_proxy-5b1","type":"blocks","created_at":"2026-01-18T15:07:03.128803388-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-csc","title":"Unit tests for Graceful Degradation","description":"## Unit Tests for Graceful Degradation\n\n### Test Coverage Areas\n\n1. **Policy Configuration Parsing**\n   ```rust\n   #[test]\n   fn test_parse_degradation_policy() {\n       assert_eq!(parse_policy(\"fail_closed\").unwrap(), Policy::FailClosed);\n       assert_eq!(parse_policy(\"try_all\").unwrap(), Policy::TryAll);\n       assert_eq!(parse_policy(\"use_last\").unwrap(), Policy::UseLast);\n       assert_eq!(parse_policy(\"direct\").unwrap(), Policy::Direct);\n       assert!(parse_policy(\"invalid\").is_err());\n   }\n\n   #[test]\n   fn test_direct_policy_requires_allow_flag() {\n       let config = config_with_policy(\"direct\", false);\n       let result = validate_config(\u0026config);\n       assert!(result.is_err());\n       assert!(result.unwrap_err().to_string().contains(\"allow_direct_fallback\"));\n   }\n   ```\n\n2. **Fail Closed Policy**\n   ```rust\n   #[test]\n   fn test_fail_closed_rejects_immediately() {\n       let policy = DegradationPolicy::FailClosed;\n       let state = all_proxies_unhealthy();\n\n       let result = policy.handle_connection(\u0026state, target);\n       assert!(result.is_err());\n       assert!(result.unwrap_err().to_string().contains(\"No healthy proxies\"));\n   }\n   ```\n\n3. **Try All Policy**\n   ```rust\n   #[tokio::test]\n   async fn test_try_all_attempts_each_proxy() {\n       let policy = DegradationPolicy::TryAll;\n       let mut state = MockState::new();\n       state.add_proxy(\"a\", false); // unhealthy\n       state.add_proxy(\"b\", false); // unhealthy\n       state.add_proxy(\"c\", false); // unhealthy but will succeed\n\n       // Make proxy-c succeed on actual connection attempt\n       state.set_connection_behavior(\"c\", ConnectionBehavior::Succeed);\n\n       let result = policy.handle_connection(\u0026state, target).await;\n       assert!(result.is_ok());\n       assert_eq!(state.connection_attempts(), vec![\"a\", \"b\", \"c\"]);\n   }\n\n   #[tokio::test]\n   async fn test_try_all_returns_first_success() {\n       let policy = DegradationPolicy::TryAll;\n       let mut state = MockState::new();\n       state.add_proxy(\"a\", false);\n       state.add_proxy(\"b\", false);\n       state.set_connection_behavior(\"a\", ConnectionBehavior::Fail);\n       state.set_connection_behavior(\"b\", ConnectionBehavior::Succeed);\n\n       let result = policy.handle_connection(\u0026state, target).await;\n       assert!(result.is_ok());\n       // Should stop at b, not try c\n       assert_eq!(state.connection_attempts(), vec![\"a\", \"b\"]);\n   }\n   ```\n\n4. **Use Last Policy**\n   ```rust\n   #[tokio::test]\n   async fn test_use_last_tries_recently_healthy() {\n       let policy = DegradationPolicy::UseLast;\n       let mut state = all_proxies_unhealthy();\n       state.set_last_healthy(\"proxy-b\", Utc::now() - Duration::from_secs(60));\n\n       let result = policy.handle_connection(\u0026state, target).await;\n       assert_eq!(state.connection_attempts(), vec![\"proxy-b\"]);\n   }\n\n   #[test]\n   fn test_use_last_fails_if_never_healthy() {\n       let policy = DegradationPolicy::UseLast;\n       let state = no_proxy_ever_healthy();\n\n       let result = policy.handle_connection(\u0026state, target);\n       assert!(result.is_err());\n       assert!(result.unwrap_err().to_string().contains(\"No proxy has ever been healthy\"));\n   }\n   ```\n\n5. **Direct Policy**\n   ```rust\n   #[tokio::test]\n   async fn test_direct_bypasses_proxy() {\n       let policy = DegradationPolicy::Direct;\n       let state = all_proxies_unhealthy();\n\n       let result = policy.handle_connection(\u0026state, \"example.com:443\").await;\n       assert!(result.is_ok());\n       assert!(state.direct_connection_made());\n   }\n   ```\n\n6. **Degradation State Tracking**\n   ```rust\n   #[test]\n   fn test_degradation_delay_debounces() {\n       let tracker = DegradationTracker::new(Duration::from_secs(5));\n\n       tracker.all_unhealthy_detected();\n       assert!(!tracker.should_apply_policy()); // Not yet\n\n       std::thread::sleep(Duration::from_secs(3));\n       assert!(!tracker.should_apply_policy()); // Still waiting\n\n       std::thread::sleep(Duration::from_secs(3));\n       assert!(tracker.should_apply_policy()); // Now ready\n   }\n\n   #[test]\n   fn test_recovery_resets_degradation() {\n       let tracker = DegradationTracker::new(Duration::from_secs(5));\n\n       tracker.all_unhealthy_detected();\n       std::thread::sleep(Duration::from_secs(3));\n\n       tracker.healthy_proxy_detected(); // Recovery!\n\n       std::thread::sleep(Duration::from_secs(3));\n       assert!(!tracker.should_apply_policy()); // Reset\n   }\n   ```\n\n### Edge Cases\n```rust\n#[test]\nfn test_empty_proxy_list_immediate_degradation() {\n    let state = no_proxies_configured();\n    let policy = DegradationPolicy::FailClosed;\n    let result = policy.handle_connection(\u0026state, target);\n    assert!(result.is_err());\n}\n\n#[test]\nfn test_policy_with_zero_delay() {\n    let tracker = DegradationTracker::new(Duration::from_secs(0));\n    tracker.all_unhealthy_detected();\n    assert!(tracker.should_apply_policy()); // Immediate\n}\n```\n\n### Test Files\n- `src/degradation.rs` - inline unit tests\n- `tests/unit/degradation_test.rs` - extended tests","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:09.517811137-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:09.517811137-05:00","dependencies":[{"issue_id":"rust_proxy-csc","depends_on_id":"rust_proxy-zkv","type":"blocks","created_at":"2026-01-18T14:56:51.802414011-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-cux","title":"E2E Test Infrastructure Foundation","description":"## Overview\n\nEstablish a comprehensive end-to-end testing infrastructure for rust_proxy that enables reliable, reproducible integration testing across all features.\n\n## Strategic Value\n\nE2E tests are essential for:\n- Catching integration issues that unit tests miss\n- Validating real-world behavior across component boundaries\n- Providing confidence for refactoring and feature additions\n- Documenting expected system behavior through executable specs\n- Enabling CI/CD automation with reliable test gates\n\n## Architecture\n\n### Test Harness Components\n\n```rust\n// tests/common/mod.rs\npub struct TestHarness {\n    /// Temporary directory for test artifacts\n    pub temp_dir: TempDir,\n    /// Test configuration file path\n    pub config_path: PathBuf,\n    /// State directory path\n    pub state_dir: PathBuf,\n    /// Mock proxy servers (if needed)\n    pub mock_proxies: Vec\u003cMockProxy\u003e,\n    /// The daemon process handle\n    pub daemon: Option\u003cDaemonHandle\u003e,\n}\n\nimpl TestHarness {\n    pub async fn new() -\u003e Self { ... }\n    pub async fn with_config(config: \u0026str) -\u003e Self { ... }\n    pub async fn start_daemon(\u0026mut self) -\u003e Result\u003c()\u003e { ... }\n    pub async fn stop_daemon(\u0026mut self) -\u003e Result\u003c()\u003e { ... }\n    pub fn run_command(\u0026self, args: \u0026[\u0026str]) -\u003e CommandResult { ... }\n    pub async fn cleanup(self) { ... }\n}\n```\n\n### Mock Proxy Server\n\n```rust\npub struct MockProxy {\n    pub port: u16,\n    pub addr: SocketAddr,\n    /// Configurable behavior\n    pub behavior: MockBehavior,\n    /// Request log for assertions\n    pub requests: Arc\u003cMutex\u003cVec\u003cMockRequest\u003e\u003e\u003e,\n}\n\npub enum MockBehavior {\n    /// Always succeed with configurable latency\n    Healthy { latency_ms: u64 },\n    /// Always fail with specific error\n    Failing { error: MockError },\n    /// Succeed N times then fail\n    FailAfter { successes: u32, error: MockError },\n    /// Random failures at given rate\n    Flaky { failure_rate: f64 },\n    /// Custom handler\n    Custom(Box\u003cdyn Fn(\u0026MockRequest) -\u003e MockResponse\u003e),\n}\n```\n\n### Test Logging Infrastructure\n\n```rust\n/// Detailed test logging for debugging failures\npub struct TestLogger {\n    log_path: PathBuf,\n    verbosity: LogVerbosity,\n}\n\nimpl TestLogger {\n    /// Log test phase transitions\n    pub fn phase(\u0026self, name: \u0026str) { ... }\n    /// Log command execution with output\n    pub fn command(\u0026self, cmd: \u0026str, output: \u0026CommandResult) { ... }\n    /// Log assertion details\n    pub fn assertion(\u0026self, name: \u0026str, expected: \u0026str, actual: \u0026str) { ... }\n    /// Capture daemon logs during test\n    pub fn daemon_logs(\u0026self) -\u003e String { ... }\n}\n```\n\n### Test Fixture Generators\n\n```rust\npub fn minimal_config() -\u003e String { ... }\npub fn multi_proxy_config(count: usize) -\u003e String { ... }\npub fn config_with_health_check(interval_secs: u64) -\u003e String { ... }\npub fn config_with_failover() -\u003e String { ... }\n```\n\n## Directory Structure\n\n```\ntests/\n├── common/\n│   ├── mod.rs          # Test harness and utilities\n│   ├── mock_proxy.rs   # Mock proxy server implementation\n│   ├── fixtures.rs     # Config and data fixtures\n│   └── assertions.rs   # Custom assertion helpers\n├── e2e/\n│   ├── basic_operations.rs\n│   ├── health_check.rs\n│   ├── failover.rs\n│   ├── metrics.rs      # When metrics feature implemented\n│   └── ...\n└── integration/\n    ├── cli_commands.rs\n    └── config_parsing.rs\n```\n\n## Key Testing Patterns\n\n### 1. Daemon Lifecycle Test\n```rust\n#[tokio::test]\nasync fn test_daemon_start_stop() {\n    let mut harness = TestHarness::new().await;\n\n    harness.start_daemon().await.expect(\"daemon should start\");\n    assert!(harness.daemon_is_running());\n\n    harness.stop_daemon().await.expect(\"daemon should stop\");\n    assert!(!harness.daemon_is_running());\n}\n```\n\n### 2. Health Check Test with Mock\n```rust\n#[tokio::test]\nasync fn test_health_check_marks_unhealthy() {\n    let mut harness = TestHarness::new().await;\n    let mock = harness.add_mock_proxy(MockBehavior::Failing {\n        error: MockError::ConnectionRefused\n    }).await;\n\n    harness.start_daemon().await.unwrap();\n\n    // Wait for health check cycle\n    tokio::time::sleep(Duration::from_secs(5)).await;\n\n    let status = harness.run_command(\u0026[\"status\", \"--json\"]);\n    let json: Value = serde_json::from_str(\u0026status.stdout).unwrap();\n\n    assert_eq!(json[\"proxies\"][\u0026mock.id][\"health\"], \"unhealthy\");\n}\n```\n\n### 3. Failover Test\n```rust\n#[tokio::test]\nasync fn test_automatic_failover() {\n    let mut harness = TestHarness::with_config(r#\"\n        [settings]\n        auto_failover = true\n        consecutive_failures_threshold = 2\n\n        [[proxies]]\n        id = \"primary\"\n        url = \"http://localhost:MOCK1_PORT\"\n        priority = 1\n\n        [[proxies]]\n        id = \"secondary\"\n        url = \"http://localhost:MOCK2_PORT\"\n        priority = 2\n    \"#).await;\n\n    let primary = harness.add_mock_proxy(MockBehavior::FailAfter {\n        successes: 2,\n        error: MockError::Timeout\n    }).await;\n    let secondary = harness.add_mock_proxy(MockBehavior::Healthy {\n        latency_ms: 50\n    }).await;\n\n    harness.start_daemon().await.unwrap();\n\n    // Wait for failover\n    tokio::time::sleep(Duration::from_secs(10)).await;\n\n    let status = harness.run_command(\u0026[\"status\", \"--json\"]);\n    assert!(status.stdout.contains(\"\\\"effective_proxy\\\": \\\"secondary\\\"\"));\n}\n```\n\n## Logging Requirements\n\nEvery E2E test MUST:\n1. Log test phase transitions (setup, execute, verify, teardown)\n2. Capture full command output (stdout + stderr)\n3. Record daemon logs during test\n4. Log assertion details on failure\n5. Preserve logs on test failure for debugging\n\n## CI Integration\n\nTests should be runnable via:\n```bash\n# All E2E tests\ncargo test --test e2e\n\n# Specific feature tests\ncargo test --test e2e health_check\n\n# With verbose logging\nRUST_LOG=debug cargo test --test e2e -- --nocapture\n```\n\n## Success Criteria\n\n- Test harness can start/stop daemon reliably\n- Mock proxy server supports all needed behaviors\n- Tests are isolated (no shared state between tests)\n- Clear logging on test failure\n- Tests complete in reasonable time (\u003c60s each)\n- All tests pass in CI environment","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:47:50.785175185-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:23:23.245618277-05:00"}
{"id":"rust_proxy-dk1","title":"Implement parallel DNS resolution for target domains","description":"## Overview\n\nReplace sequential DNS resolution with parallel resolution using `futures::future::join_all` with semaphore-based concurrency control to dramatically reduce startup and refresh times while remaining well-behaved.\n\n## Background \u0026 Motivation\n\nThe current implementation in `src/dns.rs` resolves domains sequentially:\n```rust\nfor domain in domains {\n    let ips = lookup(domain).await?;\n    // process...\n}\n```\n\n**Performance Problem:**\n- With 87 default targets and ~50ms average DNS lookup time: **4.35 seconds**\n- During this time: daemon startup is blocked, refresh cycles are slow\n- Users perceive the tool as sluggish on every restart\n\n**Why Parallel Works:**\n- DNS lookups are I/O-bound and completely independent\n- DNS resolvers (systemd-resolved, dnsmasq) handle concurrent queries well\n- Standard async pattern used by all production network tools\n\n## Implementation Plan\n\n### 1. Add semaphore-based concurrency control\nDon't fire unlimited concurrent requests - be a good citizen:\n```rust\nuse tokio::sync::Semaphore;\nuse std::sync::Arc;\n\nconst MAX_CONCURRENT_DNS: usize = 32; // Reasonable for local resolver\n```\n\n### 2. Implement parallel resolution with error isolation\n```rust\nuse futures::future::join_all;\nuse std::time::Instant;\n\npub async fn resolve_targets_parallel(\n    targets: \u0026[Target],\n    timeout: Duration,\n) -\u003e DnsResolutionReport {\n    let semaphore = Arc::new(Semaphore::new(MAX_CONCURRENT_DNS));\n    let start = Instant::now();\n    \n    let futures: Vec\u003c_\u003e = targets.iter().map(|target| {\n        let sem = semaphore.clone();\n        let domain = target.domain.clone();\n        async move {\n            let _permit = sem.acquire().await.unwrap();\n            let result = tokio::time::timeout(timeout, resolve_domain(\u0026domain)).await;\n            (domain, result)\n        }\n    }).collect();\n    \n    let results = join_all(futures).await;\n    let elapsed = start.elapsed();\n    \n    // Process results\n    let mut resolved = Vec::new();\n    let mut failed = Vec::new();\n    \n    for (domain, result) in results {\n        match result {\n            Ok(Ok(ips)) =\u003e resolved.push((domain, ips)),\n            Ok(Err(e)) =\u003e failed.push((domain, format!(\"DNS error: {}\", e))),\n            Err(_) =\u003e failed.push((domain, \"DNS timeout\".to_string())),\n        }\n    }\n    \n    DnsResolutionReport {\n        resolved,\n        failed,\n        total_domains: targets.len(),\n        elapsed,\n    }\n}\n\npub struct DnsResolutionReport {\n    pub resolved: Vec\u003c(String, Vec\u003cIpAddr\u003e)\u003e,\n    pub failed: Vec\u003c(String, String)\u003e,\n    pub total_domains: usize,\n    pub elapsed: Duration,\n}\n```\n\n### 3. Implement retry logic for transient failures\nSome DNS failures are transient (network hiccup, resolver busy). Retry once:\n```rust\nasync fn resolve_with_retry(domain: \u0026str, timeout: Duration) -\u003e Result\u003cVec\u003cIpAddr\u003e\u003e {\n    match tokio::time::timeout(timeout, resolve_domain(domain)).await {\n        Ok(Ok(ips)) =\u003e Ok(ips),\n        Ok(Err(e)) if is_transient_dns_error(\u0026e) =\u003e {\n            tracing::debug!(domain, error = %e, \"DNS failed, retrying once\");\n            tokio::time::sleep(Duration::from_millis(100)).await;\n            tokio::time::timeout(timeout, resolve_domain(domain)).await?\n        }\n        Ok(Err(e)) =\u003e Err(e),\n        Err(_) =\u003e Err(anyhow!(\"DNS timeout for {}\", domain)),\n    }\n}\n\nfn is_transient_dns_error(e: \u0026anyhow::Error) -\u003e bool {\n    let msg = e.to_string().to_lowercase();\n    msg.contains(\"temporary\") || \n    msg.contains(\"servfail\") ||\n    msg.contains(\"timeout\") ||\n    msg.contains(\"try again\")\n}\n```\n\n### 4. Graceful handling of partial failures\nDNS resolution should NOT fail entirely if some domains fail:\n```rust\n// In daemon refresh loop:\nlet report = resolve_targets_parallel(\u0026config.targets, dns_timeout).await;\n\ntracing::info!(\n    total = report.total_domains,\n    resolved = report.resolved.len(),\n    failed = report.failed.len(),\n    elapsed_ms = report.elapsed.as_millis(),\n    \"DNS resolution complete\"\n);\n\nif !report.failed.is_empty() {\n    for (domain, reason) in \u0026report.failed {\n        tracing::warn!(domain, reason, \"Failed to resolve target\");\n    }\n}\n\n// Continue with successfully resolved domains\n// Don't abort the entire refresh!\n```\n\n### 5. Detailed logging\n```\nINFO  dns: DNS resolution complete total=87 resolved=85 failed=2 elapsed_ms=127\nWARN  dns: Failed to resolve target domain=\"broken.example.com\" reason=\"NXDOMAIN\"\nWARN  dns: Failed to resolve target domain=\"timeout.example.com\" reason=\"DNS timeout\"\nDEBUG dns: Resolved domain domain=\"api.openai.com\" ips=[\"104.18.6.192\", \"104.18.7.192\"] ms=45\n```\n\n## Expected Performance Improvement\n\n| Scenario | Before | After | Speedup |\n|----------|--------|-------|---------|\n| 87 domains, 50ms avg | 4,350ms | ~150ms | **29x** |\n| 200 domains, 50ms avg | 10,000ms | ~350ms | **28x** |\n| 87 domains, 10ms avg | 870ms | ~40ms | **22x** |\n\nThe parallelism is bounded by MAX_CONCURRENT_DNS (32), so even with 200 domains we don't overwhelm the resolver.\n\n## Code Location\n\nFile: `src/dns.rs`, function: `resolve_targets()`\n\n## File Changes Summary\n\n| File | Change |\n|------|--------|\n| `src/dns.rs` | Rewrite `resolve_targets()` to use parallel resolution |\n| `src/dns.rs` | Add `DnsResolutionReport` struct |\n| `src/dns.rs` | Add retry logic and error classification |\n| `src/main.rs` | Update callers to handle new return type |\n| `Cargo.toml` | Ensure `futures` crate is available |\n\n## Testing Requirements\n\n### Unit Tests (`src/dns.rs` or `tests/dns_parallel.rs`)\n\n1. **Test parallel resolution completes**:\n   ```rust\n   #[tokio::test]\n   async fn test_parallel_resolution_basic() {\n       let targets = vec![\n           Target { domain: \"google.com\".into(), provider: None },\n           Target { domain: \"cloudflare.com\".into(), provider: None },\n       ];\n       let report = resolve_targets_parallel(\u0026targets, Duration::from_secs(5)).await;\n       assert_eq!(report.total_domains, 2);\n       assert!(report.resolved.len() \u003e= 1); // At least one should resolve\n   }\n   ```\n\n2. **Test partial failure handling**:\n   ```rust\n   #[tokio::test]\n   async fn test_partial_failure_continues() {\n       let targets = vec![\n           Target { domain: \"google.com\".into(), provider: None },\n           Target { domain: \"definitely-not-a-real-domain-xyz123.invalid\".into(), provider: None },\n       ];\n       let report = resolve_targets_parallel(\u0026targets, Duration::from_secs(5)).await;\n       assert_eq!(report.resolved.len(), 1);\n       assert_eq!(report.failed.len(), 1);\n   }\n   ```\n\n3. **Test timeout handling**:\n   ```rust\n   #[tokio::test]\n   async fn test_timeout_doesnt_block_others() {\n       // Use very short timeout\n       let report = resolve_targets_parallel(\u0026targets, Duration::from_millis(1)).await;\n       // Should complete quickly even if all timeout\n       assert!(report.elapsed \u003c Duration::from_secs(1));\n   }\n   ```\n\n4. **Test semaphore limiting**:\n   ```rust\n   #[tokio::test]\n   async fn test_concurrency_limited() {\n       let targets: Vec\u003c_\u003e = (0..100)\n           .map(|i| Target { domain: format!(\"test{}.example.com\", i), provider: None })\n           .collect();\n       let start = Instant::now();\n       let _ = resolve_targets_parallel(\u0026targets, Duration::from_secs(1)).await;\n       // With 100 domains and max 32 concurrent, should take ~4 batches\n       // Not instant (would indicate no limiting) and not 100x sequential\n   }\n   ```\n\n5. **Test transient error retry**:\n   ```rust\n   #[tokio::test]\n   async fn test_transient_error_classification() {\n       assert!(is_transient_dns_error(\u0026anyhow!(\"temporary failure\")));\n       assert!(is_transient_dns_error(\u0026anyhow!(\"SERVFAIL\")));\n       assert!(!is_transient_dns_error(\u0026anyhow!(\"NXDOMAIN\")));\n   }\n   ```\n\n### Performance Benchmark Test\n\n```rust\n// benches/dns_resolution.rs (using criterion)\nfn benchmark_dns_resolution(c: \u0026mut Criterion) {\n    let rt = tokio::runtime::Runtime::new().unwrap();\n    let targets = load_default_targets();\n    \n    c.bench_function(\"parallel_dns_87_domains\", |b| {\n        b.iter(|| {\n            rt.block_on(resolve_targets_parallel(\u0026targets, Duration::from_secs(5)))\n        })\n    });\n}\n```\n\n### E2E Test Script (`tests/e2e/dns_parallel.sh`)\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\necho \"=== E2E Test: Parallel DNS Resolution ===\"\n\n# Build release binary\ncargo build --release\n\n# Time the refresh operation\necho \"[1/3] Timing DNS resolution during daemon startup...\"\nSTART=$(date +%s%3N)\ntimeout 30 ./target/release/rust_proxy daemon --dry-run 2\u003e\u00261 | grep -i \"dns.*complete\"\nEND=$(date +%s%3N)\nELAPSED=$((END - START))\n\necho \"[2/3] Resolution completed in ${ELAPSED}ms\"\n\nif [ $ELAPSED -lt 2000 ]; then\n    echo \"✓ PASS: DNS resolution under 2 seconds (was ${ELAPSED}ms)\"\nelse\n    echo \"✗ FAIL: DNS resolution too slow (${ELAPSED}ms \u003e 2000ms)\"\n    exit 1\nfi\n\n# Verify partial failures don't crash\necho \"[3/3] Testing with intentionally broken domain...\"\n# Add a broken domain to config and verify daemon still starts\n\necho \"=== Test Complete ===\"\n```\n\n## Risk Assessment\n\n- **Complexity**: Low (straightforward async pattern)\n- **Impact**: High (major perceived performance improvement, better UX)\n- **Risk**: Low (no change to functionality, only execution order)\n- **Confidence**: Very high (standard async Rust pattern used everywhere)\n\n## Dependencies\n\nNone - standalone performance improvement.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:49:11.487995111-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:53:09.618911309-05:00","closed_at":"2026-01-18T04:53:09.618911309-05:00","close_reason":"Parallel DNS resolution implemented with semaphore-based concurrency control, retry logic for transient errors, and detailed logging. All 61 tests passing."}
{"id":"rust_proxy-dlt","title":"Unit tests for Network Diagnostics","description":"## Unit Tests for Network Diagnostics\n\n### Test Coverage Areas\n\n1. **Doctor Command Checks**\n   ```rust\n   #[test]\n   fn test_doctor_check_config_valid() {\n       let check = DoctorCheck::ConfigValid;\n       let result = check.run(\u0026valid_config());\n       assert!(result.passed);\n       assert_eq!(result.name, \"Configuration\");\n   }\n\n   #[test]\n   fn test_doctor_check_config_invalid() {\n       let check = DoctorCheck::ConfigValid;\n       let result = check.run(\u0026invalid_config());\n       assert!(!result.passed);\n       assert!(result.message.contains(\"error\") || result.message.contains(\"invalid\"));\n   }\n\n   #[test]\n   fn test_doctor_check_state_directory() {\n       let check = DoctorCheck::StateDirectory;\n       let result = check.run_with_path(\u0026writable_dir());\n       assert!(result.passed);\n       assert!(result.message.contains(\"writable\"));\n   }\n\n   #[test]\n   fn test_doctor_check_listen_port_available() {\n       let check = DoctorCheck::ListenPort;\n       // Use a likely-free high port\n       let config = config_with_listen(\"127.0.0.1:59999\");\n       let result = check.run(\u0026config);\n       assert!(result.passed || result.message.contains(\"in use\"));\n   }\n   ```\n\n2. **Ping Logic**\n   ```rust\n   #[tokio::test]\n   async fn test_ping_calculates_statistics() {\n       let results = vec![\n           PingResult { latency_ms: 40.0, success: true },\n           PingResult { latency_ms: 50.0, success: true },\n           PingResult { latency_ms: 60.0, success: true },\n       ];\n\n       let stats = PingStatistics::from_results(\u0026results);\n\n       assert_eq!(stats.min_ms, 40.0);\n       assert_eq!(stats.max_ms, 60.0);\n       assert_eq!(stats.avg_ms, 50.0);\n       assert_eq!(stats.loss_percent, 0.0);\n   }\n\n   #[tokio::test]\n   async fn test_ping_handles_failures() {\n       let results = vec![\n           PingResult { latency_ms: 0.0, success: false },\n           PingResult { latency_ms: 50.0, success: true },\n           PingResult { latency_ms: 0.0, success: false },\n       ];\n\n       let stats = PingStatistics::from_results(\u0026results);\n\n       assert!((stats.loss_percent - 66.67).abs() \u003c 1.0);\n       assert_eq!(stats.successful_count, 1);\n   }\n\n   #[test]\n   fn test_ping_formats_output() {\n       let stats = PingStatistics {\n           min_ms: 40.0,\n           avg_ms: 50.0,\n           max_ms: 60.0,\n           loss_percent: 0.0,\n           total_count: 3,\n           successful_count: 3,\n       };\n\n       let output = stats.format();\n       assert!(output.contains(\"min/avg/max = 40/50/60 ms\"));\n       assert!(output.contains(\"0% loss\"));\n   }\n   ```\n\n3. **Trace Command Steps**\n   ```rust\n   #[test]\n   fn test_trace_step_dns_resolution() {\n       let step = TraceStep::DnsResolution {\n           hostname: \"example.com\".to_string(),\n       };\n\n       let result = step.execute_sync();\n       assert!(result.success || result.error.is_some());\n       if result.success {\n           assert!(result.details.contains('.') || result.details.contains(':'));\n       }\n   }\n\n   #[tokio::test]\n   async fn test_trace_step_proxy_connect() {\n       let mock = MockProxy::new(MockBehavior::Healthy { latency_ms: 50 });\n       let step = TraceStep::ProxyConnect {\n           proxy_addr: mock.addr(),\n       };\n\n       let result = step.execute().await;\n       assert!(result.success);\n       assert!(result.latency_ms.is_some());\n   }\n\n   #[test]\n   fn test_trace_formats_timeline() {\n       let steps = vec![\n           TraceResult { step: \"DNS\", success: true, latency_ms: Some(5.0), details: \"93.184.216.34\".to_string(), error: None },\n           TraceResult { step: \"Proxy Connect\", success: true, latency_ms: Some(32.0), details: \"OK\".to_string(), error: None },\n           TraceResult { step: \"TLS Handshake\", success: true, latency_ms: Some(45.0), details: \"TLS 1.3\".to_string(), error: None },\n       ];\n\n       let output = format_trace_timeline(\u0026steps);\n       assert!(output.contains(\"DNS\"));\n       assert!(output.contains(\"32ms\"));\n       assert!(output.contains(\"TLS 1.3\"));\n   }\n   ```\n\n4. **DNS Resolution Check**\n   ```rust\n   #[tokio::test]\n   async fn test_dns_resolution_valid_hostname() {\n       let result = resolve_hostname(\"www.google.com\").await;\n       assert!(result.is_ok());\n       assert!(!result.unwrap().is_empty());\n   }\n\n   #[tokio::test]\n   async fn test_dns_resolution_invalid_hostname() {\n       let result = resolve_hostname(\"invalid.hostname.that.does.not.exist.example\").await;\n       assert!(result.is_err());\n   }\n   ```\n\n5. **JSON Output Format**\n   ```rust\n   #[test]\n   fn test_doctor_json_output() {\n       let results = DoctorResults {\n           checks: vec![\n               CheckResult { name: \"Config\".to_string(), passed: true, message: \"OK\".to_string() },\n               CheckResult { name: \"Proxy\".to_string(), passed: false, message: \"Connection refused\".to_string() },\n           ],\n       };\n\n       let json = results.to_json().unwrap();\n       let parsed: Value = serde_json::from_str(\u0026json).unwrap();\n\n       assert_eq!(parsed[\"checks\"].as_array().unwrap().len(), 2);\n       assert_eq!(parsed[\"checks\"][0][\"passed\"], true);\n       assert_eq!(parsed[\"checks\"][1][\"passed\"], false);\n   }\n\n   #[test]\n   fn test_ping_json_output() {\n       let stats = PingStatistics::default();\n       let json = stats.to_json().unwrap();\n\n       let parsed: Value = serde_json::from_str(\u0026json).unwrap();\n       assert!(parsed[\"min_ms\"].is_number());\n       assert!(parsed[\"avg_ms\"].is_number());\n   }\n   ```\n\n### Test Files\n- `src/diagnostics/doctor.rs` - inline unit tests\n- `src/diagnostics/ping.rs` - inline unit tests\n- `src/diagnostics/trace.rs` - inline unit tests\n- `tests/unit/diagnostics_test.rs` - extended tests","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:27.872344731-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:27.872344731-05:00","dependencies":[{"issue_id":"rust_proxy-dlt","depends_on_id":"rust_proxy-o4n","type":"blocks","created_at":"2026-01-18T14:56:54.961546168-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-e4g","title":"E2E tests for Graceful Degradation","description":"## E2E Tests for Graceful Degradation\n\n### Test Scenarios\n\n1. **Fail Closed Rejects When All Unhealthy**\n   ```rust\n   #[tokio::test]\n   async fn test_fail_closed_rejects_connections() {\n       let mut harness = TestHarness::with_config(r#\"\n           [settings]\n           degradation_policy = \"fail_closed\"\n           consecutive_failures_threshold = 1\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:MOCK1_PORT\"\n       \"#).await;\n\n       // Proxy that always fails\n       harness.add_mock_proxy(MockBehavior::Failing {\n           error: MockError::ConnectionRefused\n       }).await;\n       harness.start_daemon().await.unwrap();\n\n       // Wait for health check to mark unhealthy\n       tokio::time::sleep(Duration::from_secs(5)).await;\n\n       // Try to make connection\n       let result = make_request_through_proxy(\u0026harness).await;\n       assert!(result.is_err());\n       assert!(result.unwrap_err().contains(\"No healthy proxies\"));\n   }\n   ```\n\n2. **Try All Succeeds If Any Proxy Works**\n   ```rust\n   #[tokio::test]\n   async fn test_try_all_finds_working_proxy() {\n       let mut harness = TestHarness::with_config(r#\"\n           [settings]\n           degradation_policy = \"try_all\"\n           consecutive_failures_threshold = 1\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:MOCK1_PORT\"\n\n           [[proxies]]\n           id = \"proxy-b\"\n           url = \"http://localhost:MOCK2_PORT\"\n\n           [[proxies]]\n           id = \"proxy-c\"\n           url = \"http://localhost:MOCK3_PORT\"\n       \"#).await;\n\n       // First two fail health checks, third passes despite health check failure\n       harness.add_mock_proxy(MockBehavior::Failing { error: MockError::Timeout }).await;\n       harness.add_mock_proxy(MockBehavior::Failing { error: MockError::Timeout }).await;\n       harness.add_mock_proxy(MockBehavior::Flaky { failure_rate: 0.5 }).await; // Sometimes works\n       harness.start_daemon().await.unwrap();\n\n       // Wait for health checks\n       tokio::time::sleep(Duration::from_secs(5)).await;\n\n       // Attempt should try all and succeed on third\n       let result = make_request_through_proxy(\u0026harness).await;\n       // May succeed if flaky proxy happens to work\n   }\n   ```\n\n3. **Use Last Tries Recently Healthy**\n   ```rust\n   #[tokio::test]\n   async fn test_use_last_uses_recent_healthy() {\n       let mut harness = TestHarness::with_config(r#\"\n           [settings]\n           degradation_policy = \"use_last\"\n           health_check_interval_secs = 2\n           consecutive_failures_threshold = 2\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:MOCK1_PORT\"\n       \"#).await;\n\n       // Starts healthy, then fails\n       let mock = harness.add_mock_proxy(MockBehavior::FailAfter {\n           successes: 3,\n           error: MockError::Timeout\n       }).await;\n       harness.start_daemon().await.unwrap();\n\n       // Wait for initial healthy, then failure\n       tokio::time::sleep(Duration::from_secs(10)).await;\n\n       // Connection attempt should still try the last-healthy proxy\n       let result = make_request_through_proxy(\u0026harness).await;\n       assert!(mock.connection_attempts() \u003e 0);\n   }\n   ```\n\n4. **Direct Fallback Bypasses Proxy**\n   ```rust\n   #[tokio::test]\n   async fn test_direct_fallback_bypasses_proxy() {\n       let mut harness = TestHarness::with_config(r#\"\n           [settings]\n           degradation_policy = \"direct\"\n           allow_direct_fallback = true\n           consecutive_failures_threshold = 1\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:MOCK1_PORT\"\n       \"#).await;\n\n       harness.add_mock_proxy(MockBehavior::Failing {\n           error: MockError::ConnectionRefused\n       }).await;\n       harness.start_daemon().await.unwrap();\n\n       tokio::time::sleep(Duration::from_secs(5)).await;\n\n       // Should connect directly without proxy\n       let result = fetch_url_through_proxy(\u0026harness, \"http://httpbin.org/get\").await;\n       assert!(result.is_ok());\n   }\n   ```\n\n5. **Degradation Delay Debounces Transients**\n   ```rust\n   #[tokio::test]\n   async fn test_degradation_delay_debounces() {\n       let mut harness = TestHarness::with_config(r#\"\n           [settings]\n           degradation_policy = \"fail_closed\"\n           degradation_delay_secs = 10\n           health_check_interval_secs = 1\n           consecutive_failures_threshold = 1\n\n           [[proxies]]\n           id = \"proxy-a\"\n           url = \"http://localhost:MOCK1_PORT\"\n       \"#).await;\n\n       // Brief failure then recovery\n       let mock = harness.add_mock_proxy(MockBehavior::FailAfter {\n           successes: 0,\n           error: MockError::Timeout\n       }).await;\n       harness.start_daemon().await.unwrap();\n\n       // Immediately after failure detection\n       tokio::time::sleep(Duration::from_secs(3)).await;\n\n       // Should NOT be in degradation yet (delay not passed)\n       let status = harness.run_command(\u0026[\"status\", \"--json\"]);\n       assert!(!status.stdout.contains(\"\\\"degraded\\\": true\"));\n\n       // Make mock healthy again\n       mock.set_behavior(MockBehavior::Healthy { latency_ms: 50 });\n\n       // Wait for recovery detection\n       tokio::time::sleep(Duration::from_secs(3)).await;\n\n       // Should recover without ever entering degraded state\n       let status = harness.run_command(\u0026[\"status\", \"--json\"]);\n       assert!(!status.stdout.contains(\"\\\"degraded\\\": true\"));\n   }\n   ```\n\n6. **Status Shows Degradation State**\n   ```rust\n   #[tokio::test]\n   async fn test_status_shows_degradation() {\n       let harness = all_unhealthy_harness().await;\n       tokio::time::sleep(Duration::from_secs(15)).await; // Past delay\n\n       let status = harness.run_command(\u0026[\"status\"]);\n       assert!(status.stdout.contains(\"DEGRADED\") ||\n               status.stdout.contains(\"degradation_policy\"));\n   }\n   ```\n\n### Logging Requirements\n- Log when degradation state entered/exited\n- Log policy being applied for each connection\n- Log each proxy attempt in try_all mode\n- Log direct connection attempts\n- On failure, dump degradation tracker state and proxy health\n\n### Dependencies\n- Requires: rust_proxy-cux (E2E Test Infrastructure)","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:10.297725647-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:10.297725647-05:00","dependencies":[{"issue_id":"rust_proxy-e4g","depends_on_id":"rust_proxy-cux","type":"blocks","created_at":"2026-01-18T14:56:35.841866174-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-e4g","depends_on_id":"rust_proxy-zkv","type":"blocks","created_at":"2026-01-18T14:56:51.849002867-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-ei7","title":"Add degradation state tracking and delay logic","description":"## Scope\n\nAdd state tracking for degradation mode, including debounce delay logic to prevent flapping.\n\n## Rationale\n\nWe don't want to immediately enter degraded mode on a single failed health check. A debounce delay ensures we only apply degradation after a sustained period of all proxies being unhealthy.\n\n## Implementation Details\n\n### Degradation State\n\nAdd to RuntimeState:\n\n```rust\nstruct RuntimeStateInner {\n    // ... existing fields\n\n    /// When all proxies first became unhealthy\n    all_unhealthy_since: Option\u003cDateTime\u003cUtc\u003e\u003e,\n\n    /// Whether degradation policy is currently active\n    degradation_active: bool,\n}\n```\n\n### State Transitions\n\n```rust\nimpl RuntimeState {\n    /// Called by health check loop to update degradation state\n    pub async fn update_degradation_state(\n        \u0026self,\n        all_healthy_proxies: \u0026[String],\n        delay_secs: u64,\n    ) -\u003e bool {\n        let mut inner = self.inner.write().await;\n\n        if all_healthy_proxies.is_empty() {\n            // No healthy proxies\n            let now = Utc::now();\n\n            if inner.all_unhealthy_since.is_none() {\n                // Just became unhealthy\n                inner.all_unhealthy_since = Some(now);\n                tracing::warn!(\"All proxies unhealthy, starting degradation delay\");\n            }\n\n            // Check if delay has passed\n            if let Some(since) = inner.all_unhealthy_since {\n                let elapsed = now.signed_duration_since(since).num_seconds();\n                if elapsed \u003e= delay_secs as i64 \u0026\u0026 !inner.degradation_active {\n                    inner.degradation_active = true;\n                    tracing::warn!(\n                        elapsed_secs = elapsed,\n                        \"Degradation mode activated\"\n                    );\n                    return true; // State changed to degraded\n                }\n            }\n        } else {\n            // At least one healthy proxy\n            if inner.degradation_active {\n                tracing::info!(\"Degradation mode deactivated, healthy proxy available\");\n            }\n            inner.all_unhealthy_since = None;\n            inner.degradation_active = false;\n        }\n\n        false\n    }\n\n    /// Check if degradation policy should be applied\n    pub async fn is_degraded(\u0026self) -\u003e bool {\n        self.inner.read().await.degradation_active\n    }\n\n    /// Get degradation status for display\n    pub async fn get_degradation_status(\u0026self) -\u003e Option\u003cDegradationStatus\u003e {\n        let inner = self.inner.read().await;\n        inner.all_unhealthy_since.map(|since| DegradationStatus {\n            unhealthy_since: since,\n            active: inner.degradation_active,\n        })\n    }\n}\n\npub struct DegradationStatus {\n    pub unhealthy_since: DateTime\u003cUtc\u003e,\n    pub active: bool,\n}\n```\n\n### Integration with Health Check Loop\n\n```rust\nasync fn health_check_loop(...) {\n    loop {\n        // ... run health checks\n\n        let healthy = state.get_healthy_proxies().await;\n        runtime.update_degradation_state(\n            \u0026healthy,\n            config.settings.degradation_delay_secs,\n        ).await;\n\n        // ... rest of loop\n    }\n}\n```\n\n## Acceptance Criteria\n\n- Tracks when all proxies became unhealthy\n- Only activates degradation after delay\n- Clears degradation state when any proxy recovers\n- Clear logging of state transitions\n- Status queryable for display commands","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:06:36.532110518-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:06:36.532110518-05:00","dependencies":[{"issue_id":"rust_proxy-ei7","depends_on_id":"rust_proxy-ny9","type":"blocks","created_at":"2026-01-18T14:07:31.076327578-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-f0l","title":"E2E tests for Dry-Run Mode","description":"## E2E Tests for Dry-Run Mode\n\n### Test Scenarios\n\n1. **Stop --dry-run Does Not Stop**\n   ```rust\n   #[tokio::test]\n   async fn test_stop_dry_run_preserves_daemon() {\n       let harness = TestHarness::new().await;\n       harness.start_daemon().await.unwrap();\n       assert!(harness.daemon_is_running());\n\n       let result = harness.run_command(\u0026[\"stop\", \"--dry-run\"]);\n\n       assert!(result.success);\n       assert!(result.stdout.contains(\"Would\"));\n       // Daemon should still be running\n       assert!(harness.daemon_is_running());\n   }\n   ```\n\n2. **Stop --dry-run Shows What Would Happen**\n   ```rust\n   #[tokio::test]\n   async fn test_stop_dry_run_describes_actions() {\n       let harness = TestHarness::new().await;\n       harness.start_daemon().await.unwrap();\n\n       let result = harness.run_command(\u0026[\"stop\", \"--dry-run\"]);\n\n       assert!(result.stdout.contains(\"Would stop daemon\") ||\n               result.stdout.contains(\"Would send signal\"));\n       assert!(result.stdout.contains(\"PID\") ||\n               result.stdout.contains(\"process\"));\n   }\n   ```\n\n3. **Stop -n Short Flag Works**\n   ```rust\n   #[tokio::test]\n   async fn test_stop_short_dry_run_flag() {\n       let harness = TestHarness::new().await;\n       harness.start_daemon().await.unwrap();\n\n       let result = harness.run_command(\u0026[\"stop\", \"-n\"]);\n\n       assert!(result.success);\n       assert!(result.stdout.contains(\"Would\"));\n       assert!(harness.daemon_is_running());\n   }\n   ```\n\n4. **Completions Uninstall --dry-run**\n   ```rust\n   #[tokio::test]\n   async fn test_completions_uninstall_dry_run() {\n       let harness = TestHarness::new().await;\n       let path = harness.temp_dir.path().join(\"rp\");\n\n       // Install first\n       harness.run_command(\u0026[\n           \"completions\", \"install\",\n           \"--shell\", \"bash\",\n           \"--path\", \u0026path.to_string_lossy()\n       ]);\n       assert!(path.exists());\n\n       // Dry-run uninstall\n       let result = harness.run_command(\u0026[\n           \"completions\", \"uninstall\",\n           \"--shell\", \"bash\",\n           \"--path\", \u0026path.to_string_lossy(),\n           \"--dry-run\"\n       ]);\n\n       assert!(result.success);\n       assert!(result.stdout.contains(\"Would remove\"));\n       // File should still exist\n       assert!(path.exists());\n   }\n   ```\n\n5. **Service Uninstall --dry-run**\n   ```rust\n   #[tokio::test]\n   async fn test_service_uninstall_dry_run() {\n       let harness = TestHarness::new().await;\n\n       let result = harness.run_command(\u0026[\"service\", \"uninstall\", \"--dry-run\"]);\n\n       assert!(result.success);\n       assert!(result.stdout.contains(\"Would\") ||\n               result.stdout.contains(\"would\"));\n   }\n   ```\n\n6. **Dry-run JSON Output**\n   ```rust\n   #[tokio::test]\n   async fn test_dry_run_json_output() {\n       let harness = TestHarness::new().await;\n       harness.start_daemon().await.unwrap();\n\n       let result = harness.run_command(\u0026[\"stop\", \"--dry-run\", \"--json\"]);\n\n       let json: Value = serde_json::from_str(\u0026result.stdout).unwrap();\n       assert!(json[\"dry_run\"].as_bool().unwrap());\n       assert!(json[\"actions\"].is_array());\n   }\n   ```\n\n7. **Dry-run When Nothing To Do**\n   ```rust\n   #[tokio::test]\n   async fn test_dry_run_nothing_to_stop() {\n       let harness = TestHarness::new().await;\n       // Don't start daemon\n\n       let result = harness.run_command(\u0026[\"stop\", \"--dry-run\"]);\n\n       assert!(result.success || result.exit_code == 0);\n       assert!(result.stdout.contains(\"not running\") ||\n               result.stdout.contains(\"Nothing to do\"));\n   }\n   ```\n\n8. **Multiple Operations Dry-Run**\n   ```rust\n   #[tokio::test]\n   async fn test_dry_run_shows_all_actions() {\n       let harness = TestHarness::new().await;\n       harness.start_daemon().await.unwrap();\n\n       let result = harness.run_command(\u0026[\"stop\", \"--dry-run\"]);\n\n       // Should list multiple actions if applicable\n       let action_count = result.stdout.matches(\"Would\").count();\n       // At minimum should have one action\n       assert!(action_count \u003e= 1);\n   }\n   ```\n\n### Logging Requirements\n- Log that dry-run mode is active\n- Log each action that would be taken\n- Log what resources would be affected\n- Clear indication nothing was actually changed\n\n### Dependencies\n- Requires: rust_proxy-cux (E2E Test Infrastructure)","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:31.89730503-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:31.89730503-05:00","dependencies":[{"issue_id":"rust_proxy-f0l","depends_on_id":"rust_proxy-cux","type":"blocks","created_at":"2026-01-18T14:56:37.254184952-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-f0l","depends_on_id":"rust_proxy-008","type":"blocks","created_at":"2026-01-18T14:56:55.13978588-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-flg","title":"Decide git upstream for master (bd doctor warning)","description":"bd doctor reports no upstream configured for master. Decide correct remote/upstream before pushing per landing-the-plane instructions.","notes":"Checked repo: no git remotes configured and no commits yet (git status shows 'No commits yet on master'). Need user to specify remote URL and default branch before setting upstream.","status":"closed","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-17T19:41:47.865719398-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-17T21:36:37.850033452-05:00","closed_at":"2026-01-17T21:36:37.850033452-05:00","close_reason":"Configured GitHub repo, set upstream to main, pushed initial commit."}
{"id":"rust_proxy-giu","title":"Feature: Systemd service file generation","description":"## Overview\n\nAdd a command to generate systemd service files for easy deployment on Linux servers with proper security hardening.\n\n## Strategic Value (Score: 8/10)\n\nSystemd is the standard init system on modern Linux. Providing a ready-to-use service file:\n- Dramatically simplifies server deployment\n- Ensures proper startup/shutdown behavior\n- Enables systemctl integration (start/stop/restart/status)\n- Applies security best practices automatically\n- Makes the tool feel production-ready\n\n## Background and Rationale\n\n### Current State\nUsers who want to run the proxy as a system service must manually:\n1. Write a systemd unit file\n2. Figure out correct paths and options\n3. Apply security hardening (capabilities, sandboxing)\n4. Handle reload via ExecReload\n\n### The Solution\nOne command generates a complete, secure service file:\n\n```bash\n$ rp service generate\nGenerated systemd service file: /tmp/rp.service\n\nTo install:\n  sudo cp /tmp/rp.service /etc/systemd/system/\n  sudo systemctl daemon-reload\n  sudo systemctl enable --now rp\n```\n\n## Service File Features\n\n### Basic Configuration\n```ini\n[Unit]\nDescription=Rust Proxy - High-performance HTTPS proxy\nAfter=network-online.target\nWants=network-online.target\n\n[Service]\nType=notify\nExecStart=/usr/local/bin/rp start --foreground\nExecReload=/bin/kill -HUP $MAINPID\nRestart=on-failure\nRestartSec=5\n```\n\n### Security Hardening\n```ini\n# Sandboxing\nProtectSystem=strict\nProtectHome=true\nPrivateTmp=true\nNoNewPrivileges=true\n\n# Capabilities (only what's needed)\nCapabilityBoundingSet=CAP_NET_BIND_SERVICE\nAmbientCapabilities=CAP_NET_BIND_SERVICE\n\n# Resource limits\nLimitNOFILE=65535\n```\n\n### Logging Integration\n```ini\nStandardOutput=journal\nStandardError=journal\nSyslogIdentifier=rp\n```\n\n## Implementation Plan\n\nThe feature is broken into these subtasks:\n1. Add service generate command to CLI\n2. Implement service file template with placeholders\n3. Add security hardening options\n4. Add install helper command\n\n## Configuration Options\n\n```bash\n$ rp service generate --help\nGenerate systemd service file\n\nOptions:\n  --output \u003cpath\u003e      Output path (default: /tmp/rp.service)\n  --user \u003cuser\u003e        Run as user (default: root)\n  --group \u003cgroup\u003e      Run as group (default: root)\n  --config \u003cpath\u003e      Config file path\n  --hardened           Apply maximum security hardening\n  --install            Also install to /etc/systemd/system/\n```\n\n## Acceptance Criteria\n\n- `rp service generate` creates valid systemd unit\n- Security hardening applied by default\n- Config path customizable\n- User/group configurable\n- Optional direct installation\n- Clear instructions in output","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:08:26.207808631-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:08:26.207808631-05:00","dependencies":[{"issue_id":"rust_proxy-giu","depends_on_id":"rust_proxy-gj0","type":"blocks","created_at":"2026-01-18T15:07:38.900984827-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-giu","depends_on_id":"rust_proxy-99b","type":"blocks","created_at":"2026-01-18T15:08:43.590146559-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-giu","depends_on_id":"rust_proxy-px1","type":"blocks","created_at":"2026-01-18T15:08:44.115843929-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-gj0","title":"Add service generate command to CLI","description":"## Scope\n\nAdd the `service generate` subcommand to the CLI for creating systemd service files.\n\n## Implementation Details\n\n### CLI Structure\n\n```rust\n#[derive(Debug, Subcommand)]\nenum Commands {\n    // ... existing commands\n\n    /// Manage system service installation\n    Service {\n        #[command(subcommand)]\n        action: ServiceAction,\n    },\n}\n\n#[derive(Debug, Subcommand)]\nenum ServiceAction {\n    /// Generate systemd service file\n    Generate {\n        /// Output path (default: /tmp/rp.service)\n        #[arg(long, default_value = \"/tmp/rp.service\")]\n        output: PathBuf,\n\n        /// User to run service as\n        #[arg(long, default_value = \"root\")]\n        user: String,\n\n        /// Group to run service as\n        #[arg(long, default_value = \"root\")]\n        group: String,\n\n        /// Path to config file\n        #[arg(long)]\n        config: Option\u003cPathBuf\u003e,\n\n        /// Apply maximum security hardening\n        #[arg(long)]\n        hardened: bool,\n    },\n\n    /// Install generated service file (requires sudo)\n    Install {\n        /// Service file to install\n        #[arg(default_value = \"/tmp/rp.service\")]\n        service_file: PathBuf,\n    },\n}\n```\n\n### Generate Command Implementation\n\n```rust\nfn service_generate(\n    output: PathBuf,\n    user: String,\n    group: String,\n    config: Option\u003cPathBuf\u003e,\n    hardened: bool,\n) -\u003e Result\u003c()\u003e {\n    let binary_path = std::env::current_exe()?;\n    let config_path = config.unwrap_or_else(|| config_path().unwrap());\n\n    let service_content = generate_service_file(\n        \u0026binary_path,\n        \u0026config_path,\n        \u0026user,\n        \u0026group,\n        hardened,\n    );\n\n    std::fs::write(\u0026output, \u0026service_content)?;\n\n    println!(\"Generated systemd service file: {}\", output.display());\n    println!();\n    println!(\"To install:\");\n    println!(\"  sudo cp {} /etc/systemd/system/rp.service\", output.display());\n    println!(\"  sudo systemctl daemon-reload\");\n    println!(\"  sudo systemctl enable --now rp\");\n\n    Ok(())\n}\n```\n\n## Acceptance Criteria\n\n- `rp service generate` command available\n- All options work correctly\n- Clear output with installation instructions\n- Binary path auto-detected","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:09:03.458608718-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:09:03.458608718-05:00"}
{"id":"rust_proxy-gr0","title":"Implement per-shell installation paths and logic","description":"## Scope\n\nImplement the logic to determine correct installation paths and write completion scripts for each supported shell.\n\n## Implementation Details\n\n### Installation Paths\n\n```rust\nimpl Shell {\n    pub fn completion_path(\u0026self) -\u003e Result\u003cPathBuf\u003e {\n        let home = dirs::home_dir()\n            .ok_or_else(|| anyhow::anyhow!(\"Could not determine home directory\"))?;\n\n        Ok(match self {\n            Shell::Bash =\u003e {\n                // XDG spec: ~/.local/share/bash-completion/completions/\n                let xdg_data = std::env::var(\"XDG_DATA_HOME\")\n                    .map(PathBuf::from)\n                    .unwrap_or_else(|_| home.join(\".local/share\"));\n                xdg_data.join(\"bash-completion/completions/rp\")\n            }\n            Shell::Zsh =\u003e {\n                // Check if ~/.zsh/completions exists or can be created\n                // Alternatively, use first writable dir in $fpath\n                home.join(\".zsh/completions/_rp\")\n            }\n            Shell::Fish =\u003e {\n                // Fish XDG: ~/.config/fish/completions/\n                let xdg_config = std::env::var(\"XDG_CONFIG_HOME\")\n                    .map(PathBuf::from)\n                    .unwrap_or_else(|_| home.join(\".config\"));\n                xdg_config.join(\"fish/completions/rp.fish\")\n            }\n            Shell::Unknown =\u003e anyhow::bail!(\"Cannot install completions for unknown shell\"),\n        })\n    }\n\n    pub fn activation_hint(\u0026self) -\u003e \u0026'static str {\n        match self {\n            Shell::Bash =\u003e \"Restart your shell or run: source ~/.bashrc\",\n            Shell::Zsh =\u003e \"Restart your shell or run: compinit\",\n            Shell::Fish =\u003e \"Completions are active automatically\",\n            Shell::Unknown =\u003e \"\",\n        }\n    }\n}\n```\n\n### Installation Logic\n\n```rust\npub fn install_completions(shell: Shell, dry_run: bool) -\u003e Result\u003cPathBuf\u003e {\n    let path = shell.completion_path()?;\n    let script = generate_completions(shell);\n\n    if dry_run {\n        println!(\"Would install {} completions to {}\", shell.name(), path.display());\n        return Ok(path);\n    }\n\n    // Create parent directory if needed\n    if let Some(parent) = path.parent() {\n        std::fs::create_dir_all(parent)\n            .with_context(|| format!(\"Failed to create {}\", parent.display()))?;\n    }\n\n    // Write script\n    std::fs::write(\u0026path, \u0026script)\n        .with_context(|| format!(\"Failed to write {}\", path.display()))?;\n\n    Ok(path)\n}\n```\n\n### Zsh fpath Handling\n\nZsh requires the completion directory to be in `$fpath`. Check and warn:\n\n```rust\nfn check_zsh_fpath(completion_dir: \u0026Path) -\u003e bool {\n    if let Ok(fpath) = std::env::var(\"fpath\") {\n        fpath.split(':').any(|p| Path::new(p) == completion_dir)\n    } else {\n        false\n    }\n}\n\n// If not in fpath, suggest adding to .zshrc:\n// fpath=(~/.zsh/completions $fpath)\n// autoload -Uz compinit \u0026\u0026 compinit\n```\n\n## Acceptance Criteria\n\n- Correct paths for bash, zsh, fish\n- Respects XDG_DATA_HOME and XDG_CONFIG_HOME\n- Creates parent directories as needed\n- Warns about zsh fpath if needed\n- dry_run mode works correctly","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:58:58.741533265-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:58:58.741533265-05:00","dependencies":[{"issue_id":"rust_proxy-gr0","depends_on_id":"rust_proxy-28m","type":"blocks","created_at":"2026-01-18T14:02:48.895697307-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-gr0","depends_on_id":"rust_proxy-zap","type":"blocks","created_at":"2026-01-18T14:02:48.942689113-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-hcy","title":"Add GitHub Actions CI for Rust checks","description":"Add a GitHub Actions workflow that runs cargo fmt --check, cargo clippy --all-targets -- -D warnings, and cargo check --all-targets on push/PR for main.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-17T21:49:05.778246178-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-17T22:04:01.37930898-05:00","closed_at":"2026-01-17T22:04:01.37930898-05:00","close_reason":"Already implemented in .github/workflows/ci.yml"}
{"id":"rust_proxy-hvv","title":"Implement dry-run for service commands","description":"## Implement Dry-Run for Service Commands\n\n### Overview\n\nAdd --dry-run support to service-related commands (install, uninstall) so users can preview what system changes would occur.\n\n### Commands Affected\n\n1. `rp service install --dry-run`\n2. `rp service uninstall --dry-run`\n3. `rp completions install --dry-run` (already covered separately)\n4. `rp completions uninstall --dry-run`\n\n### User Experience\n\n```bash\n$ rp service install --dry-run\nWould copy service file to /etc/systemd/system/rp.service\nWould run: systemctl daemon-reload\nWould run: systemctl enable rp\n\nNo changes made (dry-run mode)\n\n$ rp service uninstall --dry-run\nWould stop service: systemctl stop rp\nWould disable service: systemctl disable rp\nWould remove /etc/systemd/system/rp.service\nWould run: systemctl daemon-reload\n\nNo changes made (dry-run mode)\n```\n\n### Implementation\n\n```rust\npub fn service_install(args: ServiceInstallArgs) -\u003e Result\u003c()\u003e {\n    let ctx = if args.dry_run {\n        Some(DryRunContext::new())\n    } else {\n        None\n    };\n\n    let service_path = PathBuf::from(\"/etc/systemd/system/rp.service\");\n\n    if let Some(ref ctx) = ctx {\n        ctx.would_do(\u0026format!(\"Copy service file to {}\", service_path.display()));\n        ctx.would_do(\"Run: systemctl daemon-reload\");\n        if args.enable {\n            ctx.would_do(\"Run: systemctl enable rp\");\n        }\n        if args.start {\n            ctx.would_do(\"Run: systemctl start rp\");\n        }\n\n        println!(\"{}\", ctx.format());\n        println!(\"\\nNo changes made (dry-run mode)\");\n        return Ok(());\n    }\n\n    // Actual install logic\n    // ...\n}\n\npub fn service_uninstall(args: ServiceUninstallArgs) -\u003e Result\u003c()\u003e {\n    let ctx = if args.dry_run {\n        Some(DryRunContext::new())\n    } else {\n        None\n    };\n\n    let service_path = PathBuf::from(\"/etc/systemd/system/rp.service\");\n\n    if let Some(ref ctx) = ctx {\n        if service_is_active() {\n            ctx.would_do(\"Stop service: systemctl stop rp\");\n        }\n        if service_is_enabled() {\n            ctx.would_do(\"Disable service: systemctl disable rp\");\n        }\n        if service_path.exists() {\n            ctx.would_do(\u0026format!(\"Remove {}\", service_path.display()));\n        }\n        ctx.would_do(\"Run: systemctl daemon-reload\");\n\n        println!(\"{}\", ctx.format());\n        println!(\"\\nNo changes made (dry-run mode)\");\n        return Ok(());\n    }\n\n    // Actual uninstall logic\n    // ...\n}\n```\n\n### Edge Cases\n\n- Service file doesn't exist: \"Nothing to uninstall\"\n- Service not running: Skip \"would stop\" message\n- Permission issues: Show what would be attempted (user can see sudo is needed)\n\n### Acceptance Criteria\n\n- [ ] service install --dry-run works\n- [ ] service uninstall --dry-run works\n- [ ] Shows all systemctl commands that would run\n- [ ] Shows files that would be created/removed\n- [ ] Handles missing service file gracefully\n- [ ] JSON output format works","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:56:10.786834744-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:56:10.786834744-05:00","dependencies":[{"issue_id":"rust_proxy-hvv","depends_on_id":"rust_proxy-ar9","type":"blocks","created_at":"2026-01-18T15:03:46.197649202-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-hxd","title":"Add completions install command to CLI","description":"## Scope\n\nAdd the `completions install` subcommand to the CLI that ties together shell detection, script generation, and installation.\n\n## Implementation Details\n\n### CLI Structure\n\n```rust\n#[derive(Debug, Subcommand)]\nenum Commands {\n    // ... existing commands\n\n    /// Manage shell completions\n    Completions {\n        #[command(subcommand)]\n        action: CompletionsAction,\n    },\n}\n\n#[derive(Debug, Subcommand)]\nenum CompletionsAction {\n    /// Install shell completions\n    Install {\n        /// Override shell detection\n        #[arg(long, value_enum)]\n        shell: Option\u003cShellArg\u003e,\n\n        /// Show what would be done without doing it\n        #[arg(long)]\n        dry_run: bool,\n    },\n\n    /// Generate completion script to stdout\n    Generate {\n        /// Shell to generate for\n        #[arg(value_enum)]\n        shell: ShellArg,\n    },\n}\n\n#[derive(Debug, Clone, Copy, clap::ValueEnum)]\nenum ShellArg {\n    Bash,\n    Zsh,\n    Fish,\n}\n```\n\n### Install Command Implementation\n\n```rust\nfn completions_install(shell_override: Option\u003cShellArg\u003e, dry_run: bool) -\u003e Result\u003c()\u003e {\n    let shell = match shell_override {\n        Some(s) =\u003e s.into(),\n        None =\u003e {\n            let detected = detect_shell();\n            if detected == Shell::Unknown {\n                anyhow::bail!(\n                    \"Could not detect shell. Use --shell to specify: bash, zsh, or fish\"\n                );\n            }\n            println!(\"Detected shell: {}\", detected.name());\n            detected\n        }\n    };\n\n    let path = install_completions(shell, dry_run)?;\n\n    if !dry_run {\n        println!(\"Installed {} completions to {}\", shell.name(), path.display());\n        println!(\"{}\", shell.activation_hint());\n\n        // Extra hint for zsh fpath\n        if shell == Shell::Zsh {\n            if let Some(parent) = path.parent() {\n                if !check_zsh_fpath(parent) {\n                    println!();\n                    println!(\"Note: You may need to add this to your ~/.zshrc:\");\n                    println!(\"  fpath=(~/.zsh/completions $fpath)\");\n                    println!(\"  autoload -Uz compinit \u0026\u0026 compinit\");\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n```\n\n### Generate Command (For Manual Installation)\n\nKeep the existing generate-to-stdout functionality for power users:\n\n```rust\nfn completions_generate(shell: ShellArg) -\u003e Result\u003c()\u003e {\n    let script = generate_completions(shell.into());\n    print!(\"{}\", script);\n    Ok(())\n}\n```\n\n## User Experience\n\n```\n$ rp completions install\nDetected shell: zsh\nInstalled zsh completions to /home/user/.zsh/completions/_rp\nRestart your shell or run: compinit\n\n$ rp completions install --shell bash --dry-run\nWould install bash completions to /home/user/.local/share/bash-completion/completions/rp\n\n$ rp completions generate fish \u003e custom_location.fish\n```\n\n## Acceptance Criteria\n\n- `rp completions install` works with auto-detection\n- `--shell` flag overrides detection\n- `--dry-run` shows what would happen\n- `rp completions generate \u003cshell\u003e` outputs to stdout\n- Clear error when shell can't be detected\n- Helpful hints for shell-specific setup","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:02:07.025124925-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:02:07.025124925-05:00","dependencies":[{"issue_id":"rust_proxy-hxd","depends_on_id":"rust_proxy-gr0","type":"blocks","created_at":"2026-01-18T14:02:48.990341654-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-j41","title":"Implement robust accept loop error recovery in proxy daemon","description":"## Overview\n\nImplement robust error handling in the TCP accept loop within the transparent proxy daemon to prevent the entire daemon from crashing when transient OS-level errors occur.\n\n## Background \u0026 Motivation\n\nThe current implementation in `src/proxy.rs` uses:\n```rust\nlet (client, _) = listener.accept().await?;\n```\n\nThis propagates ALL accept errors upward, causing the entire daemon to exit. In production environments, transient errors can occur due to:\n- **EMFILE (24)**: Per-process file descriptor limit reached\n- **ENFILE (23)**: System-wide file descriptor limit reached\n- **ENOBUFS (105)**: No buffer space available\n- **ECONNABORTED (103)**: Connection aborted by peer before accept completed (VERY common)\n- **ECONNRESET**: Connection reset by peer during accept\n- **EINTR (4)**: Interrupted by signal\n- **EAGAIN/EWOULDBLOCK (11)**: Would block (rare with async, but possible)\n- **ENOMEM**: Out of memory (temporary condition)\n\nThese conditions can arise from:\n- Temporary resource exhaustion under high load\n- Network stack hiccups or kernel memory pressure\n- Client connection resets during the accept window\n- Signal interruptions (SIGHUP, SIGUSR1, etc.)\n- Aggressive connection attempts from scanners/bots\n\nA well-designed network server MUST distinguish between transient errors (log, backoff, retry) and fatal errors (propagate and exit).\n\n## Implementation Plan\n\n### 1. Create transient error detection helper\n```rust\n/// Check if an accept() error is transient and should be retried.\n/// \n/// Transient errors are temporary conditions that may resolve on their own.\n/// We should log them, back off briefly, and continue accepting connections.\nfn is_transient_accept_error(e: \u0026std::io::Error) -\u003e bool {\n    use std::io::ErrorKind;\n    \n    // Check by ErrorKind first (portable)\n    if matches!(e.kind(), \n        ErrorKind::ConnectionReset |     // Client reset during accept\n        ErrorKind::ConnectionAborted |   // Client aborted during accept  \n        ErrorKind::Interrupted |         // Signal interrupted syscall\n        ErrorKind::WouldBlock            // Would block (shouldn't happen, but safe)\n    ) {\n        return true;\n    }\n    \n    // Check by raw OS error code (Linux-specific)\n    // These don't have stable ErrorKind mappings\n    matches!(e.raw_os_error(), \n        Some(23) |   // ENFILE: system file table full\n        Some(24) |   // EMFILE: process file descriptor limit\n        Some(103) |  // ECONNABORTED: connection aborted\n        Some(105) |  // ENOBUFS: no buffer space\n        Some(12)     // ENOMEM: out of memory (temporary)\n    )\n}\n```\n\n### 2. Implement exponential backoff for repeated errors\nFixed 10ms sleep is suboptimal under sustained resource exhaustion. Use exponential backoff:\n```rust\nstruct AcceptBackoff {\n    current_ms: u64,\n    min_ms: u64,\n    max_ms: u64,\n    consecutive_errors: u32,\n}\n\nimpl AcceptBackoff {\n    fn new() -\u003e Self {\n        Self { current_ms: 10, min_ms: 10, max_ms: 5000, consecutive_errors: 0 }\n    }\n    \n    fn record_error(\u0026mut self) -\u003e Duration {\n        self.consecutive_errors += 1;\n        let backoff = Duration::from_millis(self.current_ms);\n        self.current_ms = (self.current_ms * 2).min(self.max_ms);\n        backoff\n    }\n    \n    fn record_success(\u0026mut self) {\n        self.current_ms = self.min_ms;\n        self.consecutive_errors = 0;\n    }\n}\n```\n\n### 3. Update accept loop with robust error handling\n```rust\n// In run_proxy():\nlet mut backoff = AcceptBackoff::new();\n\nloop {\n    let (client, client_addr) = match listener.accept().await {\n        Ok(conn) =\u003e {\n            backoff.record_success();\n            conn\n        }\n        Err(e) if is_transient_accept_error(\u0026e) =\u003e {\n            let delay = backoff.record_error();\n            tracing::warn!(\n                error = %e,\n                error_code = ?e.raw_os_error(),\n                consecutive_errors = backoff.consecutive_errors,\n                backoff_ms = delay.as_millis(),\n                \"Accept error (transient, will retry)\"\n            );\n            tokio::time::sleep(delay).await;\n            continue;\n        }\n        Err(e) =\u003e {\n            tracing::error!(error = %e, \"Accept error (fatal, exiting)\");\n            return Err(e.into());\n        }\n    };\n    \n    // ... rest of connection handling\n}\n```\n\n### 4. Add observability\nConsider adding metrics counters (optional enhancement):\n```rust\n// If metrics crate is added later:\n// metrics::counter!(\"proxy.accept.transient_errors\").increment(1);\n// metrics::gauge!(\"proxy.accept.backoff_ms\").set(delay.as_millis() as f64);\n```\n\n## Code Location\n\nFile: `src/proxy.rs`, function: `run_proxy()`, approximately line 70\n\n## File Changes Summary\n\n| File | Change |\n|------|--------|\n| `src/proxy.rs` | Add `is_transient_accept_error()` helper |\n| `src/proxy.rs` | Add `AcceptBackoff` struct |\n| `src/proxy.rs` | Update accept loop in `run_proxy()` |\n\n## Testing Requirements\n\n### Unit Tests (`src/proxy.rs` or `tests/accept_errors.rs`)\n\n1. **Test `is_transient_accept_error()` classification**:\n   ```rust\n   #[test]\n   fn test_transient_error_classification() {\n       // Transient errors should return true\n       assert!(is_transient_accept_error(\u0026io::Error::from_raw_os_error(24))); // EMFILE\n       assert!(is_transient_accept_error(\u0026io::Error::from_raw_os_error(23))); // ENFILE\n       assert!(is_transient_accept_error(\u0026io::Error::from_raw_os_error(103))); // ECONNABORTED\n       assert!(is_transient_accept_error(\u0026io::Error::from_raw_os_error(105))); // ENOBUFS\n       assert!(is_transient_accept_error(\u0026io::Error::new(ErrorKind::Interrupted, \"test\")));\n       assert!(is_transient_accept_error(\u0026io::Error::new(ErrorKind::ConnectionReset, \"test\")));\n       \n       // Fatal errors should return false\n       assert!(!is_transient_accept_error(\u0026io::Error::new(ErrorKind::AddrInUse, \"test\")));\n       assert!(!is_transient_accept_error(\u0026io::Error::new(ErrorKind::PermissionDenied, \"test\")));\n       assert!(!is_transient_accept_error(\u0026io::Error::from_raw_os_error(98))); // EADDRINUSE\n   }\n   ```\n\n2. **Test `AcceptBackoff` behavior**:\n   ```rust\n   #[test]\n   fn test_backoff_exponential_growth() {\n       let mut backoff = AcceptBackoff::new();\n       assert_eq!(backoff.record_error().as_millis(), 10);\n       assert_eq!(backoff.record_error().as_millis(), 20);\n       assert_eq!(backoff.record_error().as_millis(), 40);\n       assert_eq!(backoff.record_error().as_millis(), 80);\n   }\n   \n   #[test]\n   fn test_backoff_max_cap() {\n       let mut backoff = AcceptBackoff::new();\n       for _ in 0..20 {\n           backoff.record_error();\n       }\n       assert!(backoff.current_ms \u003c= 5000);\n   }\n   \n   #[test]\n   fn test_backoff_reset_on_success() {\n       let mut backoff = AcceptBackoff::new();\n       backoff.record_error();\n       backoff.record_error();\n       backoff.record_success();\n       assert_eq!(backoff.current_ms, 10);\n       assert_eq!(backoff.consecutive_errors, 0);\n   }\n   ```\n\n### Integration Test\n\n```rust\n// tests/daemon_resilience.rs\n#[tokio::test]\nasync fn test_daemon_survives_emfile() {\n    // 1. Start daemon\n    // 2. Exhaust file descriptors (open many files/sockets)\n    // 3. Attempt connection to daemon\n    // 4. Verify daemon is still running\n    // 5. Release file descriptors\n    // 6. Verify daemon accepts new connections\n}\n```\n\n### E2E Test Script (`tests/e2e/accept_recovery.sh`)\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\necho \"=== E2E Test: Accept Loop Recovery ===\"\n\n# Start daemon\nsudo ./target/release/rust_proxy daemon \u0026\nDAEMON_PID=$!\nsleep 2\n\necho \"[1/4] Daemon started (PID: $DAEMON_PID)\"\n\n# Simulate EMFILE by hitting ulimit\necho \"[2/4] Simulating file descriptor exhaustion...\"\n# (implementation depends on test environment)\n\n# Try to connect - should see transient error handling\necho \"[3/4] Testing connection during exhaustion...\"\ncurl -v --proxy http://127.0.0.1:12345 http://example.com 2\u003e\u00261 || true\n\n# Verify daemon still running\necho \"[4/4] Verifying daemon survival...\"\nif kill -0 $DAEMON_PID 2\u003e/dev/null; then\n    echo \"✓ PASS: Daemon survived transient error\"\nelse\n    echo \"✗ FAIL: Daemon crashed\"\n    exit 1\nfi\n\n# Cleanup\nsudo kill $DAEMON_PID\necho \"=== Test Complete ===\"\n```\n\n## Logging Format\n\nAll transient errors should be logged with structured fields for easy filtering:\n```\nWARN proxy: Accept error (transient, will retry) error=\"Too many open files (os error 24)\" error_code=24 consecutive_errors=3 backoff_ms=80\n```\n\n## Risk Assessment\n\n- **Complexity**: Low (single file, ~50 lines of code including backoff)\n- **Impact**: High (prevents production crashes, improves reliability)\n- **Risk**: Very low (strictly additive, no behavior change for normal operation)\n- **Confidence**: Very high (well-established pattern in production network servers like nginx, haproxy)\n\n## Dependencies\n\nNone - this is a foundational improvement that other features (health checks) depend on.","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:46:00.044455974-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T03:44:12.903170992-05:00","closed_at":"2026-01-18T03:44:12.903170992-05:00","close_reason":"Implemented robust accept loop error recovery with transient error detection, exponential backoff, and comprehensive unit tests. All 42 tests pass."}
{"id":"rust_proxy-k2i","title":"Add security hardening options for systemd service","description":"## Scope\n\nImplement the security hardening section for systemd service files.\n\n## Implementation Details\n\n```rust\nfn generate_hardening_section() -\u003e \u0026'static str {\n    r#\"\n# Security hardening\nProtectSystem=strict\nProtectHome=true\nPrivateTmp=true\nPrivateDevices=true\nNoNewPrivileges=true\nProtectKernelTunables=true\nProtectKernelModules=true\nProtectControlGroups=true\nRestrictAddressFamilies=AF_INET AF_INET6 AF_UNIX\nRestrictNamespaces=true\nRestrictRealtime=true\nRestrictSUIDSGID=true\nMemoryDenyWriteExecute=true\nLockPersonality=true\n\n# Capabilities (minimal set for network binding)\nCapabilityBoundingSet=CAP_NET_BIND_SERVICE\nAmbientCapabilities=CAP_NET_BIND_SERVICE\n\n# System call filtering\nSystemCallFilter=@system-service\nSystemCallFilter=~@privileged @resources\nSystemCallArchitectures=native\n\"#\n}\n```\n\n### Security Options Explained\n\n| Option | Purpose |\n|--------|---------|\n| ProtectSystem=strict | Mount / read-only except explicit paths |\n| ProtectHome=true | Make /home, /root, /run/user inaccessible |\n| PrivateTmp=true | Isolated /tmp namespace |\n| NoNewPrivileges=true | Prevent privilege escalation |\n| CapabilityBoundingSet | Only CAP_NET_BIND_SERVICE for port \u003c1024 |\n| SystemCallFilter | Restrict to safe system calls |\n\n### State Directory\n\nAdd ReadWritePaths for state directory:\n\n```ini\nReadWritePaths=/var/lib/rp\nStateDirectory=rp\n```\n\n## Acceptance Criteria\n\n- All hardening options documented\n- Service still functional with hardening\n- State directory accessible\n- Can bind to privileged ports if needed","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:10:13.618852665-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:10:13.618852665-05:00","dependencies":[{"issue_id":"rust_proxy-k2i","depends_on_id":"rust_proxy-99b","type":"blocks","created_at":"2026-01-18T14:11:09.147898824-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-kyn","title":"Add HTTP server for /metrics endpoint","description":"## Scope\n\nImplement a lightweight HTTP server that exposes the Prometheus metrics endpoint.\n\n## Implementation\n\n```rust\n// In new file: src/metrics_server.rs\n\nuse axum::{routing::get, Router};\nuse std::net::SocketAddr;\nuse tokio::sync::watch;\n\nasync fn metrics_handler() -\u003e String {\n    crate::metrics::encode_metrics()\n}\n\nasync fn health_handler() -\u003e \u0026'static str {\n    \"OK\"\n}\n\npub async fn run_metrics_server(\n    bind: SocketAddr,\n    path: String,\n    mut shutdown: watch::Receiver\u003cbool\u003e,\n) {\n    let app = Router::new()\n        .route(\u0026path, get(metrics_handler))\n        .route(\"/health\", get(health_handler));  // Optional health endpoint\n\n    tracing::info\\!(\n        bind = %bind,\n        path = %path,\n        \"Starting metrics server\"\n    );\n\n    let listener = tokio::net::TcpListener::bind(bind).await.unwrap();\n    \n    axum::serve(listener, app)\n        .with_graceful_shutdown(async move {\n            let _ = shutdown.changed().await;\n            tracing::info\\!(\"Metrics server shutting down\");\n        })\n        .await\n        .unwrap();\n}\n```\n\n## Integration with Daemon\n\n```rust\n// In run_daemon() in main.rs\nif config.settings.metrics_enabled {\n    let metrics_bind = format\\!(\n        \"{}:{}\",\n        config.settings.metrics_bind.as_deref().unwrap_or(\"0.0.0.0\"),\n        config.settings.metrics_port\n    ).parse()?;\n    \n    let metrics_path = config.settings.metrics_path.clone()\n        .unwrap_or_else(|| \"/metrics\".to_string());\n    \n    let shutdown_rx = shutdown_tx.subscribe();\n    tokio::spawn(run_metrics_server(metrics_bind, metrics_path, shutdown_rx));\n}\n```\n\n## Configuration Validation\n\n- Port must be different from proxy port\n- Path must start with \"/\"\n- Bind address must be valid IP or \"0.0.0.0\"\n\n## Error Handling\n\n- If metrics port is in use, log warning and continue (metrics are optional)\n- Do not crash daemon if metrics server fails to start\n- Graceful shutdown with the rest of the daemon\n\n## Acceptance Criteria\n\n- HTTP server starts alongside daemon when metrics_enabled=true\n- GET /metrics returns valid Prometheus text format\n- Server shuts down gracefully with daemon\n- Logs indicate metrics server status\n- Port conflict handled gracefully (warning, not crash)","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:06:31.839179955-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:06:31.839179955-05:00","dependencies":[{"issue_id":"rust_proxy-kyn","depends_on_id":"rust_proxy-l96","type":"blocks","created_at":"2026-01-18T13:07:08.470320199-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-l96","title":"Define metric types in metrics.rs module","description":"## Scope\n\nCreate a new `metrics.rs` module that defines all Prometheus metric types for rust_proxy.\n\n## Metrics Structure\n\n```rust\nuse prometheus::{\n    Counter, CounterVec, Gauge, GaugeVec, Histogram, HistogramVec,\n    Opts, Registry, histogram_opts,\n};\nuse lazy_static::lazy_static;\n\nlazy_static! {\n    pub static ref REGISTRY: Registry = Registry::new();\n    \n    // Counters\n    pub static ref REQUESTS_TOTAL: CounterVec = CounterVec::new(\n        Opts::new(\"rust_proxy_requests_total\", \"Total proxy requests\"),\n        \u0026[\"proxy\", \"status\"]\n    ).unwrap();\n    \n    pub static ref BYTES_SENT: CounterVec = CounterVec::new(\n        Opts::new(\"rust_proxy_bytes_sent_total\", \"Total bytes sent\"),\n        \u0026[\"proxy\"]\n    ).unwrap();\n    \n    pub static ref BYTES_RECEIVED: CounterVec = CounterVec::new(\n        Opts::new(\"rust_proxy_bytes_received_total\", \"Total bytes received\"),\n        \u0026[\"proxy\"]\n    ).unwrap();\n    \n    pub static ref HEALTH_CHECKS: CounterVec = CounterVec::new(\n        Opts::new(\"rust_proxy_health_checks_total\", \"Health check results\"),\n        \u0026[\"proxy\", \"result\"]\n    ).unwrap();\n    \n    pub static ref FAILOVERS: CounterVec = CounterVec::new(\n        Opts::new(\"rust_proxy_failovers_total\", \"Failover events\"),\n        \u0026[\"from\", \"to\"]\n    ).unwrap();\n    \n    // Gauges\n    pub static ref ACTIVE_CONNECTIONS: GaugeVec = GaugeVec::new(\n        Opts::new(\"rust_proxy_active_connections\", \"Current active connections\"),\n        \u0026[\"proxy\"]\n    ).unwrap();\n    \n    pub static ref PROXY_HEALTH: GaugeVec = GaugeVec::new(\n        Opts::new(\"rust_proxy_proxy_health\", \"Proxy health status (1=healthy, 0=unhealthy)\"),\n        \u0026[\"proxy\"]\n    ).unwrap();\n    \n    // Histograms\n    pub static ref CONNECTION_DURATION: HistogramVec = HistogramVec::new(\n        histogram_opts!(\n            \"rust_proxy_connection_duration_seconds\",\n            \"Connection duration in seconds\",\n            vec![0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0, 30.0, 60.0]\n        ),\n        \u0026[\"proxy\"]\n    ).unwrap();\n    \n    pub static ref HEALTH_CHECK_LATENCY: HistogramVec = HistogramVec::new(\n        histogram_opts!(\n            \"rust_proxy_health_check_latency_seconds\",\n            \"Health check latency in seconds\",\n            vec![0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0]\n        ),\n        \u0026[\"proxy\"]\n    ).unwrap();\n}\n\n/// Initialize and register all metrics with the registry\npub fn init_metrics() -\u003e Result\u003c(), prometheus::Error\u003e {\n    REGISTRY.register(Box::new(REQUESTS_TOTAL.clone()))?;\n    REGISTRY.register(Box::new(BYTES_SENT.clone()))?;\n    REGISTRY.register(Box::new(BYTES_RECEIVED.clone()))?;\n    REGISTRY.register(Box::new(HEALTH_CHECKS.clone()))?;\n    REGISTRY.register(Box::new(FAILOVERS.clone()))?;\n    REGISTRY.register(Box::new(ACTIVE_CONNECTIONS.clone()))?;\n    REGISTRY.register(Box::new(PROXY_HEALTH.clone()))?;\n    REGISTRY.register(Box::new(CONNECTION_DURATION.clone()))?;\n    REGISTRY.register(Box::new(HEALTH_CHECK_LATENCY.clone()))?;\n    Ok(())\n}\n\n/// Encode all metrics to Prometheus text format\npub fn encode_metrics() -\u003e String {\n    use prometheus::Encoder;\n    let encoder = prometheus::TextEncoder::new();\n    let mut buffer = Vec::new();\n    encoder.encode(\u0026REGISTRY.gather(), \u0026mut buffer).unwrap();\n    String::from_utf8(buffer).unwrap()\n}\n```\n\n## Design Decisions\n\n- **lazy_static**: Standard pattern for global metrics in Rust\n- **Custom Registry**: Allows us to control exactly what gets exported\n- **Label choices**: Designed for useful aggregation (by proxy, by status, etc.)\n- **Histogram buckets**: Tuned for expected latency ranges\n\n## Acceptance Criteria\n\n- New `src/metrics.rs` file created\n- All metric types defined\n- `init_metrics()` function to register all metrics\n- `encode_metrics()` function to output Prometheus format\n- Module added to `mod` declarations in main.rs","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:05:49.35941234-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:05:49.35941234-05:00","dependencies":[{"issue_id":"rust_proxy-l96","depends_on_id":"rust_proxy-s05","type":"blocks","created_at":"2026-01-18T13:07:08.328739514-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-lkr","title":"Add notify crate and file watcher infrastructure","description":"## Scope\n\nAdd the `notify` crate to Cargo.toml and create the foundational file watcher infrastructure that other subtasks will build upon.\n\n## Implementation Details\n\n### Cargo.toml Changes\n\n```toml\n[dependencies]\nnotify = \"6\"  # Cross-platform file system notification\n```\n\n### File Watcher Module (src/watcher.rs)\n\nCreate a new module that encapsulates file watching:\n\n```rust\nuse notify::{Config, RecommendedWatcher, RecursiveMode, Watcher, Event};\nuse std::path::Path;\nuse std::sync::mpsc;\nuse std::time::Duration;\n\npub struct ConfigWatcher {\n    watcher: RecommendedWatcher,\n    rx: mpsc::Receiver\u003cResult\u003cEvent, notify::Error\u003e\u003e,\n}\n\nimpl ConfigWatcher {\n    pub fn new(config_path: \u0026Path) -\u003e Result\u003cSelf\u003e {\n        let (tx, rx) = mpsc::channel();\n\n        let mut watcher = RecommendedWatcher::new(\n            move |res| { let _ = tx.send(res); },\n            Config::default()\n                .with_poll_interval(Duration::from_secs(2))\n        )?;\n\n        watcher.watch(config_path, RecursiveMode::NonRecursive)?;\n\n        Ok(Self { watcher, rx })\n    }\n\n    pub fn poll(\u0026self) -\u003e Option\u003c()\u003e {\n        // Returns Some(()) if config file changed\n        // Handles debouncing internally\n    }\n}\n```\n\n### Key Design Decisions\n\n1. **Debouncing**: Config file saves often trigger multiple events (write, chmod, etc.). Debounce to avoid multiple reloads.\n2. **Poll interval**: 2 seconds is reasonable - not too aggressive, but responsive enough.\n3. **Error handling**: Watcher failures should log but not crash daemon.\n\n## Acceptance Criteria\n\n- notify crate added to dependencies\n- ConfigWatcher struct created with new() and poll() methods\n- Watcher handles multiple rapid events gracefully\n- Module compiles and exports public interface","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:11:09.740712113-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:11:09.740712113-05:00"}
{"id":"rust_proxy-mua","title":"Add trace command for connection debugging","description":"Implement rp trace \u003ctarget\u003e that shows the full connection flow: DNS resolution, proxy selection, proxy connection, CONNECT request, proxy response, and optional TLS handshake. Time each step and report total latency.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:13:52.917829968-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:13:52.917829968-05:00","dependencies":[{"issue_id":"rust_proxy-mua","depends_on_id":"rust_proxy-5gs","type":"blocks","created_at":"2026-01-18T14:14:09.57469129-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-nai","title":"Add ping command for proxy latency testing","description":"Implement rp ping [proxy-id] that sends multiple health checks and reports latency statistics (min/avg/max, packet loss). Support --count for number of pings and --interval for timing.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:13:36.978992577-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:13:36.978992577-05:00","dependencies":[{"issue_id":"rust_proxy-nai","depends_on_id":"rust_proxy-o4n","type":"blocks","created_at":"2026-01-18T14:14:09.527184824-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-nqs","title":"Unit tests for Shell Completion","description":"## Unit Tests for Shell Completion\n\n### Test Coverage Areas\n\n1. **Shell Detection Logic**\n   ```rust\n   #[test]\n   fn test_detect_shell_from_env() {\n       std::env::set_var(\"SHELL\", \"/bin/zsh\");\n       assert_eq!(detect_shell(), Some(Shell::Zsh));\n\n       std::env::set_var(\"SHELL\", \"/usr/bin/bash\");\n       assert_eq!(detect_shell(), Some(Shell::Bash));\n\n       std::env::set_var(\"SHELL\", \"/usr/bin/fish\");\n       assert_eq!(detect_shell(), Some(Shell::Fish));\n   }\n\n   #[test]\n   fn test_detect_shell_from_parent_process() {\n       // When SHELL is unset, fall back to parent process check\n       std::env::remove_var(\"SHELL\");\n       // This test depends on the actual shell running the test\n       let shell = detect_shell_from_parent();\n       assert!(shell.is_some() || shell.is_none()); // May vary\n   }\n\n   #[test]\n   fn test_shell_parse_from_path() {\n       assert_eq!(Shell::from_path(\"/bin/bash\"), Some(Shell::Bash));\n       assert_eq!(Shell::from_path(\"/usr/local/bin/zsh\"), Some(Shell::Zsh));\n       assert_eq!(Shell::from_path(\"/opt/homebrew/bin/fish\"), Some(Shell::Fish));\n       assert_eq!(Shell::from_path(\"/bin/sh\"), None); // Unsupported\n   }\n   ```\n\n2. **Completion Script Generation**\n   ```rust\n   #[test]\n   fn test_generate_bash_completions() {\n       let script = generate_completions(Shell::Bash);\n       assert!(script.contains(\"complete -F\"));\n       assert!(script.contains(\"_rp\"));\n       assert!(script.contains(\"rp\"));\n   }\n\n   #[test]\n   fn test_generate_zsh_completions() {\n       let script = generate_completions(Shell::Zsh);\n       assert!(script.contains(\"#compdef rp\"));\n       assert!(script.contains(\"_rp\"));\n   }\n\n   #[test]\n   fn test_generate_fish_completions() {\n       let script = generate_completions(Shell::Fish);\n       assert!(script.contains(\"complete -c rp\"));\n   }\n\n   #[test]\n   fn test_completions_include_all_commands() {\n       for shell in [Shell::Bash, Shell::Zsh, Shell::Fish] {\n           let script = generate_completions(shell);\n           assert!(script.contains(\"start\"), \"Missing 'start' command for {:?}\", shell);\n           assert!(script.contains(\"stop\"), \"Missing 'stop' command for {:?}\", shell);\n           assert!(script.contains(\"status\"), \"Missing 'status' command for {:?}\", shell);\n           assert!(script.contains(\"check\"), \"Missing 'check' command for {:?}\", shell);\n       }\n   }\n   ```\n\n3. **Installation Paths**\n   ```rust\n   #[test]\n   fn test_bash_completion_path() {\n       let path = get_completion_path(Shell::Bash);\n       assert!(path.to_string_lossy().contains(\"bash-completion\") ||\n               path.to_string_lossy().contains(\"bash_completion\"));\n   }\n\n   #[test]\n   fn test_zsh_completion_path() {\n       let path = get_completion_path(Shell::Zsh);\n       // Should start with underscore for zsh\n       assert!(path.file_name().unwrap().to_string_lossy().starts_with(\"_\"));\n   }\n\n   #[test]\n   fn test_fish_completion_path() {\n       let path = get_completion_path(Shell::Fish);\n       assert!(path.to_string_lossy().contains(\"fish/completions\"));\n       assert!(path.extension().unwrap() == \"fish\");\n   }\n\n   #[test]\n   fn test_custom_path_override() {\n       let custom = PathBuf::from(\"/custom/path/rp\");\n       let path = get_completion_path_with_override(Shell::Bash, Some(custom.clone()));\n       assert_eq!(path, custom);\n   }\n   ```\n\n4. **Installation Logic**\n   ```rust\n   #[test]\n   fn test_creates_parent_directory() {\n       let temp = tempdir().unwrap();\n       let path = temp.path().join(\"subdir/completions/rp\");\n\n       install_completion(Shell::Bash, \u0026path).unwrap();\n\n       assert!(path.exists());\n       assert!(path.parent().unwrap().exists());\n   }\n\n   #[test]\n   fn test_overwrites_existing_completion() {\n       let temp = tempdir().unwrap();\n       let path = temp.path().join(\"rp\");\n\n       // Write old content\n       fs::write(\u0026path, \"old completion\").unwrap();\n\n       install_completion(Shell::Bash, \u0026path).unwrap();\n\n       let content = fs::read_to_string(\u0026path).unwrap();\n       assert!(!content.contains(\"old completion\"));\n       assert!(content.contains(\"complete\"));\n   }\n   ```\n\n5. **Uninstallation Logic**\n   ```rust\n   #[test]\n   fn test_uninstall_removes_file() {\n       let temp = tempdir().unwrap();\n       let path = temp.path().join(\"rp\");\n       fs::write(\u0026path, \"completion script\").unwrap();\n\n       uninstall_completion(\u0026path).unwrap();\n\n       assert!(!path.exists());\n   }\n\n   #[test]\n   fn test_uninstall_nonexistent_is_ok() {\n       let path = PathBuf::from(\"/nonexistent/path/rp\");\n       let result = uninstall_completion(\u0026path);\n       assert!(result.is_ok()); // Should not error\n   }\n   ```\n\n### Test Files\n- `src/completions.rs` - inline unit tests\n- `tests/unit/completions_test.rs` - extended tests","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:17.331583795-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:17.331583795-05:00","dependencies":[{"issue_id":"rust_proxy-nqs","depends_on_id":"rust_proxy-ck6","type":"blocks","created_at":"2026-01-18T14:56:53.673474241-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-ny9","title":"Add degradation policy configuration options","description":"## Scope\n\nAdd configuration fields for degradation policy and related settings.\n\n## Implementation Details\n\n### Config Additions\n\n```rust\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, Default, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum DegradationPolicy {\n    /// Reject all connections when no healthy proxy (most secure)\n    #[default]\n    FailClosed,\n    /// Try each proxy in order until one works\n    TryAll,\n    /// Use the most recently healthy proxy\n    UseLast,\n    /// Connect directly without proxy (must enable allow_direct_fallback)\n    Direct,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Settings {\n    // ... existing fields\n\n    /// Policy when all proxies are unhealthy\n    #[serde(default)]\n    pub degradation_policy: DegradationPolicy,\n\n    /// Seconds to wait before applying degradation (debounce)\n    #[serde(default = \"default_degradation_delay\")]\n    pub degradation_delay_secs: u64,\n\n    /// Allow direct connections as fallback (required for Direct policy)\n    #[serde(default)]\n    pub allow_direct_fallback: bool,\n}\n\nfn default_degradation_delay() -\u003e u64 {\n    5\n}\n```\n\n### Validation\n\n```rust\nimpl AppConfig {\n    pub fn validate(\u0026self) -\u003e Result\u003c()\u003e {\n        // ... existing validation\n\n        // Direct policy requires explicit opt-in\n        if self.settings.degradation_policy == DegradationPolicy::Direct\n            \u0026\u0026 !self.settings.allow_direct_fallback\n        {\n            anyhow::bail!(\n                \"degradation_policy 'direct' requires allow_direct_fallback = true\"\n            );\n        }\n\n        Ok(())\n    }\n}\n```\n\n### Example Config\n\n```toml\n[settings]\n# Default: fail_closed (safest)\ndegradation_policy = \"fail_closed\"\n\n# Wait 5 seconds before applying degradation\ndegradation_delay_secs = 5\n\n# Required for \"direct\" policy\nallow_direct_fallback = false\n```\n\n## Acceptance Criteria\n\n- DegradationPolicy enum with all variants\n- Default is fail_closed (safest)\n- Settings fields added with sensible defaults\n- Validation prevents direct without explicit opt-in\n- Config parsing works correctly","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:04:23.068191804-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:04:23.068191804-05:00"}
{"id":"rust_proxy-o4n","title":"Feature: Enhanced network diagnostic commands","description":"## Overview\n\nAdd diagnostic commands to help users troubleshoot proxy connectivity and configuration issues.\n\n## Strategic Value (Score: 8/10)\n\nNetwork issues are notoriously hard to debug. Diagnostic commands:\n- Reduce support burden by enabling self-service troubleshooting\n- Build user confidence in the tool\n- Surface issues that would otherwise require deep investigation\n- Make the tool feel professional and complete\n\n## Commands\n\n### `rp doctor`\nComprehensive health check of the entire setup:\n```\n$ rp doctor\nChecking configuration... OK\nChecking proxy connectivity...\n  proxy-a: OK (latency: 45ms)\n  proxy-b: FAIL (connection refused)\nChecking DNS resolution... OK\nChecking listen port... OK (127.0.0.1:8080 available)\nChecking state directory... OK (writable)\n\nSummary: 1 issue found\n  - proxy-b: Connection refused to 192.168.1.100:3128\n```\n\n### `rp ping [proxy-id]`\nTest connectivity and measure latency:\n```\n$ rp ping proxy-a\nPING proxy-a (192.168.1.50:3128)\nResponse 1: time=42ms\nResponse 2: time=45ms\nResponse 3: time=43ms\n--- proxy-a statistics ---\n3 requests, 3 responses, 0% loss\nmin/avg/max = 42/43.3/45 ms\n```\n\n### `rp trace \u003ctarget\u003e`\nTrace a connection through the proxy:\n```\n$ rp trace https://api.example.com\nResolving api.example.com... 93.184.216.34\nSelecting proxy... proxy-a (round_robin)\nConnecting to proxy... OK (32ms)\nSending CONNECT request... OK\nProxy response: HTTP/1.1 200 Connection Established\nTLS handshake... OK (TLS 1.3)\nConnection established in 156ms total\n```\n\n## Implementation Plan\n\n1. Add doctor command with comprehensive checks\n2. Add ping command for proxy latency testing\n3. Add trace command for connection debugging\n4. Integrate diagnostics into check command\n\n## Acceptance Criteria\n\n- doctor command checks config, connectivity, DNS, ports\n- ping command measures proxy latency\n- trace command shows full connection flow\n- Clear, actionable output for failures\n- JSON output option for scripting","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:13:02.613858686-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:13:02.613858686-05:00","dependencies":[{"issue_id":"rust_proxy-o4n","depends_on_id":"rust_proxy-5gs","type":"blocks","created_at":"2026-01-18T15:06:08.799587057-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-o4n","depends_on_id":"rust_proxy-mua","type":"blocks","created_at":"2026-01-18T15:06:30.330048358-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-ous","title":"Add suggestion system for common errors","description":"Implement suggest_fix() method on error types that returns actionable suggestions based on error pattern. E.g., ECONNREFUSED -\u003e 'Check proxy is running', ENOENT for config -\u003e 'Run rp init to create config'.","status":"closed","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:15:40.228263671-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:19:33.942442524-05:00","closed_at":"2026-01-18T15:19:33.942442524-05:00","close_reason":"Closed","dependencies":[{"issue_id":"rust_proxy-ous","depends_on_id":"rust_proxy-6q6","type":"blocks","created_at":"2026-01-18T14:15:56.171508109-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-ow9","title":"Unit tests for Config Watch/Reload","description":"## Unit Tests for Config Watch/Reload\n\n### Test Coverage Areas\n\n1. **Config Diff Logic**\n   ```rust\n   #[test]\n   fn test_diff_detects_added_proxy() {\n       let old = config_with_proxies(\u0026[\"a\", \"b\"]);\n       let new = config_with_proxies(\u0026[\"a\", \"b\", \"c\"]);\n       let diff = ConfigDiff::compute(\u0026old, \u0026new);\n       assert_eq!(diff.added_proxies, vec![\"c\"]);\n       assert!(diff.removed_proxies.is_empty());\n       assert!(diff.modified_proxies.is_empty());\n   }\n\n   #[test]\n   fn test_diff_detects_removed_proxy() {\n       let old = config_with_proxies(\u0026[\"a\", \"b\", \"c\"]);\n       let new = config_with_proxies(\u0026[\"a\", \"c\"]);\n       let diff = ConfigDiff::compute(\u0026old, \u0026new);\n       assert_eq!(diff.removed_proxies, vec![\"b\"]);\n   }\n\n   #[test]\n   fn test_diff_detects_modified_settings() {\n       let old = config_with_interval(30);\n       let new = config_with_interval(60);\n       let diff = ConfigDiff::compute(\u0026old, \u0026new);\n       assert!(diff.settings_changed);\n       assert!(diff.changed_settings.contains(\"health_check_interval_secs\"));\n   }\n   ```\n\n2. **Config Validation**\n   ```rust\n   #[test]\n   fn test_validates_new_config_before_reload() {\n       let validator = ConfigValidator::new();\n       let invalid = \"[[proxies]]\"; // missing required fields\n       assert!(validator.validate(invalid).is_err());\n   }\n\n   #[test]\n   fn test_validation_error_includes_line_number() {\n       let validator = ConfigValidator::new();\n       let invalid = \"[settings]\\ninvalid_key = true\";\n       let err = validator.validate(invalid).unwrap_err();\n       assert!(err.to_string().contains(\"line 2\"));\n   }\n   ```\n\n3. **Atomic Reload Mechanism**\n   ```rust\n   #[tokio::test]\n   async fn test_reload_applies_atomically() {\n       let runtime = RuntimeConfig::new(initial_config());\n       let new_config = modified_config();\n\n       runtime.reload(new_config.clone()).await.unwrap();\n\n       // Verify new config is fully applied\n       let current = runtime.current().await;\n       assert_eq!(current, new_config);\n   }\n\n   #[tokio::test]\n   async fn test_reload_rollback_on_partial_failure() {\n       let runtime = RuntimeConfig::new(initial_config());\n       let bad_config = config_that_fails_application();\n\n       let result = runtime.reload(bad_config).await;\n       assert!(result.is_err());\n\n       // Original config should still be in effect\n       let current = runtime.current().await;\n       assert_eq!(current, initial_config());\n   }\n   ```\n\n4. **File Watcher Integration**\n   ```rust\n   #[tokio::test]\n   async fn test_file_watcher_debounces_rapid_changes() {\n       let (tx, mut rx) = mpsc::channel(10);\n       let watcher = FileWatcher::new(temp_config_path(), tx);\n\n       // Make 5 rapid changes\n       for i in 0..5 {\n           write_config(\u0026temp_config_path(), \u0026format!(\"version = {}\", i));\n           tokio::time::sleep(Duration::from_millis(100)).await;\n       }\n\n       // Wait for debounce period\n       tokio::time::sleep(Duration::from_secs(3)).await;\n\n       // Should receive only 1-2 events, not 5\n       let events = collect_channel(\u0026mut rx);\n       assert!(events.len() \u003c= 2);\n   }\n   ```\n\n5. **SIGHUP Handler**\n   ```rust\n   #[tokio::test]\n   async fn test_sighup_triggers_reload() {\n       let (reload_tx, mut reload_rx) = mpsc::channel(1);\n       let handler = SignalHandler::new(reload_tx);\n\n       // Simulate SIGHUP\n       handler.handle_signal(Signal::SIGHUP);\n\n       let received = reload_rx.recv().await;\n       assert!(received.is_some());\n   }\n   ```\n\n### Thread Safety Tests\n```rust\n#[tokio::test]\nasync fn test_concurrent_reload_requests() {\n    let runtime = Arc::new(RuntimeConfig::new(initial_config()));\n\n    // Spawn multiple reload requests\n    let handles: Vec\u003c_\u003e = (0..10).map(|i| {\n        let rt = runtime.clone();\n        let cfg = config_version(i);\n        tokio::spawn(async move {\n            rt.reload(cfg).await\n        })\n    }).collect();\n\n    for h in handles {\n        let _ = h.await;\n    }\n\n    // Should be in a consistent state (one of the versions)\n    let current = runtime.current().await;\n    assert!(current.version.is_some());\n}\n```\n\n### Test Files\n- `src/config/diff.rs` - inline unit tests\n- `src/config/reload.rs` - inline unit tests\n- `tests/unit/config_reload_test.rs` - extended tests","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:06.609973845-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:06.609973845-05:00","dependencies":[{"issue_id":"rust_proxy-ow9","depends_on_id":"rust_proxy-p7m","type":"blocks","created_at":"2026-01-18T14:56:51.707731908-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-p7m","title":"Feature: Config file watch with graceful reload","description":"## Overview\n\nImplement automatic detection of configuration file changes with graceful reload of daemon configuration without connection disruption or restart.\n\n## Strategic Value (Score: 9/10)\n\nThis feature dramatically improves operational ergonomics. Currently, any config change requires `rp stop \u0026\u0026 rp start`, which disrupts active connections. With hot reload:\n- Zero-downtime configuration updates\n- Faster iteration during setup and tuning\n- Better alignment with production deployment patterns\n- Reduced friction for proxy rotation scenarios\n\n## Background and Rationale\n\n### Current Pain Point\nOperators frequently need to modify configuration:\n- Add/remove proxies\n- Adjust health check parameters\n- Change failover settings\n- Tune timeouts\n\nEach change currently requires daemon restart, which:\n1. Drops all active connections\n2. Requires manual intervention\n3. Creates a window of unavailability\n4. Discourages small, incremental improvements\n\n### Why Hot Reload is Better\nMany production services support SIGHUP-triggered reload (nginx, HAProxy, systemd units). Users expect this capability. File watching adds automatic detection without manual signal sending.\n\n## Architecture Design\n\n### File Watching Strategy\n\nUse the `notify` crate for cross-platform file system events:\n```rust\nuse notify::{Watcher, RecursiveMode, watcher};\n\nfn watch_config(path: \u0026Path, tx: mpsc::Sender\u003c()\u003e) {\n    let (watcher_tx, watcher_rx) = std::sync::mpsc::channel();\n    let mut watcher = watcher(watcher_tx, Duration::from_secs(2)).unwrap();\n    watcher.watch(path, RecursiveMode::NonRecursive).unwrap();\n\n    for event in watcher_rx {\n        if let Ok(notify::DebouncedEvent::Write(_)) = event {\n            let _ = tx.send(());\n        }\n    }\n}\n```\n\n### Reload Flow\n\n1. File change detected OR SIGHUP received\n2. Parse new configuration (fail gracefully if invalid)\n3. Diff against current config to determine what changed\n4. Apply changes atomically:\n   - New proxies: add to health check rotation\n   - Removed proxies: drain connections, remove from rotation\n   - Changed settings: update in-place\n5. Log what changed for observability\n\n### What Can Be Hot-Reloaded\n\n**Safe to reload:**\n- Proxy list (add/remove/modify)\n- Health check settings (intervals, thresholds)\n- Failover/failback settings\n- Timeouts\n- Log level\n\n**Requires restart:**\n- Listen address/port (bind is done once at startup)\n- Fundamental mode changes\n\n### Graceful Handling of Invalid Config\n\nIf new config fails validation:\n1. Log clear error message with line/column if possible\n2. Continue running with existing config\n3. Do NOT crash or enter degraded state\n4. Emit metric/event for alerting\n\n## Implementation Plan\n\nThe feature is broken into these subtasks:\n1. Add notify crate and file watcher infrastructure\n2. Implement config diff logic to detect what changed\n3. Add atomic config reload mechanism with proper synchronization\n4. Add SIGHUP handler for manual reload trigger\n5. Update daemon to integrate file watching\n6. Add `reload` command for explicit reload without signal\n\n## Testing Strategy\n\n- Unit tests for config diff logic\n- Integration test: modify config file, verify new settings applied\n- Test invalid config handling (should log error, keep running)\n- Test rapid file changes (debouncing)\n- Test SIGHUP handling\n\n## Acceptance Criteria\n\n- Daemon detects config file changes within 2 seconds\n- Valid config changes applied without connection disruption\n- Invalid config changes logged but daemon continues running\n- SIGHUP triggers immediate reload\n- `rp reload` command available for explicit reload\n- Clear logging of what changed during reload","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:10:53.733176084-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:23:23.291900892-05:00","dependencies":[{"issue_id":"rust_proxy-p7m","depends_on_id":"rust_proxy-lkr","type":"blocks","created_at":"2026-01-18T15:06:07.407338138-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-p7m","depends_on_id":"rust_proxy-7s9","type":"blocks","created_at":"2026-01-18T15:07:19.447641105-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-p7m","depends_on_id":"rust_proxy-wn9","type":"blocks","created_at":"2026-01-18T15:07:19.919231133-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-px1","title":"Add service install helper command","description":"## Scope\n\nAdd a `service install` command that installs the generated service file to the system.\n\n## Rationale\n\nWhile users can copy the file manually, a helper command:\n- Reduces chance of errors\n- Can verify service file syntax\n- Can run daemon-reload automatically\n- Provides a complete, streamlined workflow\n\n## Implementation Details\n\n```rust\nfn service_install(service_file: PathBuf) -\u003e Result\u003c()\u003e {\n    // Verify we have the service file\n    if !service_file.exists() {\n        anyhow::bail!(\n            \"Service file not found: {}\\nRun 'rp service generate' first\",\n            service_file.display()\n        );\n    }\n\n    // Check if we're running as root\n    if !running_as_root() {\n        anyhow::bail!(\n            \"Installation requires root privileges.\\n\\\n             Run with sudo: sudo rp service install\"\n        );\n    }\n\n    let dest = Path::new(\"/etc/systemd/system/rp.service\");\n\n    // Optionally validate with systemd-analyze\n    if let Ok(output) = Command::new(\"systemd-analyze\")\n        .args([\"verify\", service_file.to_str().unwrap()])\n        .output()\n    {\n        if !output.status.success() {\n            let stderr = String::from_utf8_lossy(\u0026output.stderr);\n            anyhow::bail!(\"Service file validation failed:\\n{}\", stderr);\n        }\n    }\n\n    // Copy service file\n    std::fs::copy(\u0026service_file, dest)?;\n    println!(\"Installed service file to {}\", dest.display());\n\n    // Reload systemd\n    let status = Command::new(\"systemctl\")\n        .arg(\"daemon-reload\")\n        .status()?;\n\n    if !status.success() {\n        anyhow::bail!(\"Failed to reload systemd daemon\");\n    }\n    println!(\"Reloaded systemd daemon\");\n\n    println!();\n    println!(\"Service installed! To enable and start:\");\n    println!(\"  sudo systemctl enable --now rp\");\n\n    Ok(())\n}\n\nfn running_as_root() -\u003e bool {\n    #[cfg(unix)]\n    { unsafe { libc::geteuid() } == 0 }\n\n    #[cfg(not(unix))]\n    { false }\n}\n```\n\n### Safety Checks\n\n1. Verify service file exists\n2. Check root privileges\n3. Validate with systemd-analyze (optional)\n4. Backup existing service file if present\n\n## Acceptance Criteria\n\n- Installs service file to correct location\n- Requires root/sudo\n- Validates service file before installing\n- Runs daemon-reload automatically\n- Clear success/error messages","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:10:52.272235566-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:10:52.272235566-05:00","dependencies":[{"issue_id":"rust_proxy-px1","depends_on_id":"rust_proxy-gj0","type":"blocks","created_at":"2026-01-18T14:11:09.19988855-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-px1","depends_on_id":"rust_proxy-k2i","type":"blocks","created_at":"2026-01-18T14:11:09.250498799-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-s05","title":"Add prometheus and HTTP server dependencies","description":"## Scope\n\nAdd the necessary crate dependencies for Prometheus metrics exposition.\n\n## Dependencies to Add\n\n```toml\n[dependencies]\nprometheus = \"0.13\"          # Metrics types and encoding\naxum = \"0.7\"                 # Lightweight HTTP server for /metrics\ntower = \"0.4\"                # Required for axum\n```\n\n## Why These Choices\n\n- **prometheus**: The official Rust Prometheus client library. Well-maintained, feature-complete.\n- **axum**: Lightweight, tokio-native HTTP server. We only need a simple endpoint, so axum is perfect (we already use tokio).\n- **tower**: Required by axum for middleware.\n\n## Implementation\n\n1. Add dependencies to Cargo.toml\n2. Verify they compile with existing code\n3. No feature flags needed for basic usage\n\n## Acceptance Criteria\n\n- Dependencies added to Cargo.toml\n- `cargo check` passes\n- No version conflicts with existing dependencies","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:05:31.464129831-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:23:23.431803282-05:00"}
{"id":"rust_proxy-skx","title":"Implement direct fallback degradation policy","description":"## Implement Direct Fallback Policy\n\n### Overview\n\nImplement the \"direct\" degradation policy that bypasses the proxy entirely when all proxies are unhealthy, connecting directly to targets.\n\n### Why This Exists\n\nSome use cases prioritize availability over proxy enforcement:\n- Development environments where proxy is optional\n- Non-sensitive traffic where direct connection is acceptable\n- Fallback for proxy infrastructure failures\n\n### Security Considerations\n\n**This policy is dangerous and requires explicit opt-in:**\n- Direct connections bypass proxy security controls\n- May expose client IP to targets\n- May bypass audit logging\n- Should NEVER be default\n\n### Implementation\n\n```rust\nimpl DegradationPolicy {\n    async fn handle_direct(\u0026self, target: \u0026str, config: \u0026AppConfig) -\u003e Result\u003cTcpStream\u003e {\n        // Verify direct fallback is explicitly enabled\n        if !config.settings.allow_direct_fallback {\n            anyhow::bail!(\n                \"Direct fallback requested but allow_direct_fallback is false. \\\n                 Set allow_direct_fallback = true in config to enable.\"\n            );\n        }\n\n        tracing::warn!(\n            target = %target,\n            \"DIRECT CONNECTION: All proxies failed, connecting directly. \\\n             This bypasses proxy security controls.\"\n        );\n\n        // Connect directly without proxy\n        let stream = TcpStream::connect(target).await\n            .context(\"Direct connection failed\")?;\n\n        Ok(stream)\n    }\n}\n```\n\n### Configuration\n\n```toml\n[settings]\n# Required: must be true for direct policy to work\nallow_direct_fallback = true\n\n# Set the policy\ndegradation_policy = \"direct\"\n```\n\n### Logging Requirements\n\nWhen direct fallback activates, MUST log:\n- WARNING level (not info/debug)\n- Target being connected to directly\n- That proxy controls are being bypassed\n- Suggestion to investigate proxy health\n\n### Testing\n\n1. Verify direct works when allow_direct_fallback = true\n2. Verify direct FAILS when allow_direct_fallback = false (even if policy is \"direct\")\n3. Verify warning is logged\n4. Verify actual direct connection succeeds\n\n### Acceptance Criteria\n\n- [ ] Direct policy connects without proxy\n- [ ] Requires allow_direct_fallback = true\n- [ ] Logs WARNING when activating\n- [ ] Clear error when allow_direct_fallback = false\n- [ ] Works with all target types (hostname:port, IP:port)","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:56:06.957540111-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:56:06.957540111-05:00"}
{"id":"rust_proxy-sqr","title":"Unit tests for Better Error Messages","description":"## Unit Tests for Better Error Messages\n\n### Test Coverage Areas\n\n1. **Rich Error Type Construction**\n   ```rust\n   #[test]\n   fn test_proxy_error_includes_context() {\n       let err = ProxyError::ConnectionFailed {\n           proxy_id: \"proxy-a\".to_string(),\n           address: \"192.168.1.50:3128\".to_string(),\n           source: std::io::Error::new(std::io::ErrorKind::ConnectionRefused, \"refused\"),\n       };\n\n       let display = err.to_string();\n       assert!(display.contains(\"proxy-a\"));\n       assert!(display.contains(\"192.168.1.50:3128\"));\n       assert!(display.contains(\"Connection refused\") || display.contains(\"refused\"));\n   }\n\n   #[test]\n   fn test_config_error_includes_location() {\n       let err = ConfigError::ParseError {\n           path: PathBuf::from(\"/etc/rp/config.toml\"),\n           line: Some(15),\n           column: Some(8),\n           message: \"unexpected character\".to_string(),\n       };\n\n       let display = err.to_string();\n       assert!(display.contains(\"/etc/rp/config.toml\"));\n       assert!(display.contains(\"line 15\"));\n       assert!(display.contains(\"column 8\") || display.contains(\":8\"));\n   }\n   ```\n\n2. **Suggestion System**\n   ```rust\n   #[test]\n   fn test_connection_refused_suggestion() {\n       let err = ProxyError::ConnectionFailed {\n           proxy_id: \"proxy-a\".to_string(),\n           address: \"192.168.1.50:3128\".to_string(),\n           source: io_error(std::io::ErrorKind::ConnectionRefused),\n       };\n\n       let suggestions = err.suggestions();\n       assert!(!suggestions.is_empty());\n       assert!(suggestions.iter().any(|s| s.contains(\"running\") || s.contains(\"address\")));\n   }\n\n   #[test]\n   fn test_timeout_suggestion() {\n       let err = ProxyError::Timeout {\n           proxy_id: \"proxy-a\".to_string(),\n           timeout_ms: 5000,\n       };\n\n       let suggestions = err.suggestions();\n       assert!(suggestions.iter().any(|s| s.contains(\"network\") || s.contains(\"timeout\")));\n   }\n\n   #[test]\n   fn test_auth_required_suggestion() {\n       let err = ProxyError::AuthenticationRequired {\n           proxy_id: \"proxy-a\".to_string(),\n       };\n\n       let suggestions = err.suggestions();\n       assert!(suggestions.iter().any(|s| s.contains(\"credentials\") || s.contains(\"auth\")));\n   }\n\n   #[test]\n   fn test_dns_failure_suggestion() {\n       let err = ProxyError::DnsResolutionFailed {\n           hostname: \"invalid.hostname.example\".to_string(),\n       };\n\n       let suggestions = err.suggestions();\n       assert!(suggestions.iter().any(|s| s.contains(\"DNS\") || s.contains(\"hostname\")));\n   }\n   ```\n\n3. **Error Formatting**\n   ```rust\n   #[test]\n   fn test_error_format_human_readable() {\n       let err = ProxyError::ConnectionFailed {\n           proxy_id: \"proxy-a\".to_string(),\n           address: \"192.168.1.50:3128\".to_string(),\n           source: io_error(std::io::ErrorKind::ConnectionRefused),\n       };\n\n       let formatted = err.format_human();\n\n       // Should have clear structure\n       assert!(formatted.contains(\"Error:\"));\n       assert!(formatted.contains(\"Suggestion:\") || formatted.contains(\"Try:\"));\n   }\n\n   #[test]\n   fn test_error_format_json() {\n       let err = ProxyError::ConnectionFailed {\n           proxy_id: \"proxy-a\".to_string(),\n           address: \"192.168.1.50:3128\".to_string(),\n           source: io_error(std::io::ErrorKind::ConnectionRefused),\n       };\n\n       let json = err.to_json().unwrap();\n       let parsed: Value = serde_json::from_str(\u0026json).unwrap();\n\n       assert!(parsed[\"error_type\"].is_string());\n       assert!(parsed[\"message\"].is_string());\n       assert!(parsed[\"context\"].is_object());\n       assert!(parsed[\"suggestions\"].is_array());\n   }\n   ```\n\n4. **Error Context Preservation**\n   ```rust\n   #[test]\n   fn test_error_chain_preserved() {\n       let io_err = std::io::Error::new(std::io::ErrorKind::ConnectionRefused, \"refused\");\n       let err = ProxyError::ConnectionFailed {\n           proxy_id: \"proxy-a\".to_string(),\n           address: \"192.168.1.50:3128\".to_string(),\n           source: io_err,\n       };\n\n       // Should be able to access underlying error\n       let source = err.source();\n       assert!(source.is_some());\n   }\n\n   #[test]\n   fn test_error_context_all_fields() {\n       let err = ProxyError::ConnectionFailed {\n           proxy_id: \"proxy-a\".to_string(),\n           address: \"192.168.1.50:3128\".to_string(),\n           source: io_error(std::io::ErrorKind::ConnectionRefused),\n       };\n\n       let context = err.context();\n       assert_eq!(context.get(\"proxy_id\"), Some(\u0026\"proxy-a\".to_string()));\n       assert_eq!(context.get(\"address\"), Some(\u0026\"192.168.1.50:3128\".to_string()));\n   }\n   ```\n\n5. **Common Error Patterns**\n   ```rust\n   #[test]\n   fn test_file_not_found_includes_path() {\n       let err = ConfigError::FileNotFound {\n           path: PathBuf::from(\"/etc/rp/config.toml\"),\n       };\n\n       let display = err.to_string();\n       assert!(display.contains(\"/etc/rp/config.toml\"));\n       assert!(display.contains(\"not found\") || display.contains(\"does not exist\"));\n   }\n\n   #[test]\n   fn test_permission_denied_suggestion() {\n       let err = ConfigError::PermissionDenied {\n           path: PathBuf::from(\"/etc/rp/config.toml\"),\n       };\n\n       let suggestions = err.suggestions();\n       assert!(suggestions.iter().any(|s| s.contains(\"sudo\") || s.contains(\"permission\")));\n   }\n\n   #[test]\n   fn test_port_in_use_suggestion() {\n       let err = DaemonError::PortInUse {\n           address: \"127.0.0.1:8080\".to_string(),\n       };\n\n       let suggestions = err.suggestions();\n       assert!(suggestions.iter().any(|s| s.contains(\"port\") || s.contains(\"listen\")));\n   }\n   ```\n\n6. **Suggestion Deduplication**\n   ```rust\n   #[test]\n   fn test_suggestions_not_duplicated() {\n       let err = ProxyError::ConnectionFailed {\n           proxy_id: \"proxy-a\".to_string(),\n           address: \"192.168.1.50:3128\".to_string(),\n           source: io_error(std::io::ErrorKind::ConnectionRefused),\n       };\n\n       let suggestions = err.suggestions();\n       let unique: std::collections::HashSet\u003c_\u003e = suggestions.iter().collect();\n       assert_eq!(suggestions.len(), unique.len());\n   }\n   ```\n\n### Test Files\n- `src/error.rs` - inline unit tests\n- `tests/unit/error_test.rs` - extended tests","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:38.845683893-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:38.845683893-05:00","dependencies":[{"issue_id":"rust_proxy-sqr","depends_on_id":"rust_proxy-95g","type":"blocks","created_at":"2026-01-18T14:56:57.43481449-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-tkj","title":"Implement use_last degradation policy","description":"## Scope\n\nImplement the use_last degradation policy that attempts connection through the most recently healthy proxy.\n\n## Rationale\n\nTransient failures are common. A proxy that was healthy recently is likely to work again soon. This policy provides a middle ground between fail_closed (too strict) and try_all (too slow).\n\n## Implementation Details\n\n### Track Last Healthy Proxy\n\nAdd to StateStore:\n\n```rust\nimpl StateStore {\n    /// Get the proxy ID that was most recently healthy\n    pub async fn get_last_healthy_proxy(\u0026self) -\u003e Option\u003cString\u003e {\n        let state = self.inner.read().await;\n\n        state.proxies\n            .iter()\n            .filter_map(|(id, stats)| {\n                stats.last_healthy.map(|ts| (id.clone(), ts))\n            })\n            .max_by_key(|(_, ts)| *ts)\n            .map(|(id, _)| id)\n    }\n}\n```\n\n### Policy Implementation\n\n```rust\npub async fn apply_use_last_policy(\n    config: \u0026AppConfig,\n    state: \u0026StateStore,\n    target: \u0026str,\n) -\u003e Result\u003c(TcpStream, String)\u003e {\n    let last_healthy = state.get_last_healthy_proxy().await\n        .ok_or_else(|| anyhow::anyhow!(\n            \"No proxy has ever been healthy (use_last policy)\"\n        ))?;\n\n    tracing::warn!(\n        proxy = %last_healthy,\n        \"Attempting last healthy proxy (use_last policy)\"\n    );\n\n    let proxy = config.proxies\n        .iter()\n        .find(|p| p.id == last_healthy)\n        .ok_or_else(|| anyhow::anyhow!(\n            \"Last healthy proxy '{}' no longer in config\", last_healthy\n        ))?;\n\n    let stream = connect_through_proxy(proxy, target).await?;\n\n    tracing::info!(\n        proxy = %last_healthy,\n        \"Connection to last healthy proxy succeeded\"\n    );\n\n    Ok((stream, last_healthy))\n}\n```\n\n### Edge Cases\n\n1. **No proxy ever healthy**: Fall back to fail_closed behavior\n2. **Last healthy proxy removed from config**: Log warning, fall back\n3. **Multiple proxies with same last_healthy time**: Pick by priority\n\n### Fallback Chain\n\nConsider making use_last fall back to try_all on failure:\n\n```rust\nmatch apply_use_last_policy(config, state, target).await {\n    Ok(result) =\u003e Ok(result),\n    Err(e) =\u003e {\n        tracing::debug!(error = %e, \"use_last failed, falling back to try_all\");\n        apply_try_all_policy(config, target).await\n    }\n}\n```\n\nThis is configurable: some users want strict use_last (fail if it fails), others want use_last-then-try_all.\n\n## Acceptance Criteria\n\n- Identifies most recently healthy proxy correctly\n- Attempts connection through that proxy\n- Clear logging of policy application\n- Handles edge cases gracefully\n- Optional fallback to try_all configurable","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:05:59.582462549-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:05:59.582462549-05:00","dependencies":[{"issue_id":"rust_proxy-tkj","depends_on_id":"rust_proxy-ny9","type":"blocks","created_at":"2026-01-18T14:07:31.030216809-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-toh","title":"Integrate degradation handling into connection flow","description":"## Scope\n\nIntegrate degradation policy handling into the main connection handling flow, tying together all the policy implementations.\n\n## Implementation Details\n\n### Degradation Handler\n\nCreate a unified function that applies the configured policy:\n\n```rust\npub async fn handle_degradation(\n    config: \u0026AppConfig,\n    state: \u0026StateStore,\n    runtime: \u0026RuntimeState,\n    target: \u0026str,\n) -\u003e Result\u003cOption\u003c(TcpStream, String)\u003e\u003e {\n    // Check if we're in degraded state\n    if !runtime.is_degraded().await {\n        return Ok(None); // Not degraded, use normal flow\n    }\n\n    tracing::debug!(\n        policy = ?config.settings.degradation_policy,\n        \"Applying degradation policy\"\n    );\n\n    match config.settings.degradation_policy {\n        DegradationPolicy::FailClosed =\u003e {\n            apply_fail_closed_policy().await?;\n            unreachable!() // fail_closed always returns Err\n        }\n\n        DegradationPolicy::TryAll =\u003e {\n            let (stream, proxy_id) = apply_try_all_policy(config, target).await?;\n            Ok(Some((stream, proxy_id)))\n        }\n\n        DegradationPolicy::UseLast =\u003e {\n            let (stream, proxy_id) = apply_use_last_policy(config, state, target).await?;\n            Ok(Some((stream, proxy_id)))\n        }\n\n        DegradationPolicy::Direct =\u003e {\n            if !config.settings.allow_direct_fallback {\n                // Should be caught by validation, but double-check\n                anyhow::bail!(\"Direct fallback not allowed\");\n            }\n            let stream = TcpStream::connect(target).await?;\n            tracing::warn!(target = %target, \"Connected directly (no proxy)\");\n            Ok(Some((stream, \"direct\".to_string())))\n        }\n    }\n}\n```\n\n### Connection Handler Integration\n\n```rust\nasync fn handle_connection(\n    stream: TcpStream,\n    config: Arc\u003cAppConfig\u003e,\n    state: Arc\u003cStateStore\u003e,\n    runtime: Arc\u003cRuntimeState\u003e,\n    load_balancer: Arc\u003cLoadBalancer\u003e,\n) {\n    let target = parse_connect_request(\u0026stream).await?;\n\n    // Try normal proxy selection first\n    let proxy_result = load_balancer.select_proxy(\n        config.settings.load_balance_strategy,\n        \u0026config.proxies,\n        \u0026state,\n    ).await;\n\n    let (proxy_stream, proxy_id) = match proxy_result {\n        Some(proxy_id) =\u003e {\n            // Normal path - healthy proxy available\n            let proxy = config.proxies.iter().find(|p| p.id == proxy_id).unwrap();\n            let stream = connect_through_proxy(proxy, \u0026target).await?;\n            (stream, proxy_id)\n        }\n        None =\u003e {\n            // No healthy proxy - apply degradation policy\n            match handle_degradation(\u0026config, \u0026state, \u0026runtime, \u0026target).await? {\n                Some((stream, id)) =\u003e (stream, id),\n                None =\u003e {\n                    // Degradation not active yet (within delay)\n                    // Fall back to fail_closed behavior\n                    apply_fail_closed_policy().await?;\n                    return;\n                }\n            }\n        }\n    };\n\n    tracing::debug!(proxy = %proxy_id, target = %target, \"Connection established\");\n\n    // ... proceed with bidirectional copy\n}\n```\n\n### Status Command Integration\n\nShow degradation status:\n\n```\nDaemon: running (PID 12345)\nDegradation: ACTIVE (fail_closed)\n  All unhealthy since: 2025-01-18 10:30:00 (5 minutes ago)\n```\n\n## Acceptance Criteria\n\n- Connection handler checks for degradation\n- Correct policy applied based on configuration\n- Graceful handling during degradation delay period\n- Status command shows degradation state\n- Logging indicates when degradation path is taken","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:07:15.863195651-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:07:15.863195651-05:00","dependencies":[{"issue_id":"rust_proxy-toh","depends_on_id":"rust_proxy-1g6","type":"blocks","created_at":"2026-01-18T14:07:31.125862512-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-toh","depends_on_id":"rust_proxy-7nv","type":"blocks","created_at":"2026-01-18T14:07:31.174975262-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-toh","depends_on_id":"rust_proxy-tkj","type":"blocks","created_at":"2026-01-18T14:07:31.227912772-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-toh","depends_on_id":"rust_proxy-ei7","type":"blocks","created_at":"2026-01-18T14:07:31.277067681-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-uue","title":"Implement proxy selection logic for all strategies","description":"## Scope\n\nImplement the core proxy selection logic that supports all load balancing strategies.\n\n## Location\n\nAdd to `state.rs` in the `RuntimeState` impl block, or create new `load_balancer.rs` module.\n\n## Implementation\n\n```rust\nuse std::sync::atomic::{AtomicUsize, Ordering};\n\npub struct LoadBalancer {\n    round_robin_counter: AtomicUsize,\n}\n\nimpl LoadBalancer {\n    pub fn new() -\u003e Self {\n        Self {\n            round_robin_counter: AtomicUsize::new(0),\n        }\n    }\n\n    /// Select a proxy based on the configured strategy\n    pub async fn select_proxy(\n        \u0026self,\n        strategy: LoadBalanceStrategy,\n        proxies: \u0026[ProxyConfig],\n        state: \u0026StateStore,\n    ) -\u003e Option\u003cString\u003e {\n        // Get healthy proxies\n        let healthy: Vec\u003c_\u003e = proxies\n            .iter()\n            .filter(|p| {\n                // Check health status from state\n                futures::executor::block_on(state.get_health_status(\u0026p.id))\n                    == HealthStatus::Healthy\n            })\n            .collect();\n\n        if healthy.is_empty() {\n            return None; // Will trigger degradation policy\n        }\n\n        match strategy {\n            LoadBalanceStrategy::Single =\u003e {\n                // Return highest priority (lowest number) healthy proxy\n                healthy.iter()\n                    .min_by_key(|p| p.priority.unwrap_or(100))\n                    .map(|p| p.id.clone())\n            }\n            LoadBalanceStrategy::RoundRobin =\u003e {\n                let idx = self.round_robin_counter.fetch_add(1, Ordering::Relaxed);\n                healthy.get(idx % healthy.len()).map(|p| p.id.clone())\n            }\n            LoadBalanceStrategy::LeastLatency =\u003e {\n                // Get latency from state, pick lowest\n                let mut with_latency: Vec\u003c_\u003e = healthy.iter()\n                    .map(|p| {\n                        let latency = futures::executor::block_on(\n                            state.get_latency(\u0026p.id)\n                        ).unwrap_or(f64::MAX);\n                        (p, latency)\n                    })\n                    .collect();\n                with_latency.sort_by(|a, b| a.1.partial_cmp(\u0026b.1).unwrap());\n                with_latency.first().map(|(p, _)| p.id.clone())\n            }\n            LoadBalanceStrategy::Weighted =\u003e {\n                // Weighted random selection\n                let total_weight: u32 = healthy.iter().map(|p| p.weight).sum();\n                if total_weight == 0 {\n                    return healthy.first().map(|p| p.id.clone());\n                }\n                let mut rng = rand::thread_rng();\n                let target = rng.gen_range(0..total_weight);\n                let mut cumulative = 0;\n                for proxy in \u0026healthy {\n                    cumulative += proxy.weight;\n                    if target \u003c cumulative {\n                        return Some(proxy.id.clone());\n                    }\n                }\n                healthy.last().map(|p| p.id.clone())\n            }\n        }\n    }\n}\n```\n\n## State Changes\n\nAdd latency accessor to StateStore:\n\n```rust\nimpl StateStore {\n    pub async fn get_latency(\u0026self, proxy_id: \u0026str) -\u003e Option\u003cf64\u003e {\n        let state = self.inner.read().await;\n        state.proxies.get(proxy_id).and_then(|s| s.ping_avg_ms)\n    }\n}\n```\n\n## Integration Point\n\nThe proxy.rs module should call `select_proxy()` instead of using a fixed `effective_proxy` for each new connection.\n\n## Acceptance Criteria\n\n- All four strategies implemented correctly\n- Round-robin cycles through proxies fairly\n- Least-latency uses actual health check latency data\n- Weighted selection matches configured proportions over time\n- Falls back gracefully when no healthy proxies","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:08:26.419134081-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:08:26.419134081-05:00","dependencies":[{"issue_id":"rust_proxy-uue","depends_on_id":"rust_proxy-wuo","type":"blocks","created_at":"2026-01-18T13:10:01.274091918-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-wl1","title":"Feature: Customizable health check endpoint","description":"Allow users to configure what target URL/method the health check uses. Some proxies block certain sites (like google.com used currently). Add health_check_target setting with format 'CONNECT host:port' or 'GET http://url'. Validate configured target works before using.","status":"open","priority":3,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:16:13.571005331-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:16:13.571005331-05:00","dependencies":[{"issue_id":"rust_proxy-wl1","depends_on_id":"rust_proxy-8fy","type":"blocks","created_at":"2026-01-18T15:09:01.567258229-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-wl1","depends_on_id":"rust_proxy-1yw","type":"blocks","created_at":"2026-01-18T15:09:07.063604022-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-wn9","title":"Update daemon to integrate file watching","description":"## Scope\n\nIntegrate the file watcher into the daemon's main loop so config changes are automatically detected and applied.\n\n## Rationale\n\nThis ties together all the pieces: file watcher detects changes, ConfigHolder performs reload, and the daemon reacts appropriately. This is the integration point that makes hot reload actually work end-to-end.\n\n## Implementation Details\n\n### Daemon Main Loop Integration\n\n```rust\npub async fn run_daemon() -\u003e Result\u003c()\u003e {\n    let config = AppConfig::load()?;\n    let config_path = config_path()?;\n    let config_holder = Arc::new(ConfigHolder::new(config.clone(), config_path.clone()));\n\n    // Start file watcher\n    let watcher = ConfigWatcher::new(\u0026config_path)?;\n\n    // Setup SIGHUP handler\n    setup_signal_handlers(config_holder.clone()).await;\n\n    // Spawn file watch task\n    let watcher_config = config_holder.clone();\n    tokio::spawn(async move {\n        let mut interval = tokio::time::interval(Duration::from_secs(2));\n        loop {\n            interval.tick().await;\n            if watcher.poll().is_some() {\n                tracing::debug!(\"Config file change detected\");\n                if let Err(e) = watcher_config.reload().await {\n                    tracing::error!(error = %e, \"Auto-reload failed\");\n                }\n            }\n        }\n    });\n\n    // ... rest of daemon (listener, health checks, etc.)\n}\n```\n\n### Propagating Config Changes\n\nComponents that need fresh config should either:\n1. Call `config_holder.get()` on each use (simple, slightly more overhead)\n2. Subscribe to change notifications and cache (more complex, better for hot paths)\n\nFor the proxy handler (called per-connection):\n```rust\nasync fn handle_connection(\n    stream: TcpStream,\n    config_holder: Arc\u003cConfigHolder\u003e,\n    // ...\n) {\n    let config = config_holder.get().await;\n    // Use config for this connection\n}\n```\n\nFor the health check loop (long-running):\n```rust\nasync fn health_check_loop(\n    config_holder: Arc\u003cConfigHolder\u003e,\n    // ...\n) {\n    let mut change_rx = config_holder.subscribe();\n\n    loop {\n        tokio::select! {\n            _ = ticker.tick() =\u003e {\n                let config = config_holder.get().await;\n                run_health_checks(\u0026config, \u0026state).await;\n            }\n            Ok(diff) = change_rx.recv() =\u003e {\n                if !diff.settings_changed.is_empty() {\n                    // Settings changed, may need to adjust interval\n                    tracing::info!(\"Health check settings updated\");\n                }\n            }\n        }\n    }\n}\n```\n\n### Error Recovery\n\nIf the file watcher fails (e.g., filesystem unmounted):\n- Log error but don't crash\n- SIGHUP still works as manual fallback\n- Attempt to re-establish watcher periodically\n\n## Acceptance Criteria\n\n- File changes trigger automatic reload within 2-3 seconds\n- Daemon continues running if watcher fails\n- Config changes propagate to all components\n- No memory leaks from watcher task\n- Clean shutdown stops watcher","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:56:32.72966964-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:56:32.72966964-05:00","dependencies":[{"issue_id":"rust_proxy-wn9","depends_on_id":"rust_proxy-lkr","type":"blocks","created_at":"2026-01-18T13:57:06.986635385-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-wn9","depends_on_id":"rust_proxy-3q7","type":"blocks","created_at":"2026-01-18T13:57:07.040215366-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-wuo","title":"Add load balance strategy configuration option","description":"## Scope\n\nAdd configuration options for load balancing strategy and proxy weights.\n\n## Config Changes\n\n### Settings Struct\n\n```rust\n/// Load balancing strategy\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, Default, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum LoadBalanceStrategy {\n    /// Use single active proxy with failover (current behavior)\n    #[default]\n    Single,\n    /// Cycle through healthy proxies sequentially\n    RoundRobin,\n    /// Prefer proxy with lowest latency\n    LeastLatency,\n    /// Distribute by configured weights\n    Weighted,\n}\n\npub struct Settings {\n    // ... existing fields ...\n\n    /// Load balancing strategy (default: single)\n    #[serde(default)]\n    pub load_balance_strategy: LoadBalanceStrategy,\n}\n```\n\n### ProxyConfig Struct\n\n```rust\npub struct ProxyConfig {\n    // ... existing fields ...\n\n    /// Weight for weighted load balancing (default: 100)\n    #[serde(default = \"default_weight\")]\n    pub weight: u32,\n}\n\nfn default_weight() -\u003e u32 { 100 }\n```\n\n## Validation\n\n- If strategy is \"weighted\", warn if any proxy has weight=0\n- Weights should be positive integers\n- Strategy must be valid enum variant\n\n## Backward Compatibility\n\n- Default strategy is \"single\" = current behavior\n- Existing configs without load_balance_strategy continue to work\n- Weight field defaults to 100 if not specified\n\n## Acceptance Criteria\n\n- LoadBalanceStrategy enum with serde support\n- weight field on ProxyConfig\n- Validation for strategy and weights\n- Existing configs continue to work unchanged","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:07:51.086574601-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:23:23.385325039-05:00"}
{"id":"rust_proxy-x3z","title":"Implement error suggestion system","description":"## Implement Error Suggestion System\n\n### Overview\n\nCreate a system that generates actionable suggestions based on error types and context, helping users resolve issues without documentation lookup.\n\n### Architecture\n\n```rust\npub trait ErrorWithSuggestions {\n    /// Get contextual suggestions for this error\n    fn suggestions(\u0026self) -\u003e Vec\u003cString\u003e;\n}\n\npub struct SuggestionEngine {\n    /// Error pattern -\u003e suggestions mapping\n    patterns: Vec\u003cSuggestionPattern\u003e,\n}\n\nstruct SuggestionPattern {\n    /// What to match (error type, message patterns, etc.)\n    matcher: Box\u003cdyn Fn(\u0026dyn std::error::Error) -\u003e bool\u003e,\n    /// Suggestions to provide\n    suggestions: Vec\u003cString\u003e,\n}\n```\n\n### Suggestion Mappings\n\n| Error Type | Pattern | Suggestions |\n|------------|---------|-------------|\n| ConnectionRefused | `kind == ConnectionRefused` | \"Check that the proxy server is running\", \"Verify the proxy address and port are correct\", \"Check firewall rules allow outbound connections\" |\n| Timeout | `kind == TimedOut` | \"Check network connectivity\", \"Increase timeout with --timeout flag\", \"Verify proxy server is responsive\" |\n| DNS Resolution | `contains(\"resolve\")` | \"Check the hostname is correct\", \"Verify DNS configuration\", \"Try using IP address instead\" |\n| Permission Denied | `kind == PermissionDenied` | \"Run with sudo for system operations\", \"Check file ownership and permissions\" |\n| Config Parse Error | `is ConfigError::Parse` | \"Check TOML syntax at the indicated line\", \"Verify all required fields are present\", \"Run 'rp check' for detailed validation\" |\n| Auth Required | `contains(\"407\")` | \"Configure proxy credentials in config file\", \"Check username/password are correct\" |\n| Port In Use | `contains(\"address already in use\")` | \"Check if another instance is running\", \"Use a different port with listen = \\\"127.0.0.1:PORT\\\"\" |\n\n### Implementation\n\n```rust\nimpl SuggestionEngine {\n    pub fn new() -\u003e Self {\n        let mut patterns = Vec::new();\n\n        // Connection refused\n        patterns.push(SuggestionPattern {\n            matcher: Box::new(|e| {\n                e.to_string().to_lowercase().contains(\"connection refused\")\n            }),\n            suggestions: vec![\n                \"Check that the proxy server is running\".to_string(),\n                \"Verify the proxy address and port are correct\".to_string(),\n                \"Check firewall rules allow outbound connections\".to_string(),\n            ],\n        });\n\n        // Timeout\n        patterns.push(SuggestionPattern {\n            matcher: Box::new(|e| {\n                let s = e.to_string().to_lowercase();\n                s.contains(\"timeout\") || s.contains(\"timed out\")\n            }),\n            suggestions: vec![\n                \"Check network connectivity to the proxy\".to_string(),\n                \"Increase timeout in configuration\".to_string(),\n                \"Verify proxy server is responsive\".to_string(),\n            ],\n        });\n\n        // DNS\n        patterns.push(SuggestionPattern {\n            matcher: Box::new(|e| {\n                let s = e.to_string().to_lowercase();\n                s.contains(\"resolve\") || s.contains(\"dns\") || s.contains(\"no such host\")\n            }),\n            suggestions: vec![\n                \"Check the hostname is spelled correctly\".to_string(),\n                \"Verify DNS configuration on this machine\".to_string(),\n                \"Try using IP address instead of hostname\".to_string(),\n            ],\n        });\n\n        // Add more patterns...\n\n        Self { patterns }\n    }\n\n    pub fn get_suggestions(\u0026self, error: \u0026dyn std::error::Error) -\u003e Vec\u003cString\u003e {\n        self.patterns\n            .iter()\n            .filter(|p| (p.matcher)(error))\n            .flat_map(|p| p.suggestions.clone())\n            .collect()\n    }\n}\n```\n\n### Formatting\n\n```rust\npub fn format_error_with_suggestions(error: \u0026dyn std::error::Error) -\u003e String {\n    let suggestions = SUGGESTION_ENGINE.get_suggestions(error);\n\n    let mut output = format!(\"Error: {}\\n\", error);\n\n    if !suggestions.is_empty() {\n        output.push_str(\"\\nSuggestions:\\n\");\n        for (i, suggestion) in suggestions.iter().enumerate() {\n            output.push_str(\u0026format!(\"  {}. {}\\n\", i + 1, suggestion));\n        }\n    }\n\n    output\n}\n```\n\n### Acceptance Criteria\n\n- [ ] SuggestionEngine provides suggestions for common errors\n- [ ] Suggestions are actionable (verbs, specific steps)\n- [ ] No duplicate suggestions\n- [ ] Suggestions appear in error output\n- [ ] JSON format includes suggestions array\n- [ ] At least 10 error patterns covered","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:56:12.134884344-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:56:12.134884344-05:00","dependencies":[{"issue_id":"rust_proxy-x3z","depends_on_id":"rust_proxy-6q6","type":"blocks","created_at":"2026-01-18T15:04:34.035097302-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-x5i","title":"Add systemd service file for daemon","status":"closed","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T00:30:09.219153213-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T00:44:57.642536479-05:00","closed_at":"2026-01-18T00:44:57.642536479-05:00","close_reason":"Completed: added systemd service file, env template, and README documentation"}
{"id":"rust_proxy-xw7","title":"Load balancing across healthy proxies","description":"## Overview\n\nInstead of using a single \"active\" proxy with failover only on health failure, actively distribute traffic across multiple healthy proxies using configurable strategies.\n\n## Why This Matters\n\nCurrently, rust_proxy uses a single active proxy and only switches on failure. With multiple healthy proxies, users want to:\n- **Improve performance**: Use parallel capacity of multiple proxies\n- **Improve reliability**: No single point of failure\n- **Better resource utilization**: Spread load across available proxies\n- **Automatic optimization**: Use the fastest proxy without manual selection\n\n## Load Balancing Strategies\n\n### 1. Single (Current Behavior)\nUse one active proxy, failover only on health failure. This remains the default for backward compatibility.\n\n### 2. Round-Robin\nCycle through healthy proxies sequentially. Simple, fair distribution.\n\n### 3. Least-Latency\nPrefer the proxy with lowest recent latency (uses health check latency data). Automatically optimizes for performance.\n\n### 4. Weighted\nDistribute by configured weights. Useful when proxies have different capacities or costs.\n\n## Configuration\n\n```toml\n[settings]\n# Load balancing strategy: \"single\" (default), \"round_robin\", \"least_latency\", \"weighted\"\nload_balance_strategy = \"least_latency\"\n\n[[proxies]]\nid = \"mesh-us\"\nurl = \"http://us-wa.proxymesh.com:31280\"\npriority = 1\nweight = 60    # For weighted strategy: 60% of traffic\n\n[[proxies]]\nid = \"mesh-eu\"\nurl = \"http://eu.proxymesh.com:31280\"\npriority = 2\nweight = 40    # For weighted strategy: 40% of traffic\n```\n\n## Implementation Approach\n\nThe RuntimeState already tracks health per proxy. We extend it with:\n1. Proxy selection method that considers strategy\n2. Round-robin counter (atomic)\n3. Latency tracking integration (already have this from health checks)\n4. Weight-based random selection\n\n## Example Behavior\n\nWith `least_latency` strategy and three healthy proxies:\n- mesh-us: 45ms average latency\n- mesh-eu: 120ms average latency\n- mesh-jp: 200ms average latency\n\nTraffic is routed to mesh-us (fastest) until it becomes unhealthy or its latency increases.\n\nWith `round_robin`, requests cycle: mesh-us -\u003e mesh-eu -\u003e mesh-jp -\u003e mesh-us -\u003e ...\n\n## Status Command Output\n\n```\nLoad Balancing: least_latency\n  mesh-us: ✓ healthy (45ms) - ACTIVE\n  mesh-eu: ✓ healthy (120ms)\n  mesh-jp: ✓ healthy (200ms)\n```\n\n## Success Criteria\n\n- All strategies implemented and working\n- Strategy configurable via config file\n- Status command shows load balancing info\n- Backward compatible (single strategy = current behavior)\n- Performance impact minimal\n\n## Estimated Effort: 4-5 hours","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:07:33.730422041-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:07:33.730422041-05:00","dependencies":[{"issue_id":"rust_proxy-xw7","depends_on_id":"rust_proxy-wuo","type":"blocks","created_at":"2026-01-18T15:07:42.10656925-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-xw7","depends_on_id":"rust_proxy-51u","type":"blocks","created_at":"2026-01-18T15:08:14.618963667-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-xxb","title":"E2E tests for Config Watch/Reload","description":"## E2E Tests for Config Watch/Reload\n\n### Test Scenarios\n\n1. **Config File Change Triggers Reload**\n   ```rust\n   #[tokio::test]\n   async fn test_file_change_triggers_reload() {\n       let harness = TestHarness::with_config(initial_config()).await;\n       harness.start_daemon().await.unwrap();\n\n       // Verify initial state\n       let status = harness.run_command(\u0026[\"status\", \"--json\"]);\n       assert!(status.stdout.contains(\"\\\"health_check_interval_secs\\\": 30\"));\n\n       // Modify config file\n       harness.update_config(config_with_interval(60)).await;\n\n       // Wait for reload (2s detection + processing)\n       tokio::time::sleep(Duration::from_secs(5)).await;\n\n       // Verify new setting applied\n       let status = harness.run_command(\u0026[\"status\", \"--json\"]);\n       assert!(status.stdout.contains(\"\\\"health_check_interval_secs\\\": 60\"));\n   }\n   ```\n\n2. **Invalid Config Keeps Running**\n   ```rust\n   #[tokio::test]\n   async fn test_invalid_config_keeps_daemon_running() {\n       let harness = TestHarness::with_config(valid_config()).await;\n       harness.start_daemon().await.unwrap();\n\n       // Write invalid config\n       harness.update_config(\"invalid toml {{{\").await;\n\n       // Wait for reload attempt\n       tokio::time::sleep(Duration::from_secs(5)).await;\n\n       // Daemon should still be running\n       assert!(harness.daemon_is_running());\n\n       // Original config should still be in effect\n       let status = harness.run_command(\u0026[\"status\"]);\n       assert!(status.success);\n   }\n   ```\n\n3. **SIGHUP Triggers Immediate Reload**\n   ```rust\n   #[tokio::test]\n   async fn test_sighup_triggers_reload() {\n       let harness = TestHarness::with_config(initial_config()).await;\n       harness.start_daemon().await.unwrap();\n\n       // Update config file\n       harness.update_config(modified_config()).await;\n\n       // Send SIGHUP\n       harness.send_signal(Signal::SIGHUP).await;\n\n       // Reload should happen immediately\n       tokio::time::sleep(Duration::from_millis(500)).await;\n\n       let status = harness.run_command(\u0026[\"status\", \"--json\"]);\n       assert!(status.stdout.contains(\"modified_value\"));\n   }\n   ```\n\n4. **Reload Command Works**\n   ```rust\n   #[tokio::test]\n   async fn test_reload_command() {\n       let harness = TestHarness::with_config(initial_config()).await;\n       harness.start_daemon().await.unwrap();\n\n       harness.update_config(modified_config()).await;\n\n       let result = harness.run_command(\u0026[\"reload\"]);\n       assert!(result.success);\n       assert!(result.stdout.contains(\"Configuration reloaded\"));\n   }\n   ```\n\n5. **Added Proxy Becomes Available**\n   ```rust\n   #[tokio::test]\n   async fn test_added_proxy_becomes_available() {\n       let mut harness = TestHarness::with_config(single_proxy_config()).await;\n       harness.start_daemon().await.unwrap();\n\n       // Add new proxy to config\n       let new_mock = harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 50 }).await;\n       harness.update_config(two_proxy_config(new_mock.port())).await;\n\n       // Trigger reload\n       harness.run_command(\u0026[\"reload\"]);\n       tokio::time::sleep(Duration::from_secs(3)).await;\n\n       // New proxy should appear in status\n       let status = harness.run_command(\u0026[\"status\"]);\n       assert!(status.stdout.contains(\"new-proxy\"));\n   }\n   ```\n\n6. **Removed Proxy Drains Connections**\n   ```rust\n   #[tokio::test]\n   async fn test_removed_proxy_drains() {\n       let mut harness = TestHarness::with_config(two_proxy_config()).await;\n       harness.start_daemon().await.unwrap();\n\n       // Start a long-running connection through proxy-b\n       let conn = start_long_connection(\u0026harness, \"proxy-b\").await;\n\n       // Remove proxy-b from config\n       harness.update_config(single_proxy_config()).await;\n       harness.run_command(\u0026[\"reload\"]);\n\n       // Existing connection should continue\n       assert!(conn.is_alive());\n\n       // New connections should not go to removed proxy\n       let status = harness.run_command(\u0026[\"status\"]);\n       assert!(!status.stdout.contains(\"proxy-b\"));\n   }\n   ```\n\n7. **Listen Address Change Requires Restart**\n   ```rust\n   #[tokio::test]\n   async fn test_listen_address_requires_restart() {\n       let harness = TestHarness::with_config(r#\"\n           [settings]\n           listen = \"127.0.0.1:8080\"\n       \"#).await;\n       harness.start_daemon().await.unwrap();\n\n       harness.update_config(r#\"\n           [settings]\n           listen = \"127.0.0.1:9090\"\n       \"#).await;\n       let result = harness.run_command(\u0026[\"reload\"]);\n\n       // Should warn that restart is required\n       assert!(result.stdout.contains(\"requires restart\") ||\n               result.stderr.contains(\"requires restart\"));\n   }\n   ```\n\n### Logging Requirements\n- Log config file modification events\n- Log reload trigger source (file change, SIGHUP, command)\n- Log config diff (what changed)\n- Log reload success/failure with details\n- On failure, dump daemon logs around reload time\n\n### Dependencies\n- Requires: rust_proxy-cux (E2E Test Infrastructure)","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:08.52717589-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:08.52717589-05:00","dependencies":[{"issue_id":"rust_proxy-xxb","depends_on_id":"rust_proxy-cux","type":"blocks","created_at":"2026-01-18T14:56:35.793119026-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-xxb","depends_on_id":"rust_proxy-p7m","type":"blocks","created_at":"2026-01-18T14:56:51.755969687-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-y9o","title":"Add reload command for explicit reload without signal","description":"## Scope\n\nAdd a `reload` CLI command that sends SIGHUP to the running daemon, providing a user-friendly way to trigger config reload without manually finding the PID.\n\n## Rationale\n\nWhile `kill -HUP $(cat /path/to/pidfile)` works, it's cumbersome. A dedicated `rp reload` command is:\n- More discoverable\n- Easier to remember\n- Consistent with other CLI commands\n- Provides better feedback (success/failure messages)\n\n## Implementation Details\n\n### CLI Command\n\n```rust\n#[derive(Debug, Subcommand)]\nenum Commands {\n    // ... existing commands\n\n    /// Reload daemon configuration without restart\n    Reload,\n}\n```\n\n### Implementation\n\n```rust\nfn reload_cmd() -\u003e Result\u003c()\u003e {\n    let pid = read_daemon_pid()?;\n\n    #[cfg(unix)]\n    {\n        use nix::sys::signal::{kill, Signal};\n        use nix::unistd::Pid;\n\n        kill(Pid::from_raw(pid), Signal::SIGHUP)\n            .context(\"Failed to send SIGHUP to daemon\")?;\n\n        println!(\"Reload signal sent to daemon (PID {})\", pid);\n        println!(\"Check daemon logs for reload status\");\n        Ok(())\n    }\n\n    #[cfg(not(unix))]\n    {\n        anyhow::bail!(\"Reload command not supported on this platform\");\n    }\n}\n\nfn read_daemon_pid() -\u003e Result\u003ci32\u003e {\n    let pid_path = pid_file_path()?;\n    let content = fs::read_to_string(\u0026pid_path)\n        .with_context(|| format!(\"No running daemon (missing {})\", pid_path.display()))?;\n    content.trim().parse()\n        .context(\"Invalid PID in pidfile\")\n}\n```\n\n### User Experience\n\n```\n$ rp reload\nReload signal sent to daemon (PID 12345)\nCheck daemon logs for reload status\n\n$ rp reload\nError: No running daemon (missing /var/run/rp/rp.pid)\n\n$ rp status  # Could show last reload time\nDaemon: running (PID 12345)\nLast config reload: 2025-01-18 10:30:00\nConfig file: /etc/rp/config.toml\n```\n\n### Alternative: IPC-Based Reload\n\nFor richer feedback, consider using IPC (Unix socket) instead of just signals:\n\n```rust\n// Future enhancement: daemon listens on socket for commands\n// Client sends \"reload\" command, gets back result\n```\n\nThis is more complex but enables:\n- Synchronous feedback (reload succeeded/failed)\n- Richer error messages\n- Config diff in response\n\nFor now, signal-based is simpler and sufficient.\n\n## Acceptance Criteria\n\n- `rp reload` sends SIGHUP to running daemon\n- Clear error message if no daemon running\n- Success message with PID\n- Works on Unix systems\n- Graceful error on unsupported platforms","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:56:57.852651983-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:56:57.852651983-05:00","dependencies":[{"issue_id":"rust_proxy-y9o","depends_on_id":"rust_proxy-3q7","type":"blocks","created_at":"2026-01-18T13:57:07.087318535-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-z4w","title":"E2E tests for Better Error Messages","description":"## E2E Tests for Better Error Messages\n\n### Test Scenarios\n\n1. **Connection Refused Shows Helpful Message**\n   ```rust\n   #[tokio::test]\n   async fn test_connection_refused_error_message() {\n       let harness = TestHarness::with_config(r#\"\n           [[proxies]]\n           id = \"bad-proxy\"\n           url = \"http://127.0.0.1:59999\"  # Nothing listening\n       \"#).await;\n\n       let result = harness.run_command(\u0026[\"check\", \"--test-connectivity\"]);\n\n       assert!(!result.success);\n       // Should include context\n       assert!(result.stderr.contains(\"bad-proxy\") ||\n               result.stdout.contains(\"bad-proxy\"));\n       assert!(result.stderr.contains(\"127.0.0.1:59999\") ||\n               result.stdout.contains(\"127.0.0.1:59999\"));\n       // Should include suggestion\n       assert!(result.stderr.contains(\"running\") ||\n               result.stderr.contains(\"address\") ||\n               result.stdout.contains(\"Suggestion\"));\n   }\n   ```\n\n2. **Config Parse Error Shows Location**\n   ```rust\n   #[tokio::test]\n   async fn test_config_error_shows_line() {\n       let harness = TestHarness::new().await;\n       let bad_config = r#\"\n           [settings]\n           valid = true\n\n           [[proxies]\n           # Missing closing bracket\n           id = \"test\"\n       \"#;\n       harness.write_config(bad_config).await;\n\n       let result = harness.run_command(\u0026[\"check\"]);\n\n       assert!(!result.success);\n       // Should show line number\n       assert!(result.stderr.contains(\"line\") ||\n               result.stderr.contains(\":5\") ||\n               result.stderr.contains(\":6\"));\n   }\n   ```\n\n3. **File Not Found Shows Path**\n   ```rust\n   #[tokio::test]\n   async fn test_file_not_found_shows_path() {\n       let result = Command::new(\"rp\")\n           .args(\u0026[\"check\", \"--config\", \"/nonexistent/path/config.toml\"])\n           .output()\n           .unwrap();\n\n       let stderr = String::from_utf8_lossy(\u0026result.stderr);\n       assert!(stderr.contains(\"/nonexistent/path/config.toml\"));\n       assert!(stderr.contains(\"not found\") || stderr.contains(\"does not exist\"));\n   }\n   ```\n\n4. **Permission Denied Suggests sudo**\n   ```rust\n   #[tokio::test]\n   async fn test_permission_denied_suggestion() {\n       // Create a file we can't read\n       let harness = TestHarness::new().await;\n       let config_path = harness.temp_dir.path().join(\"unreadable.toml\");\n       fs::write(\u0026config_path, \"[settings]\").unwrap();\n       fs::set_permissions(\u0026config_path, fs::Permissions::from_mode(0o000)).unwrap();\n\n       let result = harness.run_command(\u0026[\n           \"check\",\n           \"--config\", \u0026config_path.to_string_lossy()\n       ]);\n\n       assert!(!result.success);\n       assert!(result.stderr.contains(\"permission\") ||\n               result.stderr.contains(\"Permission\"));\n       // May suggest sudo or permissions fix\n   }\n   ```\n\n5. **Timeout Error Includes Duration**\n   ```rust\n   #[tokio::test]\n   async fn test_timeout_error_includes_duration() {\n       let mut harness = TestHarness::with_config(r#\"\n           [settings]\n           health_check_timeout_ms = 100\n\n           [[proxies]]\n           id = \"slow-proxy\"\n           url = \"http://localhost:MOCK_PORT\"\n       \"#).await;\n\n       // Mock that takes forever to respond\n       harness.add_mock_proxy(MockBehavior::Healthy { latency_ms: 5000 }).await;\n\n       let result = harness.run_command(\u0026[\"check\", \"--test-connectivity\"]);\n\n       // Should mention timeout\n       assert!(result.stderr.contains(\"timeout\") ||\n               result.stdout.contains(\"timeout\"));\n   }\n   ```\n\n6. **JSON Error Format**\n   ```rust\n   #[tokio::test]\n   async fn test_error_json_format() {\n       let harness = TestHarness::with_config(r#\"\n           [[proxies]]\n           id = \"bad-proxy\"\n           url = \"http://127.0.0.1:59999\"\n       \"#).await;\n\n       let result = harness.run_command(\u0026[\"check\", \"--test-connectivity\", \"--json\"]);\n\n       if !result.success {\n           let json: Value = serde_json::from_str(\u0026result.stdout).unwrap_or_else(|_| {\n               serde_json::from_str(\u0026result.stderr).unwrap()\n           });\n\n           assert!(json[\"error\"].is_object() || json[\"errors\"].is_array());\n       }\n   }\n   ```\n\n7. **Multiple Errors All Shown**\n   ```rust\n   #[tokio::test]\n   async fn test_multiple_errors_all_shown() {\n       let harness = TestHarness::with_config(r#\"\n           [[proxies]]\n           id = \"bad-1\"\n           url = \"http://127.0.0.1:59991\"\n\n           [[proxies]]\n           id = \"bad-2\"\n           url = \"http://127.0.0.1:59992\"\n       \"#).await;\n\n       let result = harness.run_command(\u0026[\"check\", \"--test-connectivity\"]);\n\n       // Should show both errors\n       assert!(result.stderr.contains(\"bad-1\") || result.stdout.contains(\"bad-1\"));\n       assert!(result.stderr.contains(\"bad-2\") || result.stdout.contains(\"bad-2\"));\n   }\n   ```\n\n8. **Suggestion Actionability**\n   ```rust\n   #[tokio::test]\n   async fn test_suggestions_are_actionable() {\n       let harness = TestHarness::with_config(r#\"\n           [[proxies]]\n           id = \"bad-proxy\"\n           url = \"http://127.0.0.1:59999\"\n       \"#).await;\n\n       let result = harness.run_command(\u0026[\"check\", \"--test-connectivity\"]);\n\n       let output = format!(\"{}{}\", result.stdout, result.stderr);\n\n       // Suggestions should be actionable, not just \"an error occurred\"\n       let has_actionable = output.contains(\"Check\") ||\n                           output.contains(\"Verify\") ||\n                           output.contains(\"Try\") ||\n                           output.contains(\"Ensure\") ||\n                           output.contains(\"Make sure\");\n       assert!(has_actionable, \"Error message should have actionable suggestion\");\n   }\n   ```\n\n### Logging Requirements\n- Log error type and full context\n- Log suggestions generated for each error\n- Log error chain if nested errors\n- On test failure, dump full stderr and stdout\n\n### Dependencies\n- Requires: rust_proxy-cux (E2E Test Infrastructure)","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:54:39.98396126-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:54:39.98396126-05:00","dependencies":[{"issue_id":"rust_proxy-z4w","depends_on_id":"rust_proxy-cux","type":"blocks","created_at":"2026-01-18T14:56:37.301329835-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-z4w","depends_on_id":"rust_proxy-95g","type":"blocks","created_at":"2026-01-18T14:56:57.483952924-05:00","created_by":"Dicklesworthstone"}]}
{"id":"rust_proxy-zap","title":"Implement completion script generation using clap_complete","description":"## Scope\n\nUse clap_complete to generate shell-specific completion scripts for bash, zsh, and fish.\n\n## Implementation Details\n\n### Add clap_complete Dependency\n\n```toml\n[dependencies]\nclap_complete = \"4\"\n```\n\n### Script Generation\n\n```rust\nuse clap_complete::{generate, shells::{Bash, Zsh, Fish}};\n\npub fn generate_completions(shell: Shell) -\u003e String {\n    let mut cmd = Cli::command();\n    let mut buf = Vec::new();\n\n    match shell {\n        Shell::Bash =\u003e generate(Bash, \u0026mut cmd, \"rp\", \u0026mut buf),\n        Shell::Zsh =\u003e generate(Zsh, \u0026mut cmd, \"rp\", \u0026mut buf),\n        Shell::Fish =\u003e generate(Fish, \u0026mut cmd, \"rp\", \u0026mut buf),\n        Shell::Unknown =\u003e panic!(\"Cannot generate completions for unknown shell\"),\n    }\n\n    String::from_utf8(buf).expect(\"clap_complete generates valid UTF-8\")\n}\n```\n\n### Testing Generation\n\nEnsure scripts are valid by checking they contain expected content:\n\n```rust\n#[test]\nfn test_bash_completions() {\n    let script = generate_completions(Shell::Bash);\n    assert!(script.contains(\"complete -F\"));\n    assert!(script.contains(\"rp\"));\n}\n\n#[test]\nfn test_zsh_completions() {\n    let script = generate_completions(Shell::Zsh);\n    assert!(script.contains(\"#compdef rp\"));\n}\n\n#[test]\nfn test_fish_completions() {\n    let script = generate_completions(Shell::Fish);\n    assert!(script.contains(\"complete -c rp\"));\n}\n```\n\n## Acceptance Criteria\n\n- clap_complete dependency added\n- Scripts generated for bash, zsh, fish\n- Scripts contain correct command name (rp)\n- Scripts are syntactically valid (basic smoke test)","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:58:30.718526026-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:58:30.718526026-05:00"}
{"id":"rust_proxy-zkv","title":"Feature: Graceful degradation when all proxies fail","description":"## Overview\n\nImplement configurable behavior for when all proxies are unhealthy, giving users control over how the system degrades rather than simply failing.\n\n## Strategic Value (Score: 9/10)\n\nThis is critical for production reliability. When all proxies fail, the current behavior is undefined/catastrophic. Users need:\n- Predictable behavior they can reason about\n- Policy options that match their use case\n- Clear logging to understand what's happening\n- Potential fallback paths\n\n## Background and Rationale\n\n### The Problem\nCurrently, if all configured proxies become unhealthy:\n- New connections may fail unpredictably\n- No clear policy for what to do\n- Users have no visibility into the situation\n- No recovery path\n\n### Why This Matters\nDifferent use cases need different degradation behaviors:\n- **Security-critical**: Fail closed - better no connection than potentially leaked traffic\n- **Availability-critical**: Try anyway - maybe health check is wrong, let the connection attempt\n- **Caching use case**: Use last known good - proxy was working recently, worth trying\n\n## Degradation Policies\n\n### Policy 1: fail_closed (Default)\nReject new connections immediately with clear error:\n```\nConnection rejected: No healthy proxies available\n```\nBest for: Security-sensitive environments where traffic must go through proxy\n\n### Policy 2: try_all\nAttempt connection through each proxy in order, stopping on first success:\n```rust\nfor proxy in \u0026config.proxies {\n    match try_connect_through(proxy, target).await {\n        Ok(conn) =\u003e return Ok(conn),\n        Err(e) =\u003e tracing::debug!(proxy = %proxy.id, \"Failed: {}\", e),\n    }\n}\nErr(anyhow!(\"All proxies failed\"))\n```\nBest for: Availability-critical where any working path is acceptable\n\n### Policy 3: use_last\nTry the last proxy that was healthy (even if now marked unhealthy):\n```rust\nif let Some(last_healthy) = state.get_last_healthy_proxy().await {\n    try_connect_through(\u0026last_healthy, target).await\n} else {\n    Err(anyhow!(\"No proxy has ever been healthy\"))\n}\n```\nBest for: Transient failures where recent history is a good predictor\n\n### Policy 4: direct (Optional, Dangerous)\nBypass proxy entirely and connect directly:\n```rust\ntracing::warn!(\"Connecting directly - all proxies failed\");\nTcpStream::connect(target).await\n```\nBest for: Non-sensitive traffic where proxy is optional\n**Warning**: This may bypass security controls. Must be explicitly enabled.\n\n## Configuration\n\n```toml\n[settings]\n# What to do when all proxies are unhealthy\n# Options: fail_closed, try_all, use_last, direct\ndegradation_policy = \"fail_closed\"\n\n# How long to wait before applying degradation policy (debounce)\ndegradation_delay_secs = 5\n\n# Whether to allow direct connections (required for \"direct\" policy)\nallow_direct_fallback = false\n```\n\n## Implementation Plan\n\nThe feature is broken into these subtasks:\n1. Add degradation policy configuration options\n2. Implement fail_closed policy (immediate rejection)\n3. Implement try_all policy (sequential attempts)\n4. Implement use_last policy (recent proxy preference)\n5. Add degradation state tracking and delay logic\n6. Integrate degradation handling into connection flow\n\n## Observability\n\nClear logging when degradation activates:\n```\nWARN All proxies unhealthy, applying degradation policy: fail_closed\nWARN Connection rejected due to degradation policy\n```\n\nMetrics (if Prometheus feature implemented):\n- `proxy_degraded` gauge (1 when in degraded state)\n- `proxy_degradation_rejections_total` counter\n\n## Acceptance Criteria\n\n- Configurable degradation policy\n- fail_closed rejects immediately with clear error\n- try_all attempts all proxies sequentially\n- use_last tries most recently healthy proxy\n- Direct fallback requires explicit opt-in\n- Clear logging when degradation activates\n- Delay before applying policy (debounce transients)","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:03:45.83050865-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:23:23.173160032-05:00","dependencies":[{"issue_id":"rust_proxy-zkv","depends_on_id":"rust_proxy-skx","type":"blocks","created_at":"2026-01-18T14:57:05.890829651-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-zkv","depends_on_id":"rust_proxy-ny9","type":"blocks","created_at":"2026-01-18T15:05:39.194560038-05:00","created_by":"Dicklesworthstone"},{"issue_id":"rust_proxy-zkv","depends_on_id":"rust_proxy-toh","type":"blocks","created_at":"2026-01-18T15:05:41.136034311-05:00","created_by":"Dicklesworthstone"}]}
